{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "union-alcohol",
      "metadata": {
        "id": "union-alcohol"
      },
      "source": [
        "# Activity 1.2 : Training Neural Networks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NAME: MA. JENICA ROSE E. MOGATE**\n",
        "\n",
        "**SECTION: CPE32S8**"
      ],
      "metadata": {
        "id": "7uZQgtSb6ccO"
      },
      "id": "7uZQgtSb6ccO"
    },
    {
      "cell_type": "markdown",
      "id": "floppy-teens",
      "metadata": {
        "id": "floppy-teens"
      },
      "source": [
        "#### Objective(s):\n",
        "\n",
        "This activity aims to demonstrate how to train neural networks using keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "engaged-modem",
      "metadata": {
        "id": "engaged-modem"
      },
      "source": [
        "#### Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train neural networks\n",
        "* Demonstrate how to evaluate and plot the model using training and validation loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structured-april",
      "metadata": {
        "id": "structured-april"
      },
      "source": [
        "#### Resources:\n",
        "* Jupyter Notebook\n",
        "\n",
        "CI Pima Diabetes Dataset\n",
        "\n",
        "* pima-indians-diabetes.csv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cutting-fountain",
      "metadata": {
        "id": "cutting-fountain"
      },
      "source": [
        "#### Procedures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "entertaining-therapist",
      "metadata": {
        "id": "entertaining-therapist"
      },
      "source": [
        "Load the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "differential-native",
      "metadata": {
        "id": "differential-native"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "other-married",
      "metadata": {
        "id": "other-married"
      },
      "outputs": [],
      "source": [
        "## Import Keras objects for Deep Learning\n",
        "\n",
        "from keras.models  import Sequential\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mexican-newsletter",
      "metadata": {
        "id": "mexican-newsletter"
      },
      "source": [
        "Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "studied-twelve",
      "metadata": {
        "id": "studied-twelve"
      },
      "outputs": [],
      "source": [
        "filepath = \"pima-indians-diabetes.csv\"\n",
        "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\",\n",
        "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
        "diabetes_df = pd.read_csv(filepath, names=names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "photographic-carnival",
      "metadata": {
        "id": "photographic-carnival"
      },
      "source": [
        "Check the top 5 samples of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "undefined-inventory",
      "metadata": {
        "id": "undefined-inventory",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "875e6fe1-56c5-4830-dfb0-282e45a3a867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(768, 9)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
              "741               3                     102              44              20   \n",
              "428               0                     135              94              46   \n",
              "717              10                      94              72              18   \n",
              "707               2                     127              46              21   \n",
              "103               1                      81              72              18   \n",
              "\n",
              "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
              "741       94  30.8              0.400   26             0  \n",
              "428      145  40.6              0.284   26             0  \n",
              "717        0  23.1              0.595   56             0  \n",
              "707      335  34.4              0.176   22             0  \n",
              "103       40  26.6              0.283   24             0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-910e8335-fccb-4564-a6c1-8fd5691b5448\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>times_pregnant</th>\n",
              "      <th>glucose_tolerance_test</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>skin_thickness</th>\n",
              "      <th>insulin</th>\n",
              "      <th>bmi</th>\n",
              "      <th>pedigree_function</th>\n",
              "      <th>age</th>\n",
              "      <th>has_diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>3</td>\n",
              "      <td>102</td>\n",
              "      <td>44</td>\n",
              "      <td>20</td>\n",
              "      <td>94</td>\n",
              "      <td>30.8</td>\n",
              "      <td>0.400</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>94</td>\n",
              "      <td>46</td>\n",
              "      <td>145</td>\n",
              "      <td>40.6</td>\n",
              "      <td>0.284</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>10</td>\n",
              "      <td>94</td>\n",
              "      <td>72</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>23.1</td>\n",
              "      <td>0.595</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>707</th>\n",
              "      <td>2</td>\n",
              "      <td>127</td>\n",
              "      <td>46</td>\n",
              "      <td>21</td>\n",
              "      <td>335</td>\n",
              "      <td>34.4</td>\n",
              "      <td>0.176</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>72</td>\n",
              "      <td>18</td>\n",
              "      <td>40</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.283</td>\n",
              "      <td>24</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-910e8335-fccb-4564-a6c1-8fd5691b5448')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-910e8335-fccb-4564-a6c1-8fd5691b5448 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-910e8335-fccb-4564-a6c1-8fd5691b5448');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a00af75-2842-4713-8896-694c69985fb0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a00af75-2842-4713-8896-694c69985fb0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a00af75-2842-4713-8896-694c69985fb0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "print(diabetes_df.shape)\n",
        "diabetes_df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "systematic-motorcycle",
      "metadata": {
        "id": "systematic-motorcycle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc18ccb0-10a7-4403-e21e-a9fbc89fbfc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "times_pregnant              int64\n",
              "glucose_tolerance_test      int64\n",
              "blood_pressure              int64\n",
              "skin_thickness              int64\n",
              "insulin                     int64\n",
              "bmi                       float64\n",
              "pedigree_function         float64\n",
              "age                         int64\n",
              "has_diabetes                int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "diabetes_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "collected-lafayette",
      "metadata": {
        "id": "collected-lafayette"
      },
      "outputs": [],
      "source": [
        "X = diabetes_df.iloc[:, :-1].values\n",
        "y = diabetes_df[\"has_diabetes\"].values"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acquired-parallel",
      "metadata": {
        "id": "acquired-parallel"
      },
      "source": [
        "Split the data to Train, and Test (75%, 25%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rational-hollow",
      "metadata": {
        "id": "rational-hollow"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acceptable-equity",
      "metadata": {
        "id": "acceptable-equity",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e85e4941-6591-4825-e51f-46601a635ef7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.3489583333333333, 0.6510416666666666)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "np.mean(y), np.mean(1-y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "thick-reconstruction",
      "metadata": {
        "id": "thick-reconstruction"
      },
      "source": [
        "Build a single hidden layer neural network using 12 nodes.\n",
        "Use the sequential model with single layer network and input shape to 8.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dramatic-zealand",
      "metadata": {
        "id": "dramatic-zealand"
      },
      "source": [
        "Normalize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painted-mathematics",
      "metadata": {
        "id": "painted-mathematics"
      },
      "outputs": [],
      "source": [
        "normalizer = StandardScaler()\n",
        "X_train_norm = normalizer.fit_transform(X_train)\n",
        "X_test_norm = normalizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "previous-electricity",
      "metadata": {
        "id": "previous-electricity"
      },
      "source": [
        "Define the model:\n",
        "* Input size is 8-dimensional\n",
        "* 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
        "* Final layer with one node and sigmoid activation (standard for binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "found-bowling",
      "metadata": {
        "id": "found-bowling"
      },
      "outputs": [],
      "source": [
        "model_1 = Sequential([\n",
        "    Dense(12, input_shape=(8,), activation=\"relu\"),\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "level-terminal",
      "metadata": {
        "id": "level-terminal"
      },
      "source": [
        "View the model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "correct-kingdom",
      "metadata": {
        "id": "correct-kingdom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf71bf2-828f-4d2b-8bd4-ed6367f85642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 12)                108       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 13        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 121 (484.00 Byte)\n",
            "Trainable params: 121 (484.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "herbal-anderson",
      "metadata": {
        "id": "herbal-anderson"
      },
      "source": [
        "Train the model\n",
        "* Compile the model with optimizer, loss function and metrics\n",
        "* Use the fit function to return the run history.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "happy-prompt",
      "metadata": {
        "id": "happy-prompt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2097aaf0-4c18-48e0-92dc-b6e476b30190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "18/18 [==============================] - 1s 26ms/step - loss: 0.7961 - accuracy: 0.4549 - val_loss: 0.7949 - val_accuracy: 0.4479\n",
            "Epoch 2/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.7638 - accuracy: 0.4826 - val_loss: 0.7673 - val_accuracy: 0.4948\n",
            "Epoch 3/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7366 - accuracy: 0.5017 - val_loss: 0.7436 - val_accuracy: 0.5260\n",
            "Epoch 4/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7130 - accuracy: 0.5312 - val_loss: 0.7232 - val_accuracy: 0.5312\n",
            "Epoch 5/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.5556 - val_loss: 0.7055 - val_accuracy: 0.5521\n",
            "Epoch 6/200\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.6751 - accuracy: 0.5903 - val_loss: 0.6897 - val_accuracy: 0.5677\n",
            "Epoch 7/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.6094 - val_loss: 0.6758 - val_accuracy: 0.5677\n",
            "Epoch 8/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6458 - accuracy: 0.6163 - val_loss: 0.6633 - val_accuracy: 0.5781\n",
            "Epoch 9/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.6215 - val_loss: 0.6522 - val_accuracy: 0.5781\n",
            "Epoch 10/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6225 - accuracy: 0.6319 - val_loss: 0.6422 - val_accuracy: 0.5729\n",
            "Epoch 11/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6126 - accuracy: 0.6458 - val_loss: 0.6332 - val_accuracy: 0.5833\n",
            "Epoch 12/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6035 - accuracy: 0.6510 - val_loss: 0.6247 - val_accuracy: 0.6094\n",
            "Epoch 13/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5953 - accuracy: 0.6701 - val_loss: 0.6169 - val_accuracy: 0.6406\n",
            "Epoch 14/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5877 - accuracy: 0.6875 - val_loss: 0.6098 - val_accuracy: 0.6510\n",
            "Epoch 15/200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.5807 - accuracy: 0.6875 - val_loss: 0.6032 - val_accuracy: 0.6719\n",
            "Epoch 16/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5746 - accuracy: 0.6944 - val_loss: 0.5971 - val_accuracy: 0.6771\n",
            "Epoch 17/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5687 - accuracy: 0.6944 - val_loss: 0.5914 - val_accuracy: 0.6823\n",
            "Epoch 18/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5632 - accuracy: 0.7135 - val_loss: 0.5861 - val_accuracy: 0.6875\n",
            "Epoch 19/200\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.5583 - accuracy: 0.7188 - val_loss: 0.5812 - val_accuracy: 0.6927\n",
            "Epoch 20/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5537 - accuracy: 0.7222 - val_loss: 0.5766 - val_accuracy: 0.6979\n",
            "Epoch 21/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5494 - accuracy: 0.7205 - val_loss: 0.5724 - val_accuracy: 0.7031\n",
            "Epoch 22/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5453 - accuracy: 0.7205 - val_loss: 0.5684 - val_accuracy: 0.7083\n",
            "Epoch 23/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7240 - val_loss: 0.5647 - val_accuracy: 0.7135\n",
            "Epoch 24/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5381 - accuracy: 0.7222 - val_loss: 0.5612 - val_accuracy: 0.7188\n",
            "Epoch 25/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7257 - val_loss: 0.5580 - val_accuracy: 0.7188\n",
            "Epoch 26/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5320 - accuracy: 0.7326 - val_loss: 0.5549 - val_accuracy: 0.7292\n",
            "Epoch 27/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5292 - accuracy: 0.7361 - val_loss: 0.5521 - val_accuracy: 0.7292\n",
            "Epoch 28/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5265 - accuracy: 0.7344 - val_loss: 0.5494 - val_accuracy: 0.7344\n",
            "Epoch 29/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5239 - accuracy: 0.7378 - val_loss: 0.5468 - val_accuracy: 0.7396\n",
            "Epoch 30/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5215 - accuracy: 0.7396 - val_loss: 0.5444 - val_accuracy: 0.7396\n",
            "Epoch 31/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5192 - accuracy: 0.7396 - val_loss: 0.5421 - val_accuracy: 0.7396\n",
            "Epoch 32/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7413 - val_loss: 0.5398 - val_accuracy: 0.7396\n",
            "Epoch 33/200\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5151 - accuracy: 0.7500 - val_loss: 0.5377 - val_accuracy: 0.7344\n",
            "Epoch 34/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5131 - accuracy: 0.7517 - val_loss: 0.5356 - val_accuracy: 0.7396\n",
            "Epoch 35/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
            "Epoch 36/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7500 - val_loss: 0.5318 - val_accuracy: 0.7448\n",
            "Epoch 37/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5076 - accuracy: 0.7535 - val_loss: 0.5301 - val_accuracy: 0.7448\n",
            "Epoch 38/200\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5060 - accuracy: 0.7535 - val_loss: 0.5285 - val_accuracy: 0.7396\n",
            "Epoch 39/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7517 - val_loss: 0.5269 - val_accuracy: 0.7448\n",
            "Epoch 40/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7517 - val_loss: 0.5254 - val_accuracy: 0.7448\n",
            "Epoch 41/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.7552 - val_loss: 0.5239 - val_accuracy: 0.7396\n",
            "Epoch 42/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5002 - accuracy: 0.7587 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
            "Epoch 43/200\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4989 - accuracy: 0.7604 - val_loss: 0.5212 - val_accuracy: 0.7500\n",
            "Epoch 44/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4977 - accuracy: 0.7622 - val_loss: 0.5199 - val_accuracy: 0.7500\n",
            "Epoch 45/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7604 - val_loss: 0.5187 - val_accuracy: 0.7552\n",
            "Epoch 46/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7622 - val_loss: 0.5175 - val_accuracy: 0.7552\n",
            "Epoch 47/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7587 - val_loss: 0.5164 - val_accuracy: 0.7552\n",
            "Epoch 48/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4930 - accuracy: 0.7604 - val_loss: 0.5153 - val_accuracy: 0.7552\n",
            "Epoch 49/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4920 - accuracy: 0.7622 - val_loss: 0.5143 - val_accuracy: 0.7552\n",
            "Epoch 50/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7622 - val_loss: 0.5133 - val_accuracy: 0.7552\n",
            "Epoch 51/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7569 - val_loss: 0.5123 - val_accuracy: 0.7552\n",
            "Epoch 52/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4888 - accuracy: 0.7604 - val_loss: 0.5113 - val_accuracy: 0.7604\n",
            "Epoch 53/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4878 - accuracy: 0.7622 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
            "Epoch 54/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4869 - accuracy: 0.7569 - val_loss: 0.5095 - val_accuracy: 0.7708\n",
            "Epoch 55/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7604 - val_loss: 0.5087 - val_accuracy: 0.7708\n",
            "Epoch 56/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7639 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
            "Epoch 57/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7656 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
            "Epoch 58/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4834 - accuracy: 0.7622 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
            "Epoch 59/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7622 - val_loss: 0.5057 - val_accuracy: 0.7708\n",
            "Epoch 60/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4819 - accuracy: 0.7639 - val_loss: 0.5051 - val_accuracy: 0.7656\n",
            "Epoch 61/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.5045 - val_accuracy: 0.7656\n",
            "Epoch 62/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4807 - accuracy: 0.7622 - val_loss: 0.5040 - val_accuracy: 0.7656\n",
            "Epoch 63/200\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4800 - accuracy: 0.7622 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
            "Epoch 64/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4793 - accuracy: 0.7639 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
            "Epoch 65/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.7656 - val_loss: 0.5024 - val_accuracy: 0.7708\n",
            "Epoch 66/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.7691 - val_loss: 0.5019 - val_accuracy: 0.7708\n",
            "Epoch 67/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4774 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7708\n",
            "Epoch 68/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7691 - val_loss: 0.5010 - val_accuracy: 0.7708\n",
            "Epoch 69/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7760\n",
            "Epoch 70/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4758 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7760\n",
            "Epoch 71/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4752 - accuracy: 0.7726 - val_loss: 0.4998 - val_accuracy: 0.7812\n",
            "Epoch 72/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.7726 - val_loss: 0.4994 - val_accuracy: 0.7812\n",
            "Epoch 73/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7812\n",
            "Epoch 74/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.7708 - val_loss: 0.4988 - val_accuracy: 0.7812\n",
            "Epoch 75/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4731 - accuracy: 0.7708 - val_loss: 0.4985 - val_accuracy: 0.7812\n",
            "Epoch 76/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4726 - accuracy: 0.7691 - val_loss: 0.4982 - val_accuracy: 0.7865\n",
            "Epoch 77/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.7674 - val_loss: 0.4979 - val_accuracy: 0.7865\n",
            "Epoch 78/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7691 - val_loss: 0.4977 - val_accuracy: 0.7865\n",
            "Epoch 79/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7691 - val_loss: 0.4975 - val_accuracy: 0.7865\n",
            "Epoch 80/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7674 - val_loss: 0.4972 - val_accuracy: 0.7917\n",
            "Epoch 81/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7691 - val_loss: 0.4970 - val_accuracy: 0.7969\n",
            "Epoch 82/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7674 - val_loss: 0.4967 - val_accuracy: 0.7969\n",
            "Epoch 83/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7674 - val_loss: 0.4965 - val_accuracy: 0.7969\n",
            "Epoch 84/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7674 - val_loss: 0.4963 - val_accuracy: 0.7969\n",
            "Epoch 85/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7674 - val_loss: 0.4960 - val_accuracy: 0.7969\n",
            "Epoch 86/200\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4680 - accuracy: 0.7691 - val_loss: 0.4958 - val_accuracy: 0.7969\n",
            "Epoch 87/200\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4675 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7969\n",
            "Epoch 88/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.7656 - val_loss: 0.4954 - val_accuracy: 0.7969\n",
            "Epoch 89/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.7691 - val_loss: 0.4953 - val_accuracy: 0.7969\n",
            "Epoch 90/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7969\n",
            "Epoch 91/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7969\n",
            "Epoch 92/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7917\n",
            "Epoch 93/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7760 - val_loss: 0.4946 - val_accuracy: 0.7917\n",
            "Epoch 94/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7917\n",
            "Epoch 95/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7760 - val_loss: 0.4943 - val_accuracy: 0.7917\n",
            "Epoch 96/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4942 - val_accuracy: 0.7917\n",
            "Epoch 97/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7760 - val_loss: 0.4941 - val_accuracy: 0.7917\n",
            "Epoch 98/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7778 - val_loss: 0.4940 - val_accuracy: 0.7917\n",
            "Epoch 99/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7778 - val_loss: 0.4940 - val_accuracy: 0.7865\n",
            "Epoch 100/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7778 - val_loss: 0.4939 - val_accuracy: 0.7865\n",
            "Epoch 101/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7778 - val_loss: 0.4938 - val_accuracy: 0.7865\n",
            "Epoch 102/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
            "Epoch 103/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7865\n",
            "Epoch 104/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 105/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.4936 - val_accuracy: 0.7865\n",
            "Epoch 106/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 107/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7778 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 108/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 109/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7760 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 110/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 111/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7760 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 112/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7865\n",
            "Epoch 113/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7865\n",
            "Epoch 114/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7865\n",
            "Epoch 115/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7865\n",
            "Epoch 116/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7865\n",
            "Epoch 117/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7865\n",
            "Epoch 118/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 119/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 120/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 121/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 122/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
            "Epoch 123/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.7795 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
            "Epoch 124/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7865\n",
            "Epoch 125/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4560 - accuracy: 0.7830 - val_loss: 0.4926 - val_accuracy: 0.7865\n",
            "Epoch 126/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 127/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7812\n",
            "Epoch 128/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
            "Epoch 129/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7812\n",
            "Epoch 130/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7812\n",
            "Epoch 131/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 132/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.7830 - val_loss: 0.4928 - val_accuracy: 0.7865\n",
            "Epoch 133/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7865\n",
            "Epoch 134/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7865\n",
            "Epoch 135/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7830 - val_loss: 0.4930 - val_accuracy: 0.7865\n",
            "Epoch 136/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.7882 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 137/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7865 - val_loss: 0.4931 - val_accuracy: 0.7812\n",
            "Epoch 138/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7812\n",
            "Epoch 139/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 140/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7882 - val_loss: 0.4933 - val_accuracy: 0.7812\n",
            "Epoch 141/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.7882 - val_loss: 0.4934 - val_accuracy: 0.7812\n",
            "Epoch 142/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 143/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7899 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 144/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.7847 - val_loss: 0.4935 - val_accuracy: 0.7812\n",
            "Epoch 145/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 146/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 147/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 148/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7847 - val_loss: 0.4936 - val_accuracy: 0.7812\n",
            "Epoch 149/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7830 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 150/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7830 - val_loss: 0.4937 - val_accuracy: 0.7812\n",
            "Epoch 151/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7847 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 152/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 153/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 154/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 155/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7830 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 156/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7830 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 157/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7830 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 158/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7830 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
            "Epoch 159/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7830 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 160/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7812 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
            "Epoch 161/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7812 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 162/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7795 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
            "Epoch 163/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7812 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 164/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7795 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
            "Epoch 165/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 166/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 167/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4457 - accuracy: 0.7812 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
            "Epoch 168/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 169/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7812 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
            "Epoch 170/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7812 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 171/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7830 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
            "Epoch 172/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 173/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.7812 - val_loss: 0.4932 - val_accuracy: 0.7708\n",
            "Epoch 174/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7830 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 175/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7812 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 176/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 177/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7830 - val_loss: 0.4931 - val_accuracy: 0.7708\n",
            "Epoch 178/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 179/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7830 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 180/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7812 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 181/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7708\n",
            "Epoch 182/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7830 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 183/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7708\n",
            "Epoch 184/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7656\n",
            "Epoch 185/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 186/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.7795 - val_loss: 0.4928 - val_accuracy: 0.7708\n",
            "Epoch 187/200\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 188/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7708\n",
            "Epoch 189/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7830 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 190/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7656\n",
            "Epoch 191/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7830 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 192/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7795 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 193/200\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.4423 - accuracy: 0.7812 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 194/200\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4422 - accuracy: 0.7830 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 195/200\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4420 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7656\n",
            "Epoch 196/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7830 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 197/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 198/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 199/200\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4417 - accuracy: 0.7830 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
            "Epoch 200/200\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7830 - val_loss: 0.4925 - val_accuracy: 0.7656\n"
          ]
        }
      ],
      "source": [
        "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_class_nn_1 = (model_1.predict(X_test_norm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf7nzUxt-5rn",
        "outputId": "059bec3e-70fa-4acc-818e-3cafc30bdf35"
      },
      "id": "Lf7nzUxt-5rn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob_nn_1 = (model_1.predict(X_test_norm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssJ-fk4_C13",
        "outputId": "fa5138cf-346c-4063-f145-5e482d769180"
      },
      "id": "xssJ-fk4_C13",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tough-catering",
      "metadata": {
        "id": "tough-catering",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7295059d-fd14-4bbe-89ba-00e13696b664"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4352558 ],\n",
              "       [0.58007175],\n",
              "       [0.36048824],\n",
              "       [0.29185423],\n",
              "       [0.17806976],\n",
              "       [0.56857723],\n",
              "       [0.04447858],\n",
              "       [0.28456476],\n",
              "       [0.9223908 ],\n",
              "       [0.1720243 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Let's check out the outputs to get a feel for how keras apis work.\n",
        "y_pred_class_nn_1[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "combined-zimbabwe",
      "metadata": {
        "id": "combined-zimbabwe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c50f81b-7d7c-4ae6-94f8-7a433e8289bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4352558 ],\n",
              "       [0.58007175],\n",
              "       [0.36048824],\n",
              "       [0.29185423],\n",
              "       [0.17806976],\n",
              "       [0.56857723],\n",
              "       [0.04447858],\n",
              "       [0.28456476],\n",
              "       [0.9223908 ],\n",
              "       [0.1720243 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "y_pred_prob_nn_1[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "going-estonia",
      "metadata": {
        "id": "going-estonia"
      },
      "source": [
        "Create the plot_roc function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rf = RandomForestClassifier(n_estimators=200)\n",
        "Rf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "La3oLqqW_zn-",
        "outputId": "bc2cf7bb-0682-4f90-d226-7fa741efd6f1"
      },
      "id": "La3oLqqW_zn-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "supposed-moderator",
      "metadata": {
        "id": "supposed-moderator"
      },
      "outputs": [],
      "source": [
        "def plot_roc(y_test, y_pred, model_name):\n",
        "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
        "    fig, ax = plt.subplots(figsize=(8, 8))\n",
        "    ax.plot(fpr, tpr, 'k-')\n",
        "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
        "    ax.grid(True)\n",
        "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
        "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "second-festival",
      "metadata": {
        "id": "second-festival"
      },
      "source": [
        "Evaluate the model performance and plot the ROC CURVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,Rf.predict(X_test))))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,Rf.predict_proba(X_test)[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "gVqIAs2RAKnf",
        "outputId": "21a64907-61e4-43fd-d8d5-1561b514bd27"
      },
      "id": "gVqIAs2RAKnf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.836\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "invalid-nevada",
      "metadata": {
        "id": "invalid-nevada"
      },
      "source": [
        " Plot the training loss and the validation loss over the different epochs and see how it looks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hidden-physics",
      "metadata": {
        "id": "hidden-physics",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e45df91b-4eab-4270-8cb9-f63e0736eef3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "run_hist_1.history.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "banned-spider",
      "metadata": {
        "id": "banned-spider",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "8630f9e1-6f6b-4cc0-dd35-0e0972000ac8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3f4f30aa70>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "superb-circus",
      "metadata": {
        "id": "superb-circus"
      },
      "source": [
        "What is your interpretation about the result of the train and validation loss?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data is underfitting because it fails to reach the train loss and match the graph line of the validation loss. It shows that the trainig data fails to predict the value of the validation."
      ],
      "metadata": {
        "id": "_hdPEZ5AI0Hi"
      },
      "id": "_hdPEZ5AI0Hi"
    },
    {
      "cell_type": "markdown",
      "id": "german-cherry",
      "metadata": {
        "id": "german-cherry"
      },
      "source": [
        "#type your answer here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "involved-slovak",
      "metadata": {
        "id": "involved-slovak"
      },
      "source": [
        "#### Supplementary Activity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pending-publisher",
      "metadata": {
        "id": "pending-publisher"
      },
      "source": [
        "* Build a model with two hidden layers, each with 6 nodes\n",
        "* Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "* Use a learning rate of .003 and train for 1500 epochs\n",
        "* Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "* Plot the roc curve for the predictions\n",
        "* Use different learning rates, numbers of epochs, and network structures.\n",
        "* Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "* Interpret your result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intimate-factory",
      "metadata": {
        "id": "intimate-factory"
      },
      "source": [
        "#### Conclusion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a model with two hidden layers, each with 6 nodes\n",
        "#Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
        "\n",
        "supple = Sequential([\n",
        "    Dense(6, input_shape=(8,), activation=\"sigmoid\"),\n",
        "    Dense(2, activation=\"relu\")\n",
        "])"
      ],
      "metadata": {
        "id": "2c4l4DbNBkY2"
      },
      "id": "2c4l4DbNBkY2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a learning rate of .003 and train for 1500 epochs\n",
        "supple.compile(SGD(learning_rate = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_1 = supple.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mub475mQCZJo",
        "outputId": "d40df598-bd79-4419-b309-04ddfaf6cd98"
      },
      "id": "mub475mQCZJo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1500\n",
            "18/18 [==============================] - 1s 22ms/step - loss: 1.9328 - accuracy: 0.6823 - val_loss: 1.6825 - val_accuracy: 0.6979\n",
            "Epoch 2/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1788 - accuracy: 0.6788 - val_loss: 1.1325 - val_accuracy: 0.6875\n",
            "Epoch 3/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0401 - accuracy: 0.6788 - val_loss: 1.0491 - val_accuracy: 0.6927\n",
            "Epoch 4/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.9156 - accuracy: 0.6701 - val_loss: 0.9084 - val_accuracy: 0.6615\n",
            "Epoch 5/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8367 - accuracy: 0.6389 - val_loss: 0.8466 - val_accuracy: 0.6615\n",
            "Epoch 6/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5291 - accuracy: 0.6875 - val_loss: 1.6613 - val_accuracy: 0.7031\n",
            "Epoch 7/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.4214 - accuracy: 0.7066 - val_loss: 1.2423 - val_accuracy: 0.6823\n",
            "Epoch 8/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9245 - accuracy: 0.6771 - val_loss: 0.7258 - val_accuracy: 0.6615\n",
            "Epoch 9/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7181 - accuracy: 0.6580 - val_loss: 0.7205 - val_accuracy: 0.6510\n",
            "Epoch 10/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7133 - accuracy: 0.6545 - val_loss: 0.7160 - val_accuracy: 0.6458\n",
            "Epoch 11/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.6528 - val_loss: 0.7121 - val_accuracy: 0.6458\n",
            "Epoch 12/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7053 - accuracy: 0.6510 - val_loss: 0.7082 - val_accuracy: 0.6510\n",
            "Epoch 13/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.7017 - accuracy: 0.6510 - val_loss: 0.7047 - val_accuracy: 0.6458\n",
            "Epoch 14/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.6510 - val_loss: 0.7013 - val_accuracy: 0.6458\n",
            "Epoch 15/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6950 - accuracy: 0.6493 - val_loss: 0.6979 - val_accuracy: 0.6458\n",
            "Epoch 16/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.6476 - val_loss: 0.6948 - val_accuracy: 0.6510\n",
            "Epoch 17/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6887 - accuracy: 0.6528 - val_loss: 0.6919 - val_accuracy: 0.6510\n",
            "Epoch 18/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6785 - accuracy: 0.6111 - val_loss: 0.6622 - val_accuracy: 0.5573\n",
            "Epoch 19/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6370 - accuracy: 0.5938 - val_loss: 0.6561 - val_accuracy: 0.5729\n",
            "Epoch 20/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6146 - val_loss: 0.6233 - val_accuracy: 0.5885\n",
            "Epoch 21/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6267 - accuracy: 0.6215 - val_loss: 0.6190 - val_accuracy: 0.6146\n",
            "Epoch 22/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6234 - accuracy: 0.6319 - val_loss: 0.6158 - val_accuracy: 0.6198\n",
            "Epoch 23/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.6302 - val_loss: 0.6129 - val_accuracy: 0.6198\n",
            "Epoch 24/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.6302 - val_loss: 0.6103 - val_accuracy: 0.6198\n",
            "Epoch 25/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6148 - accuracy: 0.6302 - val_loss: 0.6079 - val_accuracy: 0.6198\n",
            "Epoch 26/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6122 - accuracy: 0.6285 - val_loss: 0.6055 - val_accuracy: 0.6250\n",
            "Epoch 27/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.6285 - val_loss: 0.6034 - val_accuracy: 0.6250\n",
            "Epoch 28/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.6075 - accuracy: 0.6285 - val_loss: 0.6012 - val_accuracy: 0.6250\n",
            "Epoch 29/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.6250 - val_loss: 0.5991 - val_accuracy: 0.6302\n",
            "Epoch 30/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6028 - accuracy: 0.6267 - val_loss: 0.5970 - val_accuracy: 0.6302\n",
            "Epoch 31/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.6285 - val_loss: 0.5947 - val_accuracy: 0.6302\n",
            "Epoch 32/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5984 - accuracy: 0.6250 - val_loss: 0.5926 - val_accuracy: 0.6302\n",
            "Epoch 33/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6250 - val_loss: 0.5907 - val_accuracy: 0.6302\n",
            "Epoch 34/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6250 - val_loss: 0.5887 - val_accuracy: 0.6302\n",
            "Epoch 35/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5922 - accuracy: 0.6233 - val_loss: 0.5868 - val_accuracy: 0.6302\n",
            "Epoch 36/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5902 - accuracy: 0.6250 - val_loss: 0.5853 - val_accuracy: 0.6302\n",
            "Epoch 37/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5884 - accuracy: 0.6233 - val_loss: 0.5838 - val_accuracy: 0.6302\n",
            "Epoch 38/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.6267 - val_loss: 0.5819 - val_accuracy: 0.6250\n",
            "Epoch 39/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5845 - accuracy: 0.6267 - val_loss: 0.5805 - val_accuracy: 0.6250\n",
            "Epoch 40/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.6285 - val_loss: 0.5789 - val_accuracy: 0.6250\n",
            "Epoch 41/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5812 - accuracy: 0.6302 - val_loss: 0.5773 - val_accuracy: 0.6198\n",
            "Epoch 42/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5794 - accuracy: 0.6285 - val_loss: 0.5756 - val_accuracy: 0.6146\n",
            "Epoch 43/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5778 - accuracy: 0.6250 - val_loss: 0.5742 - val_accuracy: 0.6146\n",
            "Epoch 44/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5761 - accuracy: 0.6198 - val_loss: 0.5729 - val_accuracy: 0.6146\n",
            "Epoch 45/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5744 - accuracy: 0.6250 - val_loss: 0.5712 - val_accuracy: 0.6146\n",
            "Epoch 46/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5728 - accuracy: 0.6233 - val_loss: 0.5699 - val_accuracy: 0.6146\n",
            "Epoch 47/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6233 - val_loss: 0.5691 - val_accuracy: 0.6094\n",
            "Epoch 48/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5696 - accuracy: 0.6250 - val_loss: 0.5683 - val_accuracy: 0.6094\n",
            "Epoch 49/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5682 - accuracy: 0.6250 - val_loss: 0.5673 - val_accuracy: 0.6094\n",
            "Epoch 50/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6233 - val_loss: 0.5664 - val_accuracy: 0.6094\n",
            "Epoch 51/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5650 - accuracy: 0.6215 - val_loss: 0.5654 - val_accuracy: 0.6094\n",
            "Epoch 52/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.6233 - val_loss: 0.5647 - val_accuracy: 0.6094\n",
            "Epoch 53/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5622 - accuracy: 0.6215 - val_loss: 0.5638 - val_accuracy: 0.6094\n",
            "Epoch 54/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5607 - accuracy: 0.6215 - val_loss: 0.5633 - val_accuracy: 0.6094\n",
            "Epoch 55/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5516 - accuracy: 0.6215 - val_loss: 0.5680 - val_accuracy: 0.4531\n",
            "Epoch 56/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.5156 - val_loss: 0.5567 - val_accuracy: 0.4896\n",
            "Epoch 57/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5395 - accuracy: 0.5382 - val_loss: 0.5527 - val_accuracy: 0.5104\n",
            "Epoch 58/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5371 - accuracy: 0.5434 - val_loss: 0.5502 - val_accuracy: 0.5208\n",
            "Epoch 59/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5360 - accuracy: 0.5486 - val_loss: 0.5485 - val_accuracy: 0.5208\n",
            "Epoch 60/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.5486 - val_loss: 0.5533 - val_accuracy: 0.4375\n",
            "Epoch 61/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.5052 - val_loss: 0.5476 - val_accuracy: 0.4844\n",
            "Epoch 62/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.5382 - val_loss: 0.5445 - val_accuracy: 0.5052\n",
            "Epoch 63/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5289 - accuracy: 0.5503 - val_loss: 0.5424 - val_accuracy: 0.5260\n",
            "Epoch 64/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5273 - accuracy: 0.5573 - val_loss: 0.5409 - val_accuracy: 0.5573\n",
            "Epoch 65/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.5573 - val_loss: 0.5395 - val_accuracy: 0.5521\n",
            "Epoch 66/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5247 - accuracy: 0.5642 - val_loss: 0.5385 - val_accuracy: 0.5417\n",
            "Epoch 67/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.5625 - val_loss: 0.5373 - val_accuracy: 0.5469\n",
            "Epoch 68/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.5556 - val_loss: 0.5361 - val_accuracy: 0.5521\n",
            "Epoch 69/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.5573 - val_loss: 0.5350 - val_accuracy: 0.5521\n",
            "Epoch 70/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5197 - accuracy: 0.5538 - val_loss: 0.5339 - val_accuracy: 0.5521\n",
            "Epoch 71/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.5538 - val_loss: 0.5329 - val_accuracy: 0.5521\n",
            "Epoch 72/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5174 - accuracy: 0.5608 - val_loss: 0.5319 - val_accuracy: 0.5521\n",
            "Epoch 73/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.5573 - val_loss: 0.5309 - val_accuracy: 0.5521\n",
            "Epoch 74/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5150 - accuracy: 0.5573 - val_loss: 0.5299 - val_accuracy: 0.5521\n",
            "Epoch 75/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5141 - accuracy: 0.5573 - val_loss: 0.5290 - val_accuracy: 0.5469\n",
            "Epoch 76/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5131 - accuracy: 0.5608 - val_loss: 0.5281 - val_accuracy: 0.5469\n",
            "Epoch 77/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5121 - accuracy: 0.5660 - val_loss: 0.5272 - val_accuracy: 0.5469\n",
            "Epoch 78/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5115 - accuracy: 0.5573 - val_loss: 0.5264 - val_accuracy: 0.5469\n",
            "Epoch 79/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5100 - accuracy: 0.5590 - val_loss: 0.5256 - val_accuracy: 0.5417\n",
            "Epoch 80/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5090 - accuracy: 0.5556 - val_loss: 0.5248 - val_accuracy: 0.5417\n",
            "Epoch 81/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.5608 - val_loss: 0.5240 - val_accuracy: 0.5365\n",
            "Epoch 82/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5072 - accuracy: 0.5503 - val_loss: 0.5231 - val_accuracy: 0.5365\n",
            "Epoch 83/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.5538 - val_loss: 0.5224 - val_accuracy: 0.5365\n",
            "Epoch 84/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.5521 - val_loss: 0.5217 - val_accuracy: 0.5365\n",
            "Epoch 85/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.5521 - val_loss: 0.5210 - val_accuracy: 0.5521\n",
            "Epoch 86/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5036 - accuracy: 0.5538 - val_loss: 0.5203 - val_accuracy: 0.5417\n",
            "Epoch 87/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.5503 - val_loss: 0.5196 - val_accuracy: 0.5469\n",
            "Epoch 88/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.5538 - val_loss: 0.5190 - val_accuracy: 0.5469\n",
            "Epoch 89/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.5538 - val_loss: 0.5183 - val_accuracy: 0.5365\n",
            "Epoch 90/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.5503 - val_loss: 0.5177 - val_accuracy: 0.5365\n",
            "Epoch 91/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.5556 - val_loss: 0.5171 - val_accuracy: 0.5365\n",
            "Epoch 92/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.5469 - val_loss: 0.5165 - val_accuracy: 0.5417\n",
            "Epoch 93/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.5503 - val_loss: 0.5159 - val_accuracy: 0.5365\n",
            "Epoch 94/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.5451 - val_loss: 0.5154 - val_accuracy: 0.5469\n",
            "Epoch 95/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4965 - accuracy: 0.5538 - val_loss: 0.5149 - val_accuracy: 0.5417\n",
            "Epoch 96/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4960 - accuracy: 0.5417 - val_loss: 0.5144 - val_accuracy: 0.5521\n",
            "Epoch 97/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4953 - accuracy: 0.5503 - val_loss: 0.5138 - val_accuracy: 0.5521\n",
            "Epoch 98/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4947 - accuracy: 0.5538 - val_loss: 0.5134 - val_accuracy: 0.5521\n",
            "Epoch 99/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.5521 - val_loss: 0.5129 - val_accuracy: 0.5469\n",
            "Epoch 100/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4932 - accuracy: 0.5538 - val_loss: 0.5124 - val_accuracy: 0.5417\n",
            "Epoch 101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4927 - accuracy: 0.5451 - val_loss: 0.5119 - val_accuracy: 0.5365\n",
            "Epoch 102/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.5451 - val_loss: 0.5114 - val_accuracy: 0.5365\n",
            "Epoch 103/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4917 - accuracy: 0.5451 - val_loss: 0.5111 - val_accuracy: 0.5365\n",
            "Epoch 104/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4910 - accuracy: 0.5434 - val_loss: 0.5106 - val_accuracy: 0.5417\n",
            "Epoch 105/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4904 - accuracy: 0.5486 - val_loss: 0.5103 - val_accuracy: 0.5469\n",
            "Epoch 106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4896 - accuracy: 0.5486 - val_loss: 0.5098 - val_accuracy: 0.5417\n",
            "Epoch 107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4891 - accuracy: 0.5486 - val_loss: 0.5094 - val_accuracy: 0.5469\n",
            "Epoch 108/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4886 - accuracy: 0.5469 - val_loss: 0.5091 - val_accuracy: 0.5469\n",
            "Epoch 109/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.5486 - val_loss: 0.5087 - val_accuracy: 0.5469\n",
            "Epoch 110/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4876 - accuracy: 0.5451 - val_loss: 0.5084 - val_accuracy: 0.5469\n",
            "Epoch 111/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.5503 - val_loss: 0.5080 - val_accuracy: 0.5469\n",
            "Epoch 112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.5469 - val_loss: 0.5077 - val_accuracy: 0.5521\n",
            "Epoch 113/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4860 - accuracy: 0.5451 - val_loss: 0.5075 - val_accuracy: 0.5573\n",
            "Epoch 114/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.5469 - val_loss: 0.5072 - val_accuracy: 0.5573\n",
            "Epoch 115/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.5451 - val_loss: 0.5068 - val_accuracy: 0.5573\n",
            "Epoch 116/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4849 - accuracy: 0.5434 - val_loss: 0.5066 - val_accuracy: 0.5521\n",
            "Epoch 117/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.5451 - val_loss: 0.5065 - val_accuracy: 0.5469\n",
            "Epoch 118/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.5399 - val_loss: 0.5064 - val_accuracy: 0.5573\n",
            "Epoch 119/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.5434 - val_loss: 0.5061 - val_accuracy: 0.5573\n",
            "Epoch 120/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4829 - accuracy: 0.5469 - val_loss: 0.5059 - val_accuracy: 0.5625\n",
            "Epoch 121/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4824 - accuracy: 0.5469 - val_loss: 0.5057 - val_accuracy: 0.5573\n",
            "Epoch 122/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4823 - accuracy: 0.5451 - val_loss: 0.5056 - val_accuracy: 0.5573\n",
            "Epoch 123/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.5434 - val_loss: 0.5054 - val_accuracy: 0.5521\n",
            "Epoch 124/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4813 - accuracy: 0.5451 - val_loss: 0.5051 - val_accuracy: 0.5521\n",
            "Epoch 125/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.5382 - val_loss: 0.5049 - val_accuracy: 0.5521\n",
            "Epoch 126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.5451 - val_loss: 0.5047 - val_accuracy: 0.5521\n",
            "Epoch 127/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.5417 - val_loss: 0.5044 - val_accuracy: 0.5521\n",
            "Epoch 128/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.5417 - val_loss: 0.5042 - val_accuracy: 0.5521\n",
            "Epoch 129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4794 - accuracy: 0.5382 - val_loss: 0.5040 - val_accuracy: 0.5469\n",
            "Epoch 130/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4790 - accuracy: 0.5434 - val_loss: 0.5039 - val_accuracy: 0.5469\n",
            "Epoch 131/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.5417 - val_loss: 0.5039 - val_accuracy: 0.5469\n",
            "Epoch 132/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.5434 - val_loss: 0.5037 - val_accuracy: 0.5469\n",
            "Epoch 133/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.5399 - val_loss: 0.5037 - val_accuracy: 0.5469\n",
            "Epoch 134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.5469 - val_loss: 0.5033 - val_accuracy: 0.5469\n",
            "Epoch 135/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4776 - accuracy: 0.5469 - val_loss: 0.5034 - val_accuracy: 0.5469\n",
            "Epoch 136/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4771 - accuracy: 0.5538 - val_loss: 0.5035 - val_accuracy: 0.5469\n",
            "Epoch 137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.5503 - val_loss: 0.5032 - val_accuracy: 0.5469\n",
            "Epoch 138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.5399 - val_loss: 0.5028 - val_accuracy: 0.5469\n",
            "Epoch 139/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.5417 - val_loss: 0.5028 - val_accuracy: 0.5469\n",
            "Epoch 140/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.5469 - val_loss: 0.5029 - val_accuracy: 0.5469\n",
            "Epoch 141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4759 - accuracy: 0.5434 - val_loss: 0.5030 - val_accuracy: 0.5469\n",
            "Epoch 142/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.5417 - val_loss: 0.5031 - val_accuracy: 0.5469\n",
            "Epoch 143/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.5503 - val_loss: 0.5027 - val_accuracy: 0.5469\n",
            "Epoch 144/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.5434 - val_loss: 0.5030 - val_accuracy: 0.5469\n",
            "Epoch 145/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.5503 - val_loss: 0.5024 - val_accuracy: 0.5469\n",
            "Epoch 146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.5469 - val_loss: 0.5021 - val_accuracy: 0.5469\n",
            "Epoch 147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.5434 - val_loss: 0.5022 - val_accuracy: 0.5469\n",
            "Epoch 148/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.5382 - val_loss: 0.5025 - val_accuracy: 0.5521\n",
            "Epoch 149/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.5399 - val_loss: 0.5027 - val_accuracy: 0.5521\n",
            "Epoch 150/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.5399 - val_loss: 0.5026 - val_accuracy: 0.5521\n",
            "Epoch 151/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4732 - accuracy: 0.5399 - val_loss: 0.5028 - val_accuracy: 0.5521\n",
            "Epoch 152/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.5434 - val_loss: 0.5025 - val_accuracy: 0.5573\n",
            "Epoch 153/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.5417 - val_loss: 0.5029 - val_accuracy: 0.5625\n",
            "Epoch 154/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.5451 - val_loss: 0.5027 - val_accuracy: 0.5625\n",
            "Epoch 155/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.5382 - val_loss: 0.5028 - val_accuracy: 0.5677\n",
            "Epoch 156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.5399 - val_loss: 0.5026 - val_accuracy: 0.5729\n",
            "Epoch 157/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4716 - accuracy: 0.5469 - val_loss: 0.5028 - val_accuracy: 0.5729\n",
            "Epoch 158/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.5451 - val_loss: 0.5022 - val_accuracy: 0.5573\n",
            "Epoch 159/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.5417 - val_loss: 0.5021 - val_accuracy: 0.5573\n",
            "Epoch 160/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.5451 - val_loss: 0.5021 - val_accuracy: 0.5521\n",
            "Epoch 161/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.5382 - val_loss: 0.5029 - val_accuracy: 0.5677\n",
            "Epoch 162/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.5399 - val_loss: 0.5041 - val_accuracy: 0.5729\n",
            "Epoch 163/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.5382 - val_loss: 0.5036 - val_accuracy: 0.5729\n",
            "Epoch 164/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.5434 - val_loss: 0.5042 - val_accuracy: 0.5781\n",
            "Epoch 165/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4700 - accuracy: 0.5434 - val_loss: 0.5036 - val_accuracy: 0.5729\n",
            "Epoch 166/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.5365 - val_loss: 0.5036 - val_accuracy: 0.5729\n",
            "Epoch 167/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.5417 - val_loss: 0.5037 - val_accuracy: 0.5729\n",
            "Epoch 168/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.5469 - val_loss: 0.5050 - val_accuracy: 0.5677\n",
            "Epoch 169/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.5521 - val_loss: 0.5034 - val_accuracy: 0.5729\n",
            "Epoch 170/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.5365 - val_loss: 0.5032 - val_accuracy: 0.5677\n",
            "Epoch 171/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.5399 - val_loss: 0.5043 - val_accuracy: 0.5677\n",
            "Epoch 172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.5382 - val_loss: 0.5060 - val_accuracy: 0.5781\n",
            "Epoch 173/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.5434 - val_loss: 0.5049 - val_accuracy: 0.5677\n",
            "Epoch 174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.5382 - val_loss: 0.5067 - val_accuracy: 0.5729\n",
            "Epoch 175/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.5399 - val_loss: 0.5071 - val_accuracy: 0.5729\n",
            "Epoch 176/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.5347 - val_loss: 0.5130 - val_accuracy: 0.5781\n",
            "Epoch 177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.5503 - val_loss: 0.5331 - val_accuracy: 0.5729\n",
            "Epoch 178/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.5399 - val_loss: 0.5333 - val_accuracy: 0.5781\n",
            "Epoch 179/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.5521 - val_loss: 0.5329 - val_accuracy: 0.5729\n",
            "Epoch 180/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.5399 - val_loss: 0.5331 - val_accuracy: 0.5729\n",
            "Epoch 181/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.5417 - val_loss: 0.5337 - val_accuracy: 0.5781\n",
            "Epoch 182/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.5451 - val_loss: 0.5331 - val_accuracy: 0.5781\n",
            "Epoch 183/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.5451 - val_loss: 0.5330 - val_accuracy: 0.5781\n",
            "Epoch 184/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.5434 - val_loss: 0.5333 - val_accuracy: 0.5781\n",
            "Epoch 185/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4664 - accuracy: 0.5469 - val_loss: 0.5337 - val_accuracy: 0.5781\n",
            "Epoch 186/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.5451 - val_loss: 0.5340 - val_accuracy: 0.5781\n",
            "Epoch 187/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.5486 - val_loss: 0.5339 - val_accuracy: 0.5781\n",
            "Epoch 188/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.5469 - val_loss: 0.5349 - val_accuracy: 0.5781\n",
            "Epoch 189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.5486 - val_loss: 0.5339 - val_accuracy: 0.5781\n",
            "Epoch 190/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.5521 - val_loss: 0.5338 - val_accuracy: 0.5781\n",
            "Epoch 191/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.5538 - val_loss: 0.5336 - val_accuracy: 0.5781\n",
            "Epoch 192/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.5451 - val_loss: 0.5350 - val_accuracy: 0.5781\n",
            "Epoch 193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.5486 - val_loss: 0.5363 - val_accuracy: 0.5781\n",
            "Epoch 194/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.5677 - val_loss: 0.5343 - val_accuracy: 0.5781\n",
            "Epoch 195/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.5590 - val_loss: 0.5340 - val_accuracy: 0.5781\n",
            "Epoch 196/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.5573 - val_loss: 0.5350 - val_accuracy: 0.5781\n",
            "Epoch 197/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.5660 - val_loss: 0.5339 - val_accuracy: 0.5729\n",
            "Epoch 198/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.5556 - val_loss: 0.5371 - val_accuracy: 0.5781\n",
            "Epoch 199/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.5590 - val_loss: 0.5389 - val_accuracy: 0.5781\n",
            "Epoch 200/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.5660 - val_loss: 0.5341 - val_accuracy: 0.5729\n",
            "Epoch 201/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.5573 - val_loss: 0.5360 - val_accuracy: 0.5781\n",
            "Epoch 202/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.5625 - val_loss: 0.5364 - val_accuracy: 0.5833\n",
            "Epoch 203/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.5625 - val_loss: 0.5405 - val_accuracy: 0.5833\n",
            "Epoch 204/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4641 - accuracy: 0.5642 - val_loss: 0.5380 - val_accuracy: 0.5729\n",
            "Epoch 205/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.5608 - val_loss: 0.5615 - val_accuracy: 0.5781\n",
            "Epoch 206/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4636 - accuracy: 0.5642 - val_loss: 0.5611 - val_accuracy: 0.5781\n",
            "Epoch 207/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.5590 - val_loss: 0.5616 - val_accuracy: 0.5781\n",
            "Epoch 208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.5660 - val_loss: 0.5618 - val_accuracy: 0.5833\n",
            "Epoch 209/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.5694 - val_loss: 0.5617 - val_accuracy: 0.5833\n",
            "Epoch 210/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.5694 - val_loss: 0.5615 - val_accuracy: 0.5833\n",
            "Epoch 211/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.5660 - val_loss: 0.5626 - val_accuracy: 0.5833\n",
            "Epoch 212/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.5747 - val_loss: 0.5607 - val_accuracy: 0.5729\n",
            "Epoch 213/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.5694 - val_loss: 0.5604 - val_accuracy: 0.5781\n",
            "Epoch 214/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.5729 - val_loss: 0.5602 - val_accuracy: 0.5781\n",
            "Epoch 215/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.5694 - val_loss: 0.5604 - val_accuracy: 0.5833\n",
            "Epoch 216/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.5694 - val_loss: 0.5614 - val_accuracy: 0.5885\n",
            "Epoch 217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.5799 - val_loss: 0.5615 - val_accuracy: 0.5885\n",
            "Epoch 218/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.5816 - val_loss: 0.5616 - val_accuracy: 0.5938\n",
            "Epoch 219/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.5816 - val_loss: 0.5620 - val_accuracy: 0.5885\n",
            "Epoch 220/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.5903 - val_loss: 0.5616 - val_accuracy: 0.5938\n",
            "Epoch 221/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.5799 - val_loss: 0.5620 - val_accuracy: 0.5885\n",
            "Epoch 222/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4622 - accuracy: 0.5955 - val_loss: 0.5622 - val_accuracy: 0.5938\n",
            "Epoch 223/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.5799 - val_loss: 0.5615 - val_accuracy: 0.5938\n",
            "Epoch 224/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.5851 - val_loss: 0.5613 - val_accuracy: 0.5938\n",
            "Epoch 225/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.5833 - val_loss: 0.5607 - val_accuracy: 0.5938\n",
            "Epoch 226/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.5938 - val_loss: 0.5608 - val_accuracy: 0.5990\n",
            "Epoch 227/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.5938 - val_loss: 0.5626 - val_accuracy: 0.5938\n",
            "Epoch 228/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.5903 - val_loss: 0.5641 - val_accuracy: 0.5938\n",
            "Epoch 229/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.5955 - val_loss: 0.5651 - val_accuracy: 0.5938\n",
            "Epoch 230/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.6024 - val_loss: 0.5622 - val_accuracy: 0.5885\n",
            "Epoch 231/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.5920 - val_loss: 0.5614 - val_accuracy: 0.6042\n",
            "Epoch 232/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4611 - accuracy: 0.6024 - val_loss: 0.5618 - val_accuracy: 0.6042\n",
            "Epoch 233/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.5903 - val_loss: 0.5627 - val_accuracy: 0.5938\n",
            "Epoch 234/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.6059 - val_loss: 0.5610 - val_accuracy: 0.6042\n",
            "Epoch 235/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.5920 - val_loss: 0.5624 - val_accuracy: 0.5938\n",
            "Epoch 236/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.6042 - val_loss: 0.5613 - val_accuracy: 0.6042\n",
            "Epoch 237/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.5955 - val_loss: 0.5607 - val_accuracy: 0.6094\n",
            "Epoch 238/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.6042 - val_loss: 0.5614 - val_accuracy: 0.5938\n",
            "Epoch 239/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.6059 - val_loss: 0.5636 - val_accuracy: 0.5938\n",
            "Epoch 240/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.6094 - val_loss: 0.5662 - val_accuracy: 0.5990\n",
            "Epoch 241/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.6146 - val_loss: 0.5632 - val_accuracy: 0.5990\n",
            "Epoch 242/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.6111 - val_loss: 0.5643 - val_accuracy: 0.5938\n",
            "Epoch 243/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4601 - accuracy: 0.6094 - val_loss: 0.5648 - val_accuracy: 0.5990\n",
            "Epoch 244/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.6181 - val_loss: 0.5676 - val_accuracy: 0.5990\n",
            "Epoch 245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.6007 - val_loss: 0.5686 - val_accuracy: 0.5938\n",
            "Epoch 246/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.6146 - val_loss: 0.5681 - val_accuracy: 0.5990\n",
            "Epoch 247/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.6076 - val_loss: 0.5715 - val_accuracy: 0.6094\n",
            "Epoch 248/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4596 - accuracy: 0.6198 - val_loss: 0.5649 - val_accuracy: 0.6146\n",
            "Epoch 249/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4594 - accuracy: 0.6163 - val_loss: 0.5621 - val_accuracy: 0.6094\n",
            "Epoch 250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4597 - accuracy: 0.6198 - val_loss: 0.5613 - val_accuracy: 0.6094\n",
            "Epoch 251/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.6181 - val_loss: 0.5630 - val_accuracy: 0.6042\n",
            "Epoch 252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4595 - accuracy: 0.6163 - val_loss: 0.5618 - val_accuracy: 0.6094\n",
            "Epoch 253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.6163 - val_loss: 0.5619 - val_accuracy: 0.6094\n",
            "Epoch 254/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.6163 - val_loss: 0.5663 - val_accuracy: 0.6094\n",
            "Epoch 255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.6215 - val_loss: 0.5635 - val_accuracy: 0.6042\n",
            "Epoch 256/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.6198 - val_loss: 0.5623 - val_accuracy: 0.6042\n",
            "Epoch 257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4592 - accuracy: 0.6198 - val_loss: 0.5614 - val_accuracy: 0.6146\n",
            "Epoch 258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4591 - accuracy: 0.6250 - val_loss: 0.5635 - val_accuracy: 0.6094\n",
            "Epoch 259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.6267 - val_loss: 0.5630 - val_accuracy: 0.6094\n",
            "Epoch 260/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.6250 - val_loss: 0.5698 - val_accuracy: 0.6094\n",
            "Epoch 261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.6285 - val_loss: 0.5882 - val_accuracy: 0.6094\n",
            "Epoch 262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.6267 - val_loss: 0.5668 - val_accuracy: 0.6146\n",
            "Epoch 263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.6267 - val_loss: 0.5885 - val_accuracy: 0.6146\n",
            "Epoch 264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4586 - accuracy: 0.6302 - val_loss: 0.5886 - val_accuracy: 0.6146\n",
            "Epoch 265/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.6267 - val_loss: 0.5884 - val_accuracy: 0.6146\n",
            "Epoch 266/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4587 - accuracy: 0.6302 - val_loss: 0.5691 - val_accuracy: 0.6094\n",
            "Epoch 267/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4585 - accuracy: 0.6250 - val_loss: 0.5883 - val_accuracy: 0.6094\n",
            "Epoch 268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.6337 - val_loss: 0.5730 - val_accuracy: 0.6094\n",
            "Epoch 269/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.6233 - val_loss: 0.5884 - val_accuracy: 0.6094\n",
            "Epoch 270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.6319 - val_loss: 0.5667 - val_accuracy: 0.6094\n",
            "Epoch 271/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.6319 - val_loss: 0.5883 - val_accuracy: 0.6042\n",
            "Epoch 272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.6250 - val_loss: 0.5883 - val_accuracy: 0.5990\n",
            "Epoch 273/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.6319 - val_loss: 0.5883 - val_accuracy: 0.6042\n",
            "Epoch 274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.6354 - val_loss: 0.5641 - val_accuracy: 0.6146\n",
            "Epoch 275/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.6267 - val_loss: 0.5881 - val_accuracy: 0.5990\n",
            "Epoch 276/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.6337 - val_loss: 0.5881 - val_accuracy: 0.5990\n",
            "Epoch 277/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.6319 - val_loss: 0.5884 - val_accuracy: 0.5990\n",
            "Epoch 278/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.6285 - val_loss: 0.5884 - val_accuracy: 0.6042\n",
            "Epoch 279/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.6319 - val_loss: 0.5886 - val_accuracy: 0.5938\n",
            "Epoch 280/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.6337 - val_loss: 0.5882 - val_accuracy: 0.6042\n",
            "Epoch 281/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4573 - accuracy: 0.6267 - val_loss: 0.5886 - val_accuracy: 0.5938\n",
            "Epoch 282/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.6302 - val_loss: 0.5886 - val_accuracy: 0.5938\n",
            "Epoch 283/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.6302 - val_loss: 0.5887 - val_accuracy: 0.6042\n",
            "Epoch 284/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4574 - accuracy: 0.6302 - val_loss: 0.5886 - val_accuracy: 0.5938\n",
            "Epoch 285/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.6250 - val_loss: 0.5881 - val_accuracy: 0.6042\n",
            "Epoch 286/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.6319 - val_loss: 0.5887 - val_accuracy: 0.6094\n",
            "Epoch 287/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.6302 - val_loss: 0.5888 - val_accuracy: 0.6146\n",
            "Epoch 288/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.6389 - val_loss: 0.5885 - val_accuracy: 0.5990\n",
            "Epoch 289/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.6319 - val_loss: 0.5885 - val_accuracy: 0.5990\n",
            "Epoch 290/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.6372 - val_loss: 0.5886 - val_accuracy: 0.5990\n",
            "Epoch 291/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.6319 - val_loss: 0.5888 - val_accuracy: 0.6146\n",
            "Epoch 292/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.6285 - val_loss: 0.5885 - val_accuracy: 0.6094\n",
            "Epoch 293/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.6372 - val_loss: 0.5889 - val_accuracy: 0.6146\n",
            "Epoch 294/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.6406 - val_loss: 0.5888 - val_accuracy: 0.6146\n",
            "Epoch 295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4568 - accuracy: 0.6319 - val_loss: 0.5892 - val_accuracy: 0.6146\n",
            "Epoch 296/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.6337 - val_loss: 0.5890 - val_accuracy: 0.6146\n",
            "Epoch 297/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.6389 - val_loss: 0.5888 - val_accuracy: 0.6146\n",
            "Epoch 298/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.6337 - val_loss: 0.5891 - val_accuracy: 0.6094\n",
            "Epoch 299/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.6406 - val_loss: 0.5891 - val_accuracy: 0.6146\n",
            "Epoch 300/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.6319 - val_loss: 0.5887 - val_accuracy: 0.6146\n",
            "Epoch 301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.6319 - val_loss: 0.5885 - val_accuracy: 0.6094\n",
            "Epoch 302/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.6319 - val_loss: 0.5882 - val_accuracy: 0.6042\n",
            "Epoch 303/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.6354 - val_loss: 0.5885 - val_accuracy: 0.6094\n",
            "Epoch 304/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.6337 - val_loss: 0.5888 - val_accuracy: 0.6094\n",
            "Epoch 305/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.6337 - val_loss: 0.5890 - val_accuracy: 0.6146\n",
            "Epoch 306/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.6337 - val_loss: 0.5885 - val_accuracy: 0.6094\n",
            "Epoch 307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.6319 - val_loss: 0.5896 - val_accuracy: 0.6094\n",
            "Epoch 308/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.6319 - val_loss: 0.5891 - val_accuracy: 0.6146\n",
            "Epoch 309/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.6354 - val_loss: 0.5896 - val_accuracy: 0.6094\n",
            "Epoch 310/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.6354 - val_loss: 0.5892 - val_accuracy: 0.6094\n",
            "Epoch 311/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4559 - accuracy: 0.6337 - val_loss: 0.5889 - val_accuracy: 0.6094\n",
            "Epoch 312/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.6302 - val_loss: 0.5887 - val_accuracy: 0.6094\n",
            "Epoch 313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.6354 - val_loss: 0.5888 - val_accuracy: 0.6094\n",
            "Epoch 314/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.6354 - val_loss: 0.5891 - val_accuracy: 0.6094\n",
            "Epoch 315/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.6319 - val_loss: 0.5898 - val_accuracy: 0.6094\n",
            "Epoch 316/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.6389 - val_loss: 0.5906 - val_accuracy: 0.6094\n",
            "Epoch 317/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.6337 - val_loss: 0.5906 - val_accuracy: 0.6146\n",
            "Epoch 318/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.6406 - val_loss: 0.5896 - val_accuracy: 0.6094\n",
            "Epoch 319/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.6319 - val_loss: 0.5901 - val_accuracy: 0.6146\n",
            "Epoch 320/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.6389 - val_loss: 0.5891 - val_accuracy: 0.6146\n",
            "Epoch 321/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4554 - accuracy: 0.6406 - val_loss: 0.5897 - val_accuracy: 0.6146\n",
            "Epoch 322/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.6354 - val_loss: 0.5904 - val_accuracy: 0.6146\n",
            "Epoch 323/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4552 - accuracy: 0.6389 - val_loss: 0.5902 - val_accuracy: 0.6198\n",
            "Epoch 324/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4555 - accuracy: 0.6354 - val_loss: 0.5904 - val_accuracy: 0.6198\n",
            "Epoch 325/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4552 - accuracy: 0.6337 - val_loss: 0.5909 - val_accuracy: 0.6198\n",
            "Epoch 326/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.6319 - val_loss: 0.5904 - val_accuracy: 0.6198\n",
            "Epoch 327/1500\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.6337 - val_loss: 0.5905 - val_accuracy: 0.6198\n",
            "Epoch 328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4554 - accuracy: 0.6354 - val_loss: 0.5906 - val_accuracy: 0.6146\n",
            "Epoch 329/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.6354 - val_loss: 0.5901 - val_accuracy: 0.6198\n",
            "Epoch 330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.6354 - val_loss: 0.5900 - val_accuracy: 0.6198\n",
            "Epoch 331/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.6319 - val_loss: 0.5903 - val_accuracy: 0.6198\n",
            "Epoch 332/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.6372 - val_loss: 0.5903 - val_accuracy: 0.6198\n",
            "Epoch 333/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.6267 - val_loss: 0.5895 - val_accuracy: 0.6146\n",
            "Epoch 334/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.6302 - val_loss: 0.5899 - val_accuracy: 0.6146\n",
            "Epoch 335/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.6319 - val_loss: 0.5899 - val_accuracy: 0.6198\n",
            "Epoch 336/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.6302 - val_loss: 0.5899 - val_accuracy: 0.6250\n",
            "Epoch 337/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.6354 - val_loss: 0.5894 - val_accuracy: 0.6198\n",
            "Epoch 338/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.6285 - val_loss: 0.5899 - val_accuracy: 0.6302\n",
            "Epoch 339/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.6354 - val_loss: 0.5894 - val_accuracy: 0.6198\n",
            "Epoch 340/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.6233 - val_loss: 0.5901 - val_accuracy: 0.6198\n",
            "Epoch 341/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.6233 - val_loss: 0.5903 - val_accuracy: 0.6198\n",
            "Epoch 342/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.6250 - val_loss: 0.5910 - val_accuracy: 0.6198\n",
            "Epoch 343/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4546 - accuracy: 0.6319 - val_loss: 0.5903 - val_accuracy: 0.6198\n",
            "Epoch 344/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.6354 - val_loss: 0.5894 - val_accuracy: 0.6146\n",
            "Epoch 345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4546 - accuracy: 0.6389 - val_loss: 0.5895 - val_accuracy: 0.6198\n",
            "Epoch 346/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.6233 - val_loss: 0.5893 - val_accuracy: 0.6146\n",
            "Epoch 347/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.6406 - val_loss: 0.5898 - val_accuracy: 0.6146\n",
            "Epoch 348/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.6302 - val_loss: 0.5910 - val_accuracy: 0.6146\n",
            "Epoch 349/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.6285 - val_loss: 0.5909 - val_accuracy: 0.6146\n",
            "Epoch 350/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.6372 - val_loss: 0.5909 - val_accuracy: 0.6146\n",
            "Epoch 351/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.6337 - val_loss: 0.5915 - val_accuracy: 0.6198\n",
            "Epoch 352/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.6302 - val_loss: 0.5927 - val_accuracy: 0.6146\n",
            "Epoch 353/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.6354 - val_loss: 0.5925 - val_accuracy: 0.6198\n",
            "Epoch 354/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.6285 - val_loss: 0.5930 - val_accuracy: 0.6250\n",
            "Epoch 355/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4540 - accuracy: 0.6319 - val_loss: 0.5915 - val_accuracy: 0.6250\n",
            "Epoch 356/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.6337 - val_loss: 0.5911 - val_accuracy: 0.6250\n",
            "Epoch 357/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.6250 - val_loss: 0.5919 - val_accuracy: 0.6250\n",
            "Epoch 358/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.6406 - val_loss: 0.5911 - val_accuracy: 0.6198\n",
            "Epoch 359/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.6250 - val_loss: 0.5920 - val_accuracy: 0.6302\n",
            "Epoch 360/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.6372 - val_loss: 0.5912 - val_accuracy: 0.6302\n",
            "Epoch 361/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.6337 - val_loss: 0.5930 - val_accuracy: 0.6302\n",
            "Epoch 362/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.6372 - val_loss: 0.5933 - val_accuracy: 0.6198\n",
            "Epoch 363/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.6319 - val_loss: 0.5946 - val_accuracy: 0.6250\n",
            "Epoch 364/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.6337 - val_loss: 0.5941 - val_accuracy: 0.6198\n",
            "Epoch 365/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.6267 - val_loss: 0.5931 - val_accuracy: 0.6198\n",
            "Epoch 366/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.6354 - val_loss: 0.5925 - val_accuracy: 0.6198\n",
            "Epoch 367/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.6337 - val_loss: 0.5916 - val_accuracy: 0.6354\n",
            "Epoch 368/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.6389 - val_loss: 0.5923 - val_accuracy: 0.6198\n",
            "Epoch 369/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.6233 - val_loss: 0.5919 - val_accuracy: 0.6198\n",
            "Epoch 370/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.6337 - val_loss: 0.5918 - val_accuracy: 0.6198\n",
            "Epoch 371/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.6285 - val_loss: 0.5919 - val_accuracy: 0.6250\n",
            "Epoch 372/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.6372 - val_loss: 0.5927 - val_accuracy: 0.6198\n",
            "Epoch 373/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.6319 - val_loss: 0.5918 - val_accuracy: 0.6250\n",
            "Epoch 374/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.6302 - val_loss: 0.5922 - val_accuracy: 0.6250\n",
            "Epoch 375/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.6406 - val_loss: 0.5928 - val_accuracy: 0.6198\n",
            "Epoch 376/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.6302 - val_loss: 0.5933 - val_accuracy: 0.6146\n",
            "Epoch 377/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4536 - accuracy: 0.6285 - val_loss: 0.5921 - val_accuracy: 0.6198\n",
            "Epoch 378/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.6319 - val_loss: 0.5913 - val_accuracy: 0.6198\n",
            "Epoch 379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.6319 - val_loss: 0.5919 - val_accuracy: 0.6146\n",
            "Epoch 380/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.6285 - val_loss: 0.5928 - val_accuracy: 0.6198\n",
            "Epoch 381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4532 - accuracy: 0.6250 - val_loss: 0.5938 - val_accuracy: 0.6198\n",
            "Epoch 382/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.6389 - val_loss: 0.5947 - val_accuracy: 0.6146\n",
            "Epoch 383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4530 - accuracy: 0.6302 - val_loss: 0.5977 - val_accuracy: 0.6198\n",
            "Epoch 384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.6319 - val_loss: 0.5930 - val_accuracy: 0.6250\n",
            "Epoch 385/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.6319 - val_loss: 0.5924 - val_accuracy: 0.6198\n",
            "Epoch 386/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.6285 - val_loss: 0.5932 - val_accuracy: 0.6146\n",
            "Epoch 387/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.6302 - val_loss: 0.5941 - val_accuracy: 0.6250\n",
            "Epoch 388/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.6337 - val_loss: 0.5948 - val_accuracy: 0.6250\n",
            "Epoch 389/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4529 - accuracy: 0.6354 - val_loss: 0.5939 - val_accuracy: 0.6198\n",
            "Epoch 390/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4533 - accuracy: 0.6285 - val_loss: 0.5937 - val_accuracy: 0.6302\n",
            "Epoch 391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.6337 - val_loss: 0.5943 - val_accuracy: 0.6198\n",
            "Epoch 392/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.6302 - val_loss: 0.5944 - val_accuracy: 0.6146\n",
            "Epoch 393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4529 - accuracy: 0.6285 - val_loss: 0.5932 - val_accuracy: 0.6146\n",
            "Epoch 394/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.6233 - val_loss: 0.5944 - val_accuracy: 0.6302\n",
            "Epoch 395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.6337 - val_loss: 0.5951 - val_accuracy: 0.6354\n",
            "Epoch 396/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.6372 - val_loss: 0.5931 - val_accuracy: 0.6302\n",
            "Epoch 397/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4526 - accuracy: 0.6372 - val_loss: 0.5945 - val_accuracy: 0.6354\n",
            "Epoch 398/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.6319 - val_loss: 0.5961 - val_accuracy: 0.6302\n",
            "Epoch 399/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.6233 - val_loss: 0.5948 - val_accuracy: 0.6354\n",
            "Epoch 400/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.6389 - val_loss: 0.5970 - val_accuracy: 0.6198\n",
            "Epoch 401/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.6337 - val_loss: 0.5967 - val_accuracy: 0.6198\n",
            "Epoch 402/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.6267 - val_loss: 0.6226 - val_accuracy: 0.6302\n",
            "Epoch 403/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.6389 - val_loss: 0.5987 - val_accuracy: 0.6094\n",
            "Epoch 404/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.6354 - val_loss: 0.5951 - val_accuracy: 0.6146\n",
            "Epoch 405/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4527 - accuracy: 0.6233 - val_loss: 0.5957 - val_accuracy: 0.6250\n",
            "Epoch 406/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.6337 - val_loss: 0.5970 - val_accuracy: 0.6094\n",
            "Epoch 407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.6319 - val_loss: 0.5953 - val_accuracy: 0.6094\n",
            "Epoch 408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.6215 - val_loss: 0.5946 - val_accuracy: 0.6354\n",
            "Epoch 409/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.6337 - val_loss: 0.5949 - val_accuracy: 0.6406\n",
            "Epoch 410/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.6337 - val_loss: 0.5938 - val_accuracy: 0.6406\n",
            "Epoch 411/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.6424 - val_loss: 0.5943 - val_accuracy: 0.6406\n",
            "Epoch 412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4522 - accuracy: 0.6319 - val_loss: 0.6226 - val_accuracy: 0.6406\n",
            "Epoch 413/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4523 - accuracy: 0.6337 - val_loss: 0.6236 - val_accuracy: 0.6354\n",
            "Epoch 414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.6372 - val_loss: 0.5974 - val_accuracy: 0.6250\n",
            "Epoch 415/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.6337 - val_loss: 0.6055 - val_accuracy: 0.6354\n",
            "Epoch 416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.6337 - val_loss: 0.5984 - val_accuracy: 0.6354\n",
            "Epoch 417/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.6337 - val_loss: 0.5990 - val_accuracy: 0.6354\n",
            "Epoch 418/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.6233 - val_loss: 0.5956 - val_accuracy: 0.6406\n",
            "Epoch 419/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.6354 - val_loss: 0.5950 - val_accuracy: 0.6302\n",
            "Epoch 420/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.6354 - val_loss: 0.5985 - val_accuracy: 0.6302\n",
            "Epoch 421/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.6337 - val_loss: 0.6074 - val_accuracy: 0.6198\n",
            "Epoch 422/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.6389 - val_loss: 0.6233 - val_accuracy: 0.6198\n",
            "Epoch 423/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.6337 - val_loss: 0.5993 - val_accuracy: 0.6198\n",
            "Epoch 424/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.6337 - val_loss: 0.6125 - val_accuracy: 0.6302\n",
            "Epoch 425/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.6267 - val_loss: 0.5983 - val_accuracy: 0.6406\n",
            "Epoch 426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4520 - accuracy: 0.6354 - val_loss: 0.5990 - val_accuracy: 0.6458\n",
            "Epoch 427/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.6337 - val_loss: 0.6116 - val_accuracy: 0.6354\n",
            "Epoch 428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.6354 - val_loss: 0.6015 - val_accuracy: 0.6406\n",
            "Epoch 429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.6302 - val_loss: 0.6012 - val_accuracy: 0.6406\n",
            "Epoch 430/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.6389 - val_loss: 0.5995 - val_accuracy: 0.6406\n",
            "Epoch 431/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.6319 - val_loss: 0.6023 - val_accuracy: 0.6458\n",
            "Epoch 432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.6389 - val_loss: 0.6002 - val_accuracy: 0.6406\n",
            "Epoch 433/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.6337 - val_loss: 0.6239 - val_accuracy: 0.6302\n",
            "Epoch 434/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.6302 - val_loss: 0.6466 - val_accuracy: 0.6250\n",
            "Epoch 435/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.6337 - val_loss: 0.6047 - val_accuracy: 0.6302\n",
            "Epoch 436/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.6337 - val_loss: 0.6013 - val_accuracy: 0.6198\n",
            "Epoch 437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.6372 - val_loss: 0.6013 - val_accuracy: 0.6198\n",
            "Epoch 438/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6285 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 439/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.6302 - val_loss: 0.6260 - val_accuracy: 0.6250\n",
            "Epoch 440/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.6354 - val_loss: 0.6234 - val_accuracy: 0.6250\n",
            "Epoch 441/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.6267 - val_loss: 0.6008 - val_accuracy: 0.6354\n",
            "Epoch 442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.6337 - val_loss: 0.5972 - val_accuracy: 0.6354\n",
            "Epoch 443/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6372 - val_loss: 0.5990 - val_accuracy: 0.6354\n",
            "Epoch 444/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6319 - val_loss: 0.6102 - val_accuracy: 0.6354\n",
            "Epoch 445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.6337 - val_loss: 0.5962 - val_accuracy: 0.6354\n",
            "Epoch 446/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.6354 - val_loss: 0.5984 - val_accuracy: 0.6354\n",
            "Epoch 447/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6302 - val_loss: 0.6240 - val_accuracy: 0.6302\n",
            "Epoch 448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4513 - accuracy: 0.6267 - val_loss: 0.6255 - val_accuracy: 0.6354\n",
            "Epoch 449/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.6302 - val_loss: 0.6006 - val_accuracy: 0.6354\n",
            "Epoch 450/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.6302 - val_loss: 0.5998 - val_accuracy: 0.6406\n",
            "Epoch 451/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.6302 - val_loss: 0.6002 - val_accuracy: 0.6458\n",
            "Epoch 452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.6372 - val_loss: 0.6238 - val_accuracy: 0.6354\n",
            "Epoch 453/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.6354 - val_loss: 0.6025 - val_accuracy: 0.6302\n",
            "Epoch 454/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.6319 - val_loss: 0.6252 - val_accuracy: 0.6302\n",
            "Epoch 455/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.6354 - val_loss: 0.6465 - val_accuracy: 0.6250\n",
            "Epoch 456/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.6354 - val_loss: 0.6021 - val_accuracy: 0.6354\n",
            "Epoch 457/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.6302 - val_loss: 0.6097 - val_accuracy: 0.6302\n",
            "Epoch 458/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.6354 - val_loss: 0.5979 - val_accuracy: 0.6250\n",
            "Epoch 459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.6250 - val_loss: 0.6243 - val_accuracy: 0.6302\n",
            "Epoch 460/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.6267 - val_loss: 0.6464 - val_accuracy: 0.6354\n",
            "Epoch 461/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.6285 - val_loss: 0.6464 - val_accuracy: 0.6354\n",
            "Epoch 462/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.6302 - val_loss: 0.6116 - val_accuracy: 0.6250\n",
            "Epoch 463/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.6354 - val_loss: 0.6239 - val_accuracy: 0.6354\n",
            "Epoch 464/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.6285 - val_loss: 0.6256 - val_accuracy: 0.6250\n",
            "Epoch 465/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.6319 - val_loss: 0.6257 - val_accuracy: 0.6354\n",
            "Epoch 466/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.6337 - val_loss: 0.6259 - val_accuracy: 0.6302\n",
            "Epoch 467/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.6302 - val_loss: 0.6286 - val_accuracy: 0.6302\n",
            "Epoch 468/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.6250 - val_loss: 0.6243 - val_accuracy: 0.6250\n",
            "Epoch 469/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.6337 - val_loss: 0.6023 - val_accuracy: 0.6250\n",
            "Epoch 470/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.6354 - val_loss: 0.6024 - val_accuracy: 0.6302\n",
            "Epoch 471/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.6285 - val_loss: 0.6252 - val_accuracy: 0.6302\n",
            "Epoch 472/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.6285 - val_loss: 0.6269 - val_accuracy: 0.6302\n",
            "Epoch 473/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4512 - accuracy: 0.6250 - val_loss: 0.6464 - val_accuracy: 0.6250\n",
            "Epoch 474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.6319 - val_loss: 0.6251 - val_accuracy: 0.6302\n",
            "Epoch 475/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.6302 - val_loss: 0.6261 - val_accuracy: 0.6302\n",
            "Epoch 476/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.6250 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 477/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.6285 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 478/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.6215 - val_loss: 0.6464 - val_accuracy: 0.6250\n",
            "Epoch 479/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.6302 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 480/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.6372 - val_loss: 0.6245 - val_accuracy: 0.6250\n",
            "Epoch 481/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.6181 - val_loss: 0.6279 - val_accuracy: 0.6250\n",
            "Epoch 482/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.6302 - val_loss: 0.6272 - val_accuracy: 0.6250\n",
            "Epoch 483/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.6250 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 484/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.6267 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 485/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.6215 - val_loss: 0.6259 - val_accuracy: 0.6250\n",
            "Epoch 486/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.6285 - val_loss: 0.5987 - val_accuracy: 0.6198\n",
            "Epoch 487/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.6302 - val_loss: 0.6030 - val_accuracy: 0.6250\n",
            "Epoch 488/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.6215 - val_loss: 0.6242 - val_accuracy: 0.6198\n",
            "Epoch 489/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.6233 - val_loss: 0.6247 - val_accuracy: 0.6250\n",
            "Epoch 490/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.6250 - val_loss: 0.6309 - val_accuracy: 0.6250\n",
            "Epoch 491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.6267 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.6233 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.6215 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 494/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.6250 - val_loss: 0.6247 - val_accuracy: 0.6198\n",
            "Epoch 495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.6215 - val_loss: 0.6462 - val_accuracy: 0.6198\n",
            "Epoch 496/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.6250 - val_loss: 0.6231 - val_accuracy: 0.6250\n",
            "Epoch 497/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.6233 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 498/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.6250 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.6215 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 500/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.6198 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 501/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.6198 - val_loss: 0.6463 - val_accuracy: 0.6198\n",
            "Epoch 502/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.6233 - val_loss: 0.6463 - val_accuracy: 0.6250\n",
            "Epoch 503/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4502 - accuracy: 0.6215 - val_loss: 0.6463 - val_accuracy: 0.6198\n",
            "Epoch 504/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.6250 - val_loss: 0.6238 - val_accuracy: 0.6302\n",
            "Epoch 505/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.6250 - val_loss: 0.6257 - val_accuracy: 0.6198\n",
            "Epoch 506/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.6198 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 507/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.6319 - val_loss: 0.6034 - val_accuracy: 0.6198\n",
            "Epoch 508/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.6215 - val_loss: 0.6241 - val_accuracy: 0.6250\n",
            "Epoch 509/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.6215 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 510/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.6267 - val_loss: 0.6259 - val_accuracy: 0.6250\n",
            "Epoch 511/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.6285 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 512/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.6233 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 513/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.6250 - val_loss: 0.6226 - val_accuracy: 0.6250\n",
            "Epoch 514/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.6198 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 515/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.6233 - val_loss: 0.6462 - val_accuracy: 0.6198\n",
            "Epoch 516/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.6233 - val_loss: 0.6226 - val_accuracy: 0.6250\n",
            "Epoch 517/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.6198 - val_loss: 0.6283 - val_accuracy: 0.6250\n",
            "Epoch 518/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.6215 - val_loss: 0.6258 - val_accuracy: 0.6198\n",
            "Epoch 519/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.6233 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 520/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.6215 - val_loss: 0.6462 - val_accuracy: 0.6250\n",
            "Epoch 521/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.6233 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 522/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.6146 - val_loss: 0.6462 - val_accuracy: 0.6302\n",
            "Epoch 523/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.6285 - val_loss: 0.6322 - val_accuracy: 0.6198\n",
            "Epoch 524/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.6267 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 525/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.6233 - val_loss: 0.6264 - val_accuracy: 0.6250\n",
            "Epoch 526/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6215 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 527/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.6233 - val_loss: 0.6461 - val_accuracy: 0.6302\n",
            "Epoch 528/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6233 - val_loss: 0.6461 - val_accuracy: 0.6302\n",
            "Epoch 529/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.6233 - val_loss: 0.6462 - val_accuracy: 0.6302\n",
            "Epoch 530/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.6215 - val_loss: 0.6461 - val_accuracy: 0.6302\n",
            "Epoch 531/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.6215 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 532/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.6215 - val_loss: 0.6461 - val_accuracy: 0.6250\n",
            "Epoch 533/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.6267 - val_loss: 0.6460 - val_accuracy: 0.6250\n",
            "Epoch 534/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4495 - accuracy: 0.6267 - val_loss: 0.6252 - val_accuracy: 0.6250\n",
            "Epoch 535/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.6233 - val_loss: 0.6460 - val_accuracy: 0.6250\n",
            "Epoch 536/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.6285 - val_loss: 0.6460 - val_accuracy: 0.6250\n",
            "Epoch 537/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.6198 - val_loss: 0.6240 - val_accuracy: 0.6198\n",
            "Epoch 538/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.6233 - val_loss: 0.6252 - val_accuracy: 0.6250\n",
            "Epoch 539/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.6267 - val_loss: 0.6249 - val_accuracy: 0.6250\n",
            "Epoch 540/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.6267 - val_loss: 0.6460 - val_accuracy: 0.6250\n",
            "Epoch 541/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.6285 - val_loss: 0.6300 - val_accuracy: 0.6250\n",
            "Epoch 542/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.6215 - val_loss: 0.6257 - val_accuracy: 0.6250\n",
            "Epoch 543/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.6198 - val_loss: 0.6460 - val_accuracy: 0.6302\n",
            "Epoch 544/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4496 - accuracy: 0.6250 - val_loss: 0.6245 - val_accuracy: 0.6250\n",
            "Epoch 545/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.6215 - val_loss: 0.6296 - val_accuracy: 0.6302\n",
            "Epoch 546/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.6250 - val_loss: 0.6229 - val_accuracy: 0.6198\n",
            "Epoch 547/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4497 - accuracy: 0.6250 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 548/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.6198 - val_loss: 0.6246 - val_accuracy: 0.6250\n",
            "Epoch 549/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.6233 - val_loss: 0.6216 - val_accuracy: 0.6250\n",
            "Epoch 550/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.6250 - val_loss: 0.6210 - val_accuracy: 0.6302\n",
            "Epoch 551/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.6233 - val_loss: 0.6221 - val_accuracy: 0.6302\n",
            "Epoch 552/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.6233 - val_loss: 0.6255 - val_accuracy: 0.6354\n",
            "Epoch 553/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4494 - accuracy: 0.6215 - val_loss: 0.6246 - val_accuracy: 0.6302\n",
            "Epoch 554/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4492 - accuracy: 0.6337 - val_loss: 0.6459 - val_accuracy: 0.6302\n",
            "Epoch 555/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.6250 - val_loss: 0.6226 - val_accuracy: 0.6302\n",
            "Epoch 556/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.6233 - val_loss: 0.6220 - val_accuracy: 0.6354\n",
            "Epoch 557/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.6215 - val_loss: 0.6229 - val_accuracy: 0.6354\n",
            "Epoch 558/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.6233 - val_loss: 0.6220 - val_accuracy: 0.6302\n",
            "Epoch 559/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4494 - accuracy: 0.6215 - val_loss: 0.6246 - val_accuracy: 0.6302\n",
            "Epoch 560/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.6233 - val_loss: 0.6253 - val_accuracy: 0.6302\n",
            "Epoch 561/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.6285 - val_loss: 0.6232 - val_accuracy: 0.6302\n",
            "Epoch 562/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.6267 - val_loss: 0.6215 - val_accuracy: 0.6354\n",
            "Epoch 563/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.6215 - val_loss: 0.6219 - val_accuracy: 0.6302\n",
            "Epoch 564/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.6233 - val_loss: 0.6228 - val_accuracy: 0.6250\n",
            "Epoch 565/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.6250 - val_loss: 0.6232 - val_accuracy: 0.6250\n",
            "Epoch 566/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.6250 - val_loss: 0.6459 - val_accuracy: 0.6302\n",
            "Epoch 567/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4495 - accuracy: 0.6285 - val_loss: 0.6459 - val_accuracy: 0.6250\n",
            "Epoch 568/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.6250 - val_loss: 0.6459 - val_accuracy: 0.6198\n",
            "Epoch 569/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.6215 - val_loss: 0.6292 - val_accuracy: 0.6250\n",
            "Epoch 570/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.6233 - val_loss: 0.6459 - val_accuracy: 0.6250\n",
            "Epoch 571/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.6215 - val_loss: 0.6459 - val_accuracy: 0.6146\n",
            "Epoch 572/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.6250 - val_loss: 0.6270 - val_accuracy: 0.6198\n",
            "Epoch 573/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.6250 - val_loss: 0.6459 - val_accuracy: 0.6198\n",
            "Epoch 574/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.6215 - val_loss: 0.6459 - val_accuracy: 0.6198\n",
            "Epoch 575/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.6267 - val_loss: 0.6269 - val_accuracy: 0.6198\n",
            "Epoch 576/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.6250 - val_loss: 0.6238 - val_accuracy: 0.6198\n",
            "Epoch 577/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.6250 - val_loss: 0.6219 - val_accuracy: 0.6198\n",
            "Epoch 578/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.6233 - val_loss: 0.6227 - val_accuracy: 0.6250\n",
            "Epoch 579/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.6250 - val_loss: 0.6241 - val_accuracy: 0.6198\n",
            "Epoch 580/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.6233 - val_loss: 0.6237 - val_accuracy: 0.6198\n",
            "Epoch 581/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.6267 - val_loss: 0.6238 - val_accuracy: 0.6198\n",
            "Epoch 582/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.6250 - val_loss: 0.6220 - val_accuracy: 0.6146\n",
            "Epoch 583/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.6250 - val_loss: 0.6243 - val_accuracy: 0.6198\n",
            "Epoch 584/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.6215 - val_loss: 0.6255 - val_accuracy: 0.6198\n",
            "Epoch 585/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.6285 - val_loss: 0.6458 - val_accuracy: 0.6198\n",
            "Epoch 586/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.6267 - val_loss: 0.6254 - val_accuracy: 0.6198\n",
            "Epoch 587/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.6250 - val_loss: 0.6458 - val_accuracy: 0.6198\n",
            "Epoch 588/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.6267 - val_loss: 0.6458 - val_accuracy: 0.6198\n",
            "Epoch 589/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6215 - val_loss: 0.6226 - val_accuracy: 0.6198\n",
            "Epoch 590/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6215 - val_loss: 0.6249 - val_accuracy: 0.6198\n",
            "Epoch 591/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6302 - val_loss: 0.6232 - val_accuracy: 0.6198\n",
            "Epoch 592/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6250 - val_loss: 0.6215 - val_accuracy: 0.6198\n",
            "Epoch 593/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6198 - val_loss: 0.6458 - val_accuracy: 0.6198\n",
            "Epoch 594/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.6233 - val_loss: 0.6263 - val_accuracy: 0.6198\n",
            "Epoch 595/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.6215 - val_loss: 0.6235 - val_accuracy: 0.6198\n",
            "Epoch 596/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6285 - val_loss: 0.6232 - val_accuracy: 0.6198\n",
            "Epoch 597/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.6267 - val_loss: 0.6230 - val_accuracy: 0.6198\n",
            "Epoch 598/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.6302 - val_loss: 0.6227 - val_accuracy: 0.6198\n",
            "Epoch 599/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.6267 - val_loss: 0.6457 - val_accuracy: 0.6198\n",
            "Epoch 600/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.6215 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
            "Epoch 601/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6215 - val_loss: 0.6457 - val_accuracy: 0.6198\n",
            "Epoch 602/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.6267 - val_loss: 0.6457 - val_accuracy: 0.6198\n",
            "Epoch 603/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6285 - val_loss: 0.6264 - val_accuracy: 0.6146\n",
            "Epoch 604/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.6233 - val_loss: 0.6255 - val_accuracy: 0.6302\n",
            "Epoch 605/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.6302 - val_loss: 0.6214 - val_accuracy: 0.6302\n",
            "Epoch 606/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.6267 - val_loss: 0.6230 - val_accuracy: 0.6302\n",
            "Epoch 607/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.6250 - val_loss: 0.6234 - val_accuracy: 0.6250\n",
            "Epoch 608/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.6302 - val_loss: 0.6217 - val_accuracy: 0.6302\n",
            "Epoch 609/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6285 - val_loss: 0.6243 - val_accuracy: 0.6302\n",
            "Epoch 610/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.6319 - val_loss: 0.6224 - val_accuracy: 0.6198\n",
            "Epoch 611/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6233 - val_loss: 0.6316 - val_accuracy: 0.6198\n",
            "Epoch 612/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.6302 - val_loss: 0.6236 - val_accuracy: 0.6198\n",
            "Epoch 613/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6267 - val_loss: 0.6243 - val_accuracy: 0.6198\n",
            "Epoch 614/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.6319 - val_loss: 0.6227 - val_accuracy: 0.6198\n",
            "Epoch 615/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6302 - val_loss: 0.6216 - val_accuracy: 0.6198\n",
            "Epoch 616/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.6250 - val_loss: 0.6218 - val_accuracy: 0.6198\n",
            "Epoch 617/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6250 - val_loss: 0.6264 - val_accuracy: 0.6198\n",
            "Epoch 618/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.6285 - val_loss: 0.6223 - val_accuracy: 0.6302\n",
            "Epoch 619/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6267 - val_loss: 0.6239 - val_accuracy: 0.6198\n",
            "Epoch 620/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6285 - val_loss: 0.6246 - val_accuracy: 0.6198\n",
            "Epoch 621/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6233 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
            "Epoch 622/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.6267 - val_loss: 0.6457 - val_accuracy: 0.6198\n",
            "Epoch 623/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.6267 - val_loss: 0.6457 - val_accuracy: 0.6250\n",
            "Epoch 624/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.6233 - val_loss: 0.6240 - val_accuracy: 0.6302\n",
            "Epoch 625/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6302 - val_loss: 0.6220 - val_accuracy: 0.6250\n",
            "Epoch 626/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.6319 - val_loss: 0.6219 - val_accuracy: 0.6250\n",
            "Epoch 627/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6250 - val_loss: 0.6205 - val_accuracy: 0.6302\n",
            "Epoch 628/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6285 - val_loss: 0.6206 - val_accuracy: 0.6302\n",
            "Epoch 629/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6302 - val_loss: 0.6217 - val_accuracy: 0.6250\n",
            "Epoch 630/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.6267 - val_loss: 0.6218 - val_accuracy: 0.6250\n",
            "Epoch 631/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6267 - val_loss: 0.6202 - val_accuracy: 0.6302\n",
            "Epoch 632/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6285 - val_loss: 0.6208 - val_accuracy: 0.6302\n",
            "Epoch 633/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.6319 - val_loss: 0.6211 - val_accuracy: 0.6302\n",
            "Epoch 634/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6267 - val_loss: 0.6249 - val_accuracy: 0.6198\n",
            "Epoch 635/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6233 - val_loss: 0.6456 - val_accuracy: 0.6146\n",
            "Epoch 636/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.6302 - val_loss: 0.6240 - val_accuracy: 0.6250\n",
            "Epoch 637/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6250 - val_loss: 0.6242 - val_accuracy: 0.6250\n",
            "Epoch 638/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.6302 - val_loss: 0.6254 - val_accuracy: 0.6198\n",
            "Epoch 639/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.6250 - val_loss: 0.6235 - val_accuracy: 0.6302\n",
            "Epoch 640/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6267 - val_loss: 0.6261 - val_accuracy: 0.6250\n",
            "Epoch 641/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.6285 - val_loss: 0.6315 - val_accuracy: 0.6250\n",
            "Epoch 642/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4482 - accuracy: 0.6302 - val_loss: 0.6262 - val_accuracy: 0.6302\n",
            "Epoch 643/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.6267 - val_loss: 0.6224 - val_accuracy: 0.6302\n",
            "Epoch 644/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.6285 - val_loss: 0.6213 - val_accuracy: 0.6250\n",
            "Epoch 645/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.6250 - val_loss: 0.6205 - val_accuracy: 0.6250\n",
            "Epoch 646/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6233 - val_loss: 0.6207 - val_accuracy: 0.6250\n",
            "Epoch 647/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.6285 - val_loss: 0.6214 - val_accuracy: 0.6250\n",
            "Epoch 648/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.6267 - val_loss: 0.6217 - val_accuracy: 0.6250\n",
            "Epoch 649/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6285 - val_loss: 0.6197 - val_accuracy: 0.6250\n",
            "Epoch 650/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.6267 - val_loss: 0.6194 - val_accuracy: 0.6302\n",
            "Epoch 651/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.6302 - val_loss: 0.6195 - val_accuracy: 0.6250\n",
            "Epoch 652/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.6233 - val_loss: 0.6218 - val_accuracy: 0.6198\n",
            "Epoch 653/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.6302 - val_loss: 0.6226 - val_accuracy: 0.6198\n",
            "Epoch 654/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.6267 - val_loss: 0.6229 - val_accuracy: 0.6146\n",
            "Epoch 655/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4481 - accuracy: 0.6215 - val_loss: 0.6226 - val_accuracy: 0.6198\n",
            "Epoch 656/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.6250 - val_loss: 0.6229 - val_accuracy: 0.6198\n",
            "Epoch 657/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4479 - accuracy: 0.6302 - val_loss: 0.6195 - val_accuracy: 0.6250\n",
            "Epoch 658/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6233 - val_loss: 0.6201 - val_accuracy: 0.6250\n",
            "Epoch 659/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.6250 - val_loss: 0.6227 - val_accuracy: 0.6146\n",
            "Epoch 660/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.6267 - val_loss: 0.6206 - val_accuracy: 0.6146\n",
            "Epoch 661/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.6285 - val_loss: 0.6192 - val_accuracy: 0.6198\n",
            "Epoch 662/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.6215 - val_loss: 0.6202 - val_accuracy: 0.6198\n",
            "Epoch 663/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.6302 - val_loss: 0.6209 - val_accuracy: 0.6146\n",
            "Epoch 664/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.6250 - val_loss: 0.6214 - val_accuracy: 0.6198\n",
            "Epoch 665/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.6267 - val_loss: 0.6212 - val_accuracy: 0.6146\n",
            "Epoch 666/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.6267 - val_loss: 0.6201 - val_accuracy: 0.6146\n",
            "Epoch 667/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.6215 - val_loss: 0.6213 - val_accuracy: 0.6198\n",
            "Epoch 668/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4478 - accuracy: 0.6233 - val_loss: 0.6221 - val_accuracy: 0.6198\n",
            "Epoch 669/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.6285 - val_loss: 0.6205 - val_accuracy: 0.6146\n",
            "Epoch 670/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.6250 - val_loss: 0.6215 - val_accuracy: 0.6198\n",
            "Epoch 671/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.6250 - val_loss: 0.6212 - val_accuracy: 0.6146\n",
            "Epoch 672/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.6267 - val_loss: 0.6202 - val_accuracy: 0.6094\n",
            "Epoch 673/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.6250 - val_loss: 0.6202 - val_accuracy: 0.6198\n",
            "Epoch 674/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.6250 - val_loss: 0.6208 - val_accuracy: 0.6198\n",
            "Epoch 675/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.6250 - val_loss: 0.6200 - val_accuracy: 0.6094\n",
            "Epoch 676/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.6215 - val_loss: 0.6217 - val_accuracy: 0.6094\n",
            "Epoch 677/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.6267 - val_loss: 0.6211 - val_accuracy: 0.6094\n",
            "Epoch 678/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.6267 - val_loss: 0.6210 - val_accuracy: 0.6094\n",
            "Epoch 679/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.6267 - val_loss: 0.6192 - val_accuracy: 0.6094\n",
            "Epoch 680/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.6267 - val_loss: 0.6194 - val_accuracy: 0.6198\n",
            "Epoch 681/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.6267 - val_loss: 0.6198 - val_accuracy: 0.6146\n",
            "Epoch 682/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4476 - accuracy: 0.6250 - val_loss: 0.6208 - val_accuracy: 0.6146\n",
            "Epoch 683/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.6302 - val_loss: 0.6196 - val_accuracy: 0.6094\n",
            "Epoch 684/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.6233 - val_loss: 0.6211 - val_accuracy: 0.6146\n",
            "Epoch 685/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.6302 - val_loss: 0.6204 - val_accuracy: 0.6146\n",
            "Epoch 686/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4475 - accuracy: 0.6233 - val_loss: 0.6201 - val_accuracy: 0.6146\n",
            "Epoch 687/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.6250 - val_loss: 0.6213 - val_accuracy: 0.6146\n",
            "Epoch 688/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4475 - accuracy: 0.6267 - val_loss: 0.6209 - val_accuracy: 0.6198\n",
            "Epoch 689/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.6250 - val_loss: 0.6208 - val_accuracy: 0.6146\n",
            "Epoch 690/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4473 - accuracy: 0.6267 - val_loss: 0.6201 - val_accuracy: 0.6146\n",
            "Epoch 691/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.6233 - val_loss: 0.6205 - val_accuracy: 0.6146\n",
            "Epoch 692/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4475 - accuracy: 0.6233 - val_loss: 0.6215 - val_accuracy: 0.6146\n",
            "Epoch 693/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4475 - accuracy: 0.6302 - val_loss: 0.6199 - val_accuracy: 0.6094\n",
            "Epoch 694/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.6198 - val_loss: 0.6210 - val_accuracy: 0.6146\n",
            "Epoch 695/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.6285 - val_loss: 0.6206 - val_accuracy: 0.6146\n",
            "Epoch 696/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4473 - accuracy: 0.6233 - val_loss: 0.6192 - val_accuracy: 0.6094\n",
            "Epoch 697/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.6233 - val_loss: 0.6190 - val_accuracy: 0.6146\n",
            "Epoch 698/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.6215 - val_loss: 0.6202 - val_accuracy: 0.6146\n",
            "Epoch 699/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.6250 - val_loss: 0.6196 - val_accuracy: 0.6094\n",
            "Epoch 700/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.6233 - val_loss: 0.6206 - val_accuracy: 0.6146\n",
            "Epoch 701/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4472 - accuracy: 0.6267 - val_loss: 0.6203 - val_accuracy: 0.6094\n",
            "Epoch 702/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4472 - accuracy: 0.6267 - val_loss: 0.6205 - val_accuracy: 0.6146\n",
            "Epoch 703/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.6250 - val_loss: 0.6199 - val_accuracy: 0.6146\n",
            "Epoch 704/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.6267 - val_loss: 0.6192 - val_accuracy: 0.6146\n",
            "Epoch 705/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.6215 - val_loss: 0.6199 - val_accuracy: 0.6146\n",
            "Epoch 706/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4472 - accuracy: 0.6302 - val_loss: 0.6200 - val_accuracy: 0.6094\n",
            "Epoch 707/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.6302 - val_loss: 0.6195 - val_accuracy: 0.6094\n",
            "Epoch 708/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.6267 - val_loss: 0.6195 - val_accuracy: 0.6146\n",
            "Epoch 709/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.6267 - val_loss: 0.6195 - val_accuracy: 0.5990\n",
            "Epoch 710/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6250 - val_loss: 0.6198 - val_accuracy: 0.6146\n",
            "Epoch 711/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.6233 - val_loss: 0.6198 - val_accuracy: 0.5990\n",
            "Epoch 712/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.6250 - val_loss: 0.6205 - val_accuracy: 0.5990\n",
            "Epoch 713/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6267 - val_loss: 0.6194 - val_accuracy: 0.6094\n",
            "Epoch 714/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.6233 - val_loss: 0.6200 - val_accuracy: 0.6146\n",
            "Epoch 715/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.6285 - val_loss: 0.6187 - val_accuracy: 0.6146\n",
            "Epoch 716/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.6250 - val_loss: 0.6188 - val_accuracy: 0.6146\n",
            "Epoch 717/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6302 - val_loss: 0.6193 - val_accuracy: 0.6094\n",
            "Epoch 718/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4472 - accuracy: 0.6233 - val_loss: 0.6191 - val_accuracy: 0.6094\n",
            "Epoch 719/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.6250 - val_loss: 0.6196 - val_accuracy: 0.6094\n",
            "Epoch 720/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6267 - val_loss: 0.6201 - val_accuracy: 0.6146\n",
            "Epoch 721/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6302 - val_loss: 0.6196 - val_accuracy: 0.6094\n",
            "Epoch 722/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6302 - val_loss: 0.6199 - val_accuracy: 0.5990\n",
            "Epoch 723/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6233 - val_loss: 0.6189 - val_accuracy: 0.6146\n",
            "Epoch 724/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.6267 - val_loss: 0.6190 - val_accuracy: 0.6146\n",
            "Epoch 725/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.6250 - val_loss: 0.6196 - val_accuracy: 0.6146\n",
            "Epoch 726/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.6285 - val_loss: 0.6187 - val_accuracy: 0.6094\n",
            "Epoch 727/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.6267 - val_loss: 0.6188 - val_accuracy: 0.6094\n",
            "Epoch 728/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6267 - val_loss: 0.6189 - val_accuracy: 0.6094\n",
            "Epoch 729/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.6285 - val_loss: 0.6189 - val_accuracy: 0.6146\n",
            "Epoch 730/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4469 - accuracy: 0.6250 - val_loss: 0.6190 - val_accuracy: 0.6094\n",
            "Epoch 731/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6285 - val_loss: 0.6182 - val_accuracy: 0.6094\n",
            "Epoch 732/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4468 - accuracy: 0.6285 - val_loss: 0.6187 - val_accuracy: 0.5990\n",
            "Epoch 733/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.6215 - val_loss: 0.6191 - val_accuracy: 0.6094\n",
            "Epoch 734/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.6267 - val_loss: 0.6196 - val_accuracy: 0.6094\n",
            "Epoch 735/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6250 - val_loss: 0.6186 - val_accuracy: 0.6094\n",
            "Epoch 736/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.6233 - val_loss: 0.6192 - val_accuracy: 0.6094\n",
            "Epoch 737/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.6285 - val_loss: 0.6184 - val_accuracy: 0.6094\n",
            "Epoch 738/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.6215 - val_loss: 0.6182 - val_accuracy: 0.6094\n",
            "Epoch 739/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.6233 - val_loss: 0.6189 - val_accuracy: 0.6094\n",
            "Epoch 740/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.6267 - val_loss: 0.6189 - val_accuracy: 0.6094\n",
            "Epoch 741/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.6285 - val_loss: 0.6186 - val_accuracy: 0.6094\n",
            "Epoch 742/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.6285 - val_loss: 0.6184 - val_accuracy: 0.6042\n",
            "Epoch 743/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.6233 - val_loss: 0.6183 - val_accuracy: 0.6094\n",
            "Epoch 744/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.6198 - val_loss: 0.6188 - val_accuracy: 0.6042\n",
            "Epoch 745/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.6285 - val_loss: 0.6185 - val_accuracy: 0.5990\n",
            "Epoch 746/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.6319 - val_loss: 0.6181 - val_accuracy: 0.6042\n",
            "Epoch 747/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4467 - accuracy: 0.6267 - val_loss: 0.6185 - val_accuracy: 0.5990\n",
            "Epoch 748/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.6267 - val_loss: 0.6186 - val_accuracy: 0.5990\n",
            "Epoch 749/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.6267 - val_loss: 0.6185 - val_accuracy: 0.5990\n",
            "Epoch 750/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.6285 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 751/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.6267 - val_loss: 0.6184 - val_accuracy: 0.6042\n",
            "Epoch 752/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.6233 - val_loss: 0.6188 - val_accuracy: 0.5990\n",
            "Epoch 753/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.6267 - val_loss: 0.6185 - val_accuracy: 0.6042\n",
            "Epoch 754/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.6250 - val_loss: 0.6178 - val_accuracy: 0.6094\n",
            "Epoch 755/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4466 - accuracy: 0.6319 - val_loss: 0.6175 - val_accuracy: 0.6094\n",
            "Epoch 756/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.6267 - val_loss: 0.6177 - val_accuracy: 0.6042\n",
            "Epoch 757/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.6302 - val_loss: 0.6175 - val_accuracy: 0.6042\n",
            "Epoch 758/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.6285 - val_loss: 0.6180 - val_accuracy: 0.5990\n",
            "Epoch 759/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6285 - val_loss: 0.6182 - val_accuracy: 0.6042\n",
            "Epoch 760/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6285 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 761/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.6285 - val_loss: 0.6177 - val_accuracy: 0.6042\n",
            "Epoch 762/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.6302 - val_loss: 0.6179 - val_accuracy: 0.5990\n",
            "Epoch 763/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.6233 - val_loss: 0.6181 - val_accuracy: 0.6042\n",
            "Epoch 764/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6267 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 765/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.6267 - val_loss: 0.6179 - val_accuracy: 0.5990\n",
            "Epoch 766/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.6302 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 767/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.6250 - val_loss: 0.6183 - val_accuracy: 0.5990\n",
            "Epoch 768/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4463 - accuracy: 0.6319 - val_loss: 0.6183 - val_accuracy: 0.5938\n",
            "Epoch 769/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6233 - val_loss: 0.6182 - val_accuracy: 0.5990\n",
            "Epoch 770/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.6285 - val_loss: 0.6176 - val_accuracy: 0.5938\n",
            "Epoch 771/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6285 - val_loss: 0.6178 - val_accuracy: 0.5990\n",
            "Epoch 772/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.6267 - val_loss: 0.6179 - val_accuracy: 0.5938\n",
            "Epoch 773/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6233 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 774/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.6267 - val_loss: 0.6187 - val_accuracy: 0.5938\n",
            "Epoch 775/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.6250 - val_loss: 0.6186 - val_accuracy: 0.5938\n",
            "Epoch 776/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.6198 - val_loss: 0.6185 - val_accuracy: 0.5938\n",
            "Epoch 777/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.6267 - val_loss: 0.6178 - val_accuracy: 0.5990\n",
            "Epoch 778/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6250 - val_loss: 0.6180 - val_accuracy: 0.5938\n",
            "Epoch 779/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.6215 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 780/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.6215 - val_loss: 0.6177 - val_accuracy: 0.6042\n",
            "Epoch 781/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.6250 - val_loss: 0.6180 - val_accuracy: 0.5990\n",
            "Epoch 782/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.6285 - val_loss: 0.6178 - val_accuracy: 0.5990\n",
            "Epoch 783/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.6267 - val_loss: 0.6176 - val_accuracy: 0.5990\n",
            "Epoch 784/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6233 - val_loss: 0.6176 - val_accuracy: 0.5990\n",
            "Epoch 785/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4462 - accuracy: 0.6250 - val_loss: 0.6178 - val_accuracy: 0.5990\n",
            "Epoch 786/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.6250 - val_loss: 0.6175 - val_accuracy: 0.5938\n",
            "Epoch 787/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.6198 - val_loss: 0.6182 - val_accuracy: 0.5990\n",
            "Epoch 788/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.6250 - val_loss: 0.6181 - val_accuracy: 0.5938\n",
            "Epoch 789/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.6267 - val_loss: 0.6182 - val_accuracy: 0.5938\n",
            "Epoch 790/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4458 - accuracy: 0.6285 - val_loss: 0.6178 - val_accuracy: 0.5990\n",
            "Epoch 791/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6302 - val_loss: 0.6175 - val_accuracy: 0.5990\n",
            "Epoch 792/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6233 - val_loss: 0.6174 - val_accuracy: 0.5990\n",
            "Epoch 793/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6198 - val_loss: 0.6180 - val_accuracy: 0.5990\n",
            "Epoch 794/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.6250 - val_loss: 0.6172 - val_accuracy: 0.5990\n",
            "Epoch 795/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.6285 - val_loss: 0.6174 - val_accuracy: 0.5938\n",
            "Epoch 796/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.6181 - val_loss: 0.6175 - val_accuracy: 0.5990\n",
            "Epoch 797/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.6233 - val_loss: 0.6175 - val_accuracy: 0.5938\n",
            "Epoch 798/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6198 - val_loss: 0.6178 - val_accuracy: 0.5938\n",
            "Epoch 799/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.6215 - val_loss: 0.6181 - val_accuracy: 0.5990\n",
            "Epoch 800/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4458 - accuracy: 0.6233 - val_loss: 0.6178 - val_accuracy: 0.5885\n",
            "Epoch 801/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6181 - val_loss: 0.6178 - val_accuracy: 0.5938\n",
            "Epoch 802/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6285 - val_loss: 0.6174 - val_accuracy: 0.5885\n",
            "Epoch 803/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6215 - val_loss: 0.6175 - val_accuracy: 0.5938\n",
            "Epoch 804/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6215 - val_loss: 0.6177 - val_accuracy: 0.6042\n",
            "Epoch 805/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.6233 - val_loss: 0.6180 - val_accuracy: 0.6042\n",
            "Epoch 806/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6233 - val_loss: 0.6177 - val_accuracy: 0.6042\n",
            "Epoch 807/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6250 - val_loss: 0.6176 - val_accuracy: 0.5885\n",
            "Epoch 808/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6198 - val_loss: 0.6175 - val_accuracy: 0.5885\n",
            "Epoch 809/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6215 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 810/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6233 - val_loss: 0.6170 - val_accuracy: 0.5885\n",
            "Epoch 811/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6233 - val_loss: 0.6169 - val_accuracy: 0.5885\n",
            "Epoch 812/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.6146 - val_loss: 0.6175 - val_accuracy: 0.6042\n",
            "Epoch 813/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4457 - accuracy: 0.6233 - val_loss: 0.6168 - val_accuracy: 0.5990\n",
            "Epoch 814/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.6250 - val_loss: 0.6170 - val_accuracy: 0.5885\n",
            "Epoch 815/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.6250 - val_loss: 0.6169 - val_accuracy: 0.5885\n",
            "Epoch 816/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.6250 - val_loss: 0.6174 - val_accuracy: 0.5885\n",
            "Epoch 817/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.6163 - val_loss: 0.6169 - val_accuracy: 0.5885\n",
            "Epoch 818/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.6163 - val_loss: 0.6165 - val_accuracy: 0.5938\n",
            "Epoch 819/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.6215 - val_loss: 0.6166 - val_accuracy: 0.5990\n",
            "Epoch 820/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.6250 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 821/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.6215 - val_loss: 0.6171 - val_accuracy: 0.5938\n",
            "Epoch 822/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4455 - accuracy: 0.6233 - val_loss: 0.6168 - val_accuracy: 0.5885\n",
            "Epoch 823/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.6181 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 824/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4456 - accuracy: 0.6215 - val_loss: 0.6173 - val_accuracy: 0.5990\n",
            "Epoch 825/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.6233 - val_loss: 0.6171 - val_accuracy: 0.6042\n",
            "Epoch 826/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.6250 - val_loss: 0.6168 - val_accuracy: 0.5885\n",
            "Epoch 827/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.6181 - val_loss: 0.6167 - val_accuracy: 0.5885\n",
            "Epoch 828/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.6215 - val_loss: 0.6167 - val_accuracy: 0.5885\n",
            "Epoch 829/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.6181 - val_loss: 0.6173 - val_accuracy: 0.5938\n",
            "Epoch 830/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4453 - accuracy: 0.6181 - val_loss: 0.6168 - val_accuracy: 0.5885\n",
            "Epoch 831/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.6215 - val_loss: 0.6168 - val_accuracy: 0.5833\n",
            "Epoch 832/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4455 - accuracy: 0.6233 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 833/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.6163 - val_loss: 0.6170 - val_accuracy: 0.5885\n",
            "Epoch 834/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.6181 - val_loss: 0.6168 - val_accuracy: 0.5938\n",
            "Epoch 835/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.6233 - val_loss: 0.6169 - val_accuracy: 0.5885\n",
            "Epoch 836/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4454 - accuracy: 0.6163 - val_loss: 0.6166 - val_accuracy: 0.5833\n",
            "Epoch 837/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4452 - accuracy: 0.6198 - val_loss: 0.6168 - val_accuracy: 0.5885\n",
            "Epoch 838/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.6198 - val_loss: 0.6172 - val_accuracy: 0.5885\n",
            "Epoch 839/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.6198 - val_loss: 0.6169 - val_accuracy: 0.5885\n",
            "Epoch 840/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.6267 - val_loss: 0.6169 - val_accuracy: 0.5938\n",
            "Epoch 841/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.6198 - val_loss: 0.6170 - val_accuracy: 0.5990\n",
            "Epoch 842/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4452 - accuracy: 0.6198 - val_loss: 0.6166 - val_accuracy: 0.5938\n",
            "Epoch 843/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.6181 - val_loss: 0.6171 - val_accuracy: 0.5885\n",
            "Epoch 844/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.6250 - val_loss: 0.6173 - val_accuracy: 0.5885\n",
            "Epoch 845/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.6198 - val_loss: 0.6167 - val_accuracy: 0.5885\n",
            "Epoch 846/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4451 - accuracy: 0.6250 - val_loss: 0.6167 - val_accuracy: 0.5885\n",
            "Epoch 847/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4451 - accuracy: 0.6215 - val_loss: 0.6165 - val_accuracy: 0.5938\n",
            "Epoch 848/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.6215 - val_loss: 0.6168 - val_accuracy: 0.5938\n",
            "Epoch 849/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.6233 - val_loss: 0.6165 - val_accuracy: 0.5885\n",
            "Epoch 850/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.6233 - val_loss: 0.6163 - val_accuracy: 0.5833\n",
            "Epoch 851/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6215 - val_loss: 0.6165 - val_accuracy: 0.5885\n",
            "Epoch 852/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.6250 - val_loss: 0.6168 - val_accuracy: 0.5885\n",
            "Epoch 853/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.6215 - val_loss: 0.6164 - val_accuracy: 0.5833\n",
            "Epoch 854/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.6181 - val_loss: 0.6165 - val_accuracy: 0.5885\n",
            "Epoch 855/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.6181 - val_loss: 0.6163 - val_accuracy: 0.5885\n",
            "Epoch 856/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.6233 - val_loss: 0.6161 - val_accuracy: 0.5885\n",
            "Epoch 857/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.6250 - val_loss: 0.6163 - val_accuracy: 0.5833\n",
            "Epoch 858/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.6215 - val_loss: 0.6164 - val_accuracy: 0.5885\n",
            "Epoch 859/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.6198 - val_loss: 0.6167 - val_accuracy: 0.5885\n",
            "Epoch 860/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6215 - val_loss: 0.6164 - val_accuracy: 0.5938\n",
            "Epoch 861/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.6215 - val_loss: 0.6163 - val_accuracy: 0.5885\n",
            "Epoch 862/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.6215 - val_loss: 0.6163 - val_accuracy: 0.5938\n",
            "Epoch 863/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6198 - val_loss: 0.6162 - val_accuracy: 0.5885\n",
            "Epoch 864/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.6198 - val_loss: 0.6161 - val_accuracy: 0.5885\n",
            "Epoch 865/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6233 - val_loss: 0.6161 - val_accuracy: 0.5885\n",
            "Epoch 866/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.6181 - val_loss: 0.6164 - val_accuracy: 0.5885\n",
            "Epoch 867/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.6250 - val_loss: 0.6165 - val_accuracy: 0.5885\n",
            "Epoch 868/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6233 - val_loss: 0.6162 - val_accuracy: 0.5833\n",
            "Epoch 869/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.6233 - val_loss: 0.6162 - val_accuracy: 0.5990\n",
            "Epoch 870/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.6163 - val_loss: 0.6162 - val_accuracy: 0.5885\n",
            "Epoch 871/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.6233 - val_loss: 0.6160 - val_accuracy: 0.5781\n",
            "Epoch 872/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.6215 - val_loss: 0.6163 - val_accuracy: 0.5938\n",
            "Epoch 873/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6233 - val_loss: 0.6164 - val_accuracy: 0.5938\n",
            "Epoch 874/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6233 - val_loss: 0.6162 - val_accuracy: 0.5833\n",
            "Epoch 875/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.6198 - val_loss: 0.6162 - val_accuracy: 0.5833\n",
            "Epoch 876/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6215 - val_loss: 0.6167 - val_accuracy: 0.5938\n",
            "Epoch 877/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.6233 - val_loss: 0.6166 - val_accuracy: 0.5938\n",
            "Epoch 878/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6215 - val_loss: 0.6164 - val_accuracy: 0.5938\n",
            "Epoch 879/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.6233 - val_loss: 0.6165 - val_accuracy: 0.5938\n",
            "Epoch 880/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.6198 - val_loss: 0.6164 - val_accuracy: 0.5938\n",
            "Epoch 881/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.6181 - val_loss: 0.6164 - val_accuracy: 0.5938\n",
            "Epoch 882/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.6181 - val_loss: 0.6161 - val_accuracy: 0.5885\n",
            "Epoch 883/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.6267 - val_loss: 0.6155 - val_accuracy: 0.5885\n",
            "Epoch 884/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.6181 - val_loss: 0.6161 - val_accuracy: 0.5938\n",
            "Epoch 885/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.6233 - val_loss: 0.6162 - val_accuracy: 0.5938\n",
            "Epoch 886/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6181 - val_loss: 0.6161 - val_accuracy: 0.5938\n",
            "Epoch 887/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6215 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 888/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6215 - val_loss: 0.6162 - val_accuracy: 0.5938\n",
            "Epoch 889/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.6181 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 890/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.6198 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 891/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6215 - val_loss: 0.6156 - val_accuracy: 0.5833\n",
            "Epoch 892/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6181 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 893/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.6198 - val_loss: 0.6161 - val_accuracy: 0.5938\n",
            "Epoch 894/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6233 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 895/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.6233 - val_loss: 0.6158 - val_accuracy: 0.5885\n",
            "Epoch 896/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.6233 - val_loss: 0.6161 - val_accuracy: 0.5885\n",
            "Epoch 897/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.6267 - val_loss: 0.6156 - val_accuracy: 0.5938\n",
            "Epoch 898/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6198 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 899/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6146 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 900/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.6215 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 901/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6250 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 902/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6198 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 903/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6181 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 904/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6198 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 905/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4446 - accuracy: 0.6198 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 906/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.6250 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 907/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.6250 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 908/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.6198 - val_loss: 0.6160 - val_accuracy: 0.5938\n",
            "Epoch 909/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.6198 - val_loss: 0.6159 - val_accuracy: 0.5938\n",
            "Epoch 910/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.6233 - val_loss: 0.6157 - val_accuracy: 0.5938\n",
            "Epoch 911/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6181 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 912/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6198 - val_loss: 0.6157 - val_accuracy: 0.5938\n",
            "Epoch 913/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.6233 - val_loss: 0.6158 - val_accuracy: 0.5885\n",
            "Epoch 914/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.6215 - val_loss: 0.6156 - val_accuracy: 0.5885\n",
            "Epoch 915/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6233 - val_loss: 0.6153 - val_accuracy: 0.5833\n",
            "Epoch 916/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.6198 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 917/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.6250 - val_loss: 0.6158 - val_accuracy: 0.5938\n",
            "Epoch 918/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.6198 - val_loss: 0.6158 - val_accuracy: 0.5833\n",
            "Epoch 919/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6163 - val_loss: 0.6158 - val_accuracy: 0.5833\n",
            "Epoch 920/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6146 - val_loss: 0.6157 - val_accuracy: 0.5833\n",
            "Epoch 921/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5833\n",
            "Epoch 922/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6215 - val_loss: 0.6156 - val_accuracy: 0.5833\n",
            "Epoch 923/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6215 - val_loss: 0.6158 - val_accuracy: 0.5833\n",
            "Epoch 924/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6198 - val_loss: 0.6155 - val_accuracy: 0.5885\n",
            "Epoch 925/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6233 - val_loss: 0.6154 - val_accuracy: 0.5938\n",
            "Epoch 926/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.6163 - val_loss: 0.6153 - val_accuracy: 0.5938\n",
            "Epoch 927/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6233 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 928/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.6181 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 929/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 930/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.6233 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 931/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6146 - val_loss: 0.6153 - val_accuracy: 0.5938\n",
            "Epoch 932/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5833\n",
            "Epoch 933/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6163 - val_loss: 0.6153 - val_accuracy: 0.5885\n",
            "Epoch 934/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6233 - val_loss: 0.6156 - val_accuracy: 0.5885\n",
            "Epoch 935/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.6215 - val_loss: 0.6157 - val_accuracy: 0.5833\n",
            "Epoch 936/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.6250 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 937/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6250 - val_loss: 0.6153 - val_accuracy: 0.5833\n",
            "Epoch 938/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6163 - val_loss: 0.6153 - val_accuracy: 0.5938\n",
            "Epoch 939/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5833\n",
            "Epoch 940/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5833\n",
            "Epoch 941/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6163 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 942/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.6215 - val_loss: 0.6154 - val_accuracy: 0.5833\n",
            "Epoch 943/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6198 - val_loss: 0.6156 - val_accuracy: 0.5885\n",
            "Epoch 944/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.6198 - val_loss: 0.6155 - val_accuracy: 0.5833\n",
            "Epoch 945/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6233 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 946/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.6215 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 947/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.6146 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 948/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.6198 - val_loss: 0.6155 - val_accuracy: 0.5885\n",
            "Epoch 949/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.6233 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 950/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6198 - val_loss: 0.6154 - val_accuracy: 0.5885\n",
            "Epoch 951/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.6215 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 952/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.6198 - val_loss: 0.6149 - val_accuracy: 0.5938\n",
            "Epoch 953/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.6146 - val_loss: 0.6153 - val_accuracy: 0.5885\n",
            "Epoch 954/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.6215 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 955/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.6181 - val_loss: 0.6151 - val_accuracy: 0.5885\n",
            "Epoch 956/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.6215 - val_loss: 0.6151 - val_accuracy: 0.5885\n",
            "Epoch 957/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4436 - accuracy: 0.6198 - val_loss: 0.6150 - val_accuracy: 0.5885\n",
            "Epoch 958/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.6233 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 959/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4436 - accuracy: 0.6181 - val_loss: 0.6150 - val_accuracy: 0.5833\n",
            "Epoch 960/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.6163 - val_loss: 0.6150 - val_accuracy: 0.5885\n",
            "Epoch 961/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.6233 - val_loss: 0.6151 - val_accuracy: 0.5885\n",
            "Epoch 962/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.6128 - val_loss: 0.6149 - val_accuracy: 0.5885\n",
            "Epoch 963/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.6163 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 964/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.6233 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 965/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.6181 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 966/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.6215 - val_loss: 0.6150 - val_accuracy: 0.5833\n",
            "Epoch 967/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4438 - accuracy: 0.6163 - val_loss: 0.6153 - val_accuracy: 0.5833\n",
            "Epoch 968/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4436 - accuracy: 0.6215 - val_loss: 0.6149 - val_accuracy: 0.5781\n",
            "Epoch 969/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.6146 - val_loss: 0.6149 - val_accuracy: 0.5938\n",
            "Epoch 970/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.6198 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 971/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.6163 - val_loss: 0.6153 - val_accuracy: 0.5938\n",
            "Epoch 972/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.6267 - val_loss: 0.6149 - val_accuracy: 0.5885\n",
            "Epoch 973/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.6233 - val_loss: 0.6149 - val_accuracy: 0.5833\n",
            "Epoch 974/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.6198 - val_loss: 0.6150 - val_accuracy: 0.5833\n",
            "Epoch 975/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4434 - accuracy: 0.6146 - val_loss: 0.6150 - val_accuracy: 0.5938\n",
            "Epoch 976/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.6233 - val_loss: 0.6150 - val_accuracy: 0.5885\n",
            "Epoch 977/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4435 - accuracy: 0.6215 - val_loss: 0.6150 - val_accuracy: 0.5833\n",
            "Epoch 978/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.6198 - val_loss: 0.6151 - val_accuracy: 0.5833\n",
            "Epoch 979/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.6163 - val_loss: 0.6152 - val_accuracy: 0.5833\n",
            "Epoch 980/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.6163 - val_loss: 0.6149 - val_accuracy: 0.5833\n",
            "Epoch 981/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4435 - accuracy: 0.6215 - val_loss: 0.6148 - val_accuracy: 0.5833\n",
            "Epoch 982/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4434 - accuracy: 0.6163 - val_loss: 0.6150 - val_accuracy: 0.5885\n",
            "Epoch 983/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.6198 - val_loss: 0.6146 - val_accuracy: 0.5938\n",
            "Epoch 984/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6146 - val_loss: 0.6148 - val_accuracy: 0.5938\n",
            "Epoch 985/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.6181 - val_loss: 0.6147 - val_accuracy: 0.5938\n",
            "Epoch 986/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6215 - val_loss: 0.6147 - val_accuracy: 0.5833\n",
            "Epoch 987/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.6198 - val_loss: 0.6146 - val_accuracy: 0.5833\n",
            "Epoch 988/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6146 - val_loss: 0.6147 - val_accuracy: 0.5885\n",
            "Epoch 989/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.6181 - val_loss: 0.6148 - val_accuracy: 0.5833\n",
            "Epoch 990/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.6128 - val_loss: 0.6147 - val_accuracy: 0.5833\n",
            "Epoch 991/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.6128 - val_loss: 0.6147 - val_accuracy: 0.5885\n",
            "Epoch 992/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6163 - val_loss: 0.6149 - val_accuracy: 0.5833\n",
            "Epoch 993/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.6285 - val_loss: 0.6147 - val_accuracy: 0.5885\n",
            "Epoch 994/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6181 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 995/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.6128 - val_loss: 0.6146 - val_accuracy: 0.5833\n",
            "Epoch 996/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.6146 - val_loss: 0.6148 - val_accuracy: 0.5833\n",
            "Epoch 997/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.6076 - val_loss: 0.6146 - val_accuracy: 0.5938\n",
            "Epoch 998/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.6163 - val_loss: 0.6148 - val_accuracy: 0.5885\n",
            "Epoch 999/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.6233 - val_loss: 0.6148 - val_accuracy: 0.5833\n",
            "Epoch 1000/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.6111 - val_loss: 0.6148 - val_accuracy: 0.5833\n",
            "Epoch 1001/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.6181 - val_loss: 0.6147 - val_accuracy: 0.5833\n",
            "Epoch 1002/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.6163 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1003/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.6163 - val_loss: 0.6147 - val_accuracy: 0.5885\n",
            "Epoch 1004/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6181 - val_loss: 0.6147 - val_accuracy: 0.5833\n",
            "Epoch 1005/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6163 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1006/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6215 - val_loss: 0.6145 - val_accuracy: 0.5833\n",
            "Epoch 1007/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.6146 - val_loss: 0.6145 - val_accuracy: 0.5833\n",
            "Epoch 1008/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.6233 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1009/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.6146 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1010/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.6111 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1011/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.6215 - val_loss: 0.6147 - val_accuracy: 0.5833\n",
            "Epoch 1012/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.6181 - val_loss: 0.6147 - val_accuracy: 0.5885\n",
            "Epoch 1013/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.6163 - val_loss: 0.6147 - val_accuracy: 0.5938\n",
            "Epoch 1014/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6111 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1015/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.6146 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1016/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.6128 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1017/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6163 - val_loss: 0.6145 - val_accuracy: 0.5833\n",
            "Epoch 1018/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.6233 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1019/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.6094 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1020/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.6128 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1021/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4428 - accuracy: 0.6128 - val_loss: 0.6146 - val_accuracy: 0.5885\n",
            "Epoch 1022/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.6181 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1023/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6250 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1024/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.6181 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1025/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.6181 - val_loss: 0.6142 - val_accuracy: 0.5885\n",
            "Epoch 1026/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6198 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1027/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.6128 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1028/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6146 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1029/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.6146 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1030/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.6111 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1031/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.6128 - val_loss: 0.6145 - val_accuracy: 0.5885\n",
            "Epoch 1032/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.6181 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1033/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.6163 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1034/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.6128 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1035/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6163 - val_loss: 0.6144 - val_accuracy: 0.5938\n",
            "Epoch 1036/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6215 - val_loss: 0.6144 - val_accuracy: 0.5885\n",
            "Epoch 1037/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6163 - val_loss: 0.6142 - val_accuracy: 0.5938\n",
            "Epoch 1038/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6181 - val_loss: 0.6144 - val_accuracy: 0.5833\n",
            "Epoch 1039/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.6146 - val_loss: 0.6143 - val_accuracy: 0.5885\n",
            "Epoch 1040/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6198 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 1041/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.6163 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 1042/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.6111 - val_loss: 0.6142 - val_accuracy: 0.5938\n",
            "Epoch 1043/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.6146 - val_loss: 0.6140 - val_accuracy: 0.5938\n",
            "Epoch 1044/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6181 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 1045/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6163 - val_loss: 0.6142 - val_accuracy: 0.5885\n",
            "Epoch 1046/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.6163 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 1047/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.6094 - val_loss: 0.6142 - val_accuracy: 0.5885\n",
            "Epoch 1048/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.6233 - val_loss: 0.6141 - val_accuracy: 0.5833\n",
            "Epoch 1049/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6128 - val_loss: 0.6142 - val_accuracy: 0.5938\n",
            "Epoch 1050/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6181 - val_loss: 0.6141 - val_accuracy: 0.5833\n",
            "Epoch 1051/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.6198 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1052/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.6146 - val_loss: 0.6140 - val_accuracy: 0.5833\n",
            "Epoch 1053/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6146 - val_loss: 0.6141 - val_accuracy: 0.5833\n",
            "Epoch 1054/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6111 - val_loss: 0.6139 - val_accuracy: 0.5833\n",
            "Epoch 1055/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.6111 - val_loss: 0.6140 - val_accuracy: 0.5833\n",
            "Epoch 1056/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.6146 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1057/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.6181 - val_loss: 0.6141 - val_accuracy: 0.5833\n",
            "Epoch 1058/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.6181 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1059/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.6146 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1060/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.6146 - val_loss: 0.6138 - val_accuracy: 0.5781\n",
            "Epoch 1061/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4425 - accuracy: 0.6198 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1062/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.6076 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1063/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.6163 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1064/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.6128 - val_loss: 0.6139 - val_accuracy: 0.5885\n",
            "Epoch 1065/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.6128 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1066/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6128 - val_loss: 0.6140 - val_accuracy: 0.5885\n",
            "Epoch 1067/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.6181 - val_loss: 0.6139 - val_accuracy: 0.5938\n",
            "Epoch 1068/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6181 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1069/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.6111 - val_loss: 0.6139 - val_accuracy: 0.5938\n",
            "Epoch 1070/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6198 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1071/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.6163 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1072/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.6181 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1073/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6128 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1074/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.6128 - val_loss: 0.6140 - val_accuracy: 0.5938\n",
            "Epoch 1075/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.6181 - val_loss: 0.6142 - val_accuracy: 0.5833\n",
            "Epoch 1076/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.6163 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1077/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.6198 - val_loss: 0.6139 - val_accuracy: 0.5885\n",
            "Epoch 1078/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6163 - val_loss: 0.6140 - val_accuracy: 0.5885\n",
            "Epoch 1079/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.6181 - val_loss: 0.6140 - val_accuracy: 0.5885\n",
            "Epoch 1080/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.6198 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1081/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.6250 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1082/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.6163 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1083/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.6163 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1084/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.6163 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1085/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.6146 - val_loss: 0.6140 - val_accuracy: 0.5885\n",
            "Epoch 1086/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.6198 - val_loss: 0.6139 - val_accuracy: 0.5885\n",
            "Epoch 1087/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.6250 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1088/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.6111 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1089/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.6163 - val_loss: 0.6141 - val_accuracy: 0.5781\n",
            "Epoch 1090/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.6198 - val_loss: 0.6140 - val_accuracy: 0.5781\n",
            "Epoch 1091/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.6181 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1092/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.6163 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1093/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.6111 - val_loss: 0.6138 - val_accuracy: 0.5781\n",
            "Epoch 1094/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6111 - val_loss: 0.6138 - val_accuracy: 0.5833\n",
            "Epoch 1095/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6146 - val_loss: 0.6139 - val_accuracy: 0.5833\n",
            "Epoch 1096/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.6146 - val_loss: 0.6138 - val_accuracy: 0.5885\n",
            "Epoch 1097/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.6198 - val_loss: 0.6139 - val_accuracy: 0.5833\n",
            "Epoch 1098/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.6198 - val_loss: 0.6138 - val_accuracy: 0.5885\n",
            "Epoch 1099/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4421 - accuracy: 0.6198 - val_loss: 0.6140 - val_accuracy: 0.5833\n",
            "Epoch 1100/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4420 - accuracy: 0.6181 - val_loss: 0.6139 - val_accuracy: 0.5885\n",
            "Epoch 1101/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.6198 - val_loss: 0.6137 - val_accuracy: 0.5833\n",
            "Epoch 1102/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6181 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1103/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.6111 - val_loss: 0.6138 - val_accuracy: 0.5781\n",
            "Epoch 1104/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.6128 - val_loss: 0.6138 - val_accuracy: 0.5833\n",
            "Epoch 1105/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6128 - val_loss: 0.6138 - val_accuracy: 0.5833\n",
            "Epoch 1106/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.6111 - val_loss: 0.6141 - val_accuracy: 0.5833\n",
            "Epoch 1107/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.6181 - val_loss: 0.6140 - val_accuracy: 0.5833\n",
            "Epoch 1108/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.6163 - val_loss: 0.6138 - val_accuracy: 0.5833\n",
            "Epoch 1109/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.6163 - val_loss: 0.6137 - val_accuracy: 0.5833\n",
            "Epoch 1110/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.6215 - val_loss: 0.6138 - val_accuracy: 0.5833\n",
            "Epoch 1111/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6181 - val_loss: 0.6139 - val_accuracy: 0.5781\n",
            "Epoch 1112/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.6128 - val_loss: 0.6137 - val_accuracy: 0.5833\n",
            "Epoch 1113/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4417 - accuracy: 0.6163 - val_loss: 0.6137 - val_accuracy: 0.5833\n",
            "Epoch 1114/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.6146 - val_loss: 0.6137 - val_accuracy: 0.5833\n",
            "Epoch 1115/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4419 - accuracy: 0.6215 - val_loss: 0.6135 - val_accuracy: 0.5833\n",
            "Epoch 1116/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.6181 - val_loss: 0.6136 - val_accuracy: 0.5833\n",
            "Epoch 1117/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.6233 - val_loss: 0.6136 - val_accuracy: 0.5833\n",
            "Epoch 1118/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4415 - accuracy: 0.6163 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1119/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4419 - accuracy: 0.6146 - val_loss: 0.6138 - val_accuracy: 0.5781\n",
            "Epoch 1120/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.6163 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1121/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.6181 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1122/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.6163 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1123/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.6198 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1124/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.6146 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1125/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.6215 - val_loss: 0.6135 - val_accuracy: 0.5781\n",
            "Epoch 1126/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.6163 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1127/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.6146 - val_loss: 0.6138 - val_accuracy: 0.5781\n",
            "Epoch 1128/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.6181 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1129/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.6198 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1130/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.6233 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1131/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.6198 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1132/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.6163 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1133/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1134/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.6215 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1135/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.6181 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1136/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.6181 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1137/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1138/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.6233 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1139/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1140/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.6163 - val_loss: 0.6137 - val_accuracy: 0.5729\n",
            "Epoch 1141/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.6163 - val_loss: 0.6137 - val_accuracy: 0.5781\n",
            "Epoch 1142/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.6198 - val_loss: 0.6137 - val_accuracy: 0.5729\n",
            "Epoch 1143/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.6215 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1144/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1145/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.6146 - val_loss: 0.6135 - val_accuracy: 0.5781\n",
            "Epoch 1146/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.6128 - val_loss: 0.6137 - val_accuracy: 0.5729\n",
            "Epoch 1147/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.6198 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1148/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5781\n",
            "Epoch 1149/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.6198 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1150/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4414 - accuracy: 0.6181 - val_loss: 0.6137 - val_accuracy: 0.5729\n",
            "Epoch 1151/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4413 - accuracy: 0.6198 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1152/1500\n",
            "18/18 [==============================] - 0s 19ms/step - loss: 0.4413 - accuracy: 0.6181 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1153/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4412 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1154/1500\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4413 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1155/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.6146 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1156/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.6198 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1157/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.6181 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1158/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.6198 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1159/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.6215 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1160/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6233 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1161/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1162/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1163/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1164/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6181 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1165/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6215 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1166/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1167/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6215 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1168/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.6181 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1169/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1170/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1171/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.6215 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1172/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1173/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1174/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1175/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6181 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1176/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.6146 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1177/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6146 - val_loss: 0.6137 - val_accuracy: 0.5729\n",
            "Epoch 1178/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6146 - val_loss: 0.6136 - val_accuracy: 0.5729\n",
            "Epoch 1179/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.6128 - val_loss: 0.6136 - val_accuracy: 0.5833\n",
            "Epoch 1180/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6181 - val_loss: 0.6134 - val_accuracy: 0.5833\n",
            "Epoch 1181/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.6215 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1182/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5833\n",
            "Epoch 1183/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6233 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1184/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6181 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1185/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.6181 - val_loss: 0.6135 - val_accuracy: 0.5729\n",
            "Epoch 1186/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1187/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1188/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1189/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.6128 - val_loss: 0.6134 - val_accuracy: 0.5729\n",
            "Epoch 1190/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1191/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.6198 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1192/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1193/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1194/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6146 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1195/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6146 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1196/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1197/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1198/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.6198 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1199/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1200/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.6233 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1201/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1202/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.6146 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1203/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1204/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6215 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1205/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6128 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1206/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1207/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.6181 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1208/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.6163 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1209/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1210/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1211/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1212/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1213/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.6163 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1214/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.6128 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1215/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.6198 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1216/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1217/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.6163 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1218/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.6163 - val_loss: 0.6131 - val_accuracy: 0.5729\n",
            "Epoch 1219/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1220/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1221/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.6163 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1222/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.6181 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1223/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1224/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4406 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1225/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1226/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.6198 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1227/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4403 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1228/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.6128 - val_loss: 0.6133 - val_accuracy: 0.5833\n",
            "Epoch 1229/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5833\n",
            "Epoch 1230/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.6181 - val_loss: 0.6133 - val_accuracy: 0.5833\n",
            "Epoch 1231/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1232/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1233/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.6146 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1234/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1235/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.6111 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1236/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1237/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.6128 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1238/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4402 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1239/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.6146 - val_loss: 0.6134 - val_accuracy: 0.5781\n",
            "Epoch 1240/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1241/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4401 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1242/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6163 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1243/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.6111 - val_loss: 0.6133 - val_accuracy: 0.5833\n",
            "Epoch 1244/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1245/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.6128 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1246/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.6146 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1247/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.6181 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1248/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1249/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1250/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1251/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1252/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6181 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1253/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1254/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.6163 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1255/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.6181 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1256/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1257/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.6181 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1258/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1259/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.6163 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1260/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1261/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1262/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4401 - accuracy: 0.6128 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1263/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6163 - val_loss: 0.6133 - val_accuracy: 0.5781\n",
            "Epoch 1264/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6198 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1265/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1266/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6146 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1267/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6059 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1268/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.6094 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1269/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1270/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1271/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6163 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1272/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6059 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1273/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.6076 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1274/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6111 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1275/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.6111 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1276/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1277/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6128 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1278/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.6111 - val_loss: 0.6133 - val_accuracy: 0.5833\n",
            "Epoch 1279/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6094 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1280/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.6111 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1281/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.6076 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1282/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1283/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1284/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6076 - val_loss: 0.6132 - val_accuracy: 0.5781\n",
            "Epoch 1285/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1286/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6059 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1287/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6111 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1288/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6094 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1289/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4396 - accuracy: 0.6111 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1290/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4398 - accuracy: 0.6111 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1291/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1292/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1293/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4399 - accuracy: 0.6094 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1294/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1295/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6094 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1296/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1297/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6111 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1298/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1299/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6094 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1300/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1301/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6076 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1302/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1303/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.6059 - val_loss: 0.6129 - val_accuracy: 0.5833\n",
            "Epoch 1304/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6111 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1305/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6042 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1306/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1307/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6024 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1308/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6007 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1309/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.6076 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1310/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4396 - accuracy: 0.6094 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1311/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6007 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1312/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4394 - accuracy: 0.6024 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1313/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1314/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1315/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6076 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1316/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.6059 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1317/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.6076 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1318/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1319/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6024 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1320/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.5990 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1321/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1322/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1323/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1324/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1325/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5781\n",
            "Epoch 1326/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1327/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6042 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1328/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1329/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6094 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1330/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4394 - accuracy: 0.6059 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1331/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4397 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1332/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4395 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5833\n",
            "Epoch 1333/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1334/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1335/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6007 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1336/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1337/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5833\n",
            "Epoch 1338/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4393 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1339/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1340/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6007 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1341/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6042 - val_loss: 0.6131 - val_accuracy: 0.5833\n",
            "Epoch 1342/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6042 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1343/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.6007 - val_loss: 0.6132 - val_accuracy: 0.5833\n",
            "Epoch 1344/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.6042 - val_loss: 0.6132 - val_accuracy: 0.5729\n",
            "Epoch 1345/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6042 - val_loss: 0.6133 - val_accuracy: 0.5729\n",
            "Epoch 1346/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.6007 - val_loss: 0.6132 - val_accuracy: 0.5729\n",
            "Epoch 1347/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4392 - accuracy: 0.6007 - val_loss: 0.6131 - val_accuracy: 0.5729\n",
            "Epoch 1348/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1349/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4394 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5833\n",
            "Epoch 1350/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4391 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1351/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1352/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4392 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1353/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1354/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1355/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.6059 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1356/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1357/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1358/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4388 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1359/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1360/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4389 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5833\n",
            "Epoch 1361/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4389 - accuracy: 0.6024 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1362/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1363/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4389 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1364/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4390 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1365/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1366/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4389 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1367/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1368/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4388 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1369/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4392 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1370/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4386 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1371/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4390 - accuracy: 0.5955 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1372/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4387 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1373/1500\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4386 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1374/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4388 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1375/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4387 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1376/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.6007 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1377/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4387 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1378/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1379/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1380/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1381/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1382/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1383/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.6024 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1384/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1385/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1386/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.6042 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1387/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1388/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1389/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1390/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.6024 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1391/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1392/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1393/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1394/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1395/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1396/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.5990 - val_loss: 0.6131 - val_accuracy: 0.5729\n",
            "Epoch 1397/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1398/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4384 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1399/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4386 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1400/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1401/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1402/1500\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.4382 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1403/1500\n",
            "18/18 [==============================] - 0s 22ms/step - loss: 0.4383 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1404/1500\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.4383 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1405/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1406/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1407/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1408/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1409/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1410/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1411/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1412/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1413/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1414/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4382 - accuracy: 0.6007 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1415/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4387 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1416/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.5938 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1417/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1418/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1419/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1420/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1421/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1422/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1423/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1424/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1425/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.6007 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1426/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.6007 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1427/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1428/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1429/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1430/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5990 - val_loss: 0.6131 - val_accuracy: 0.5729\n",
            "Epoch 1431/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1432/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1433/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1434/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1435/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1436/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1437/1500\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1438/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1439/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1440/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1441/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1442/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1443/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.5938 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1444/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1445/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1446/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1447/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4383 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1448/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.5955 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1449/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4382 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1450/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1451/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1452/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4379 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1453/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1454/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1455/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1456/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1457/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1458/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1459/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1460/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.5972 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1461/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1462/1500\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.4380 - accuracy: 0.5990 - val_loss: 0.6130 - val_accuracy: 0.5729\n",
            "Epoch 1463/1500\n",
            "18/18 [==============================] - 0s 25ms/step - loss: 0.4378 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1464/1500\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.4379 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1465/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4377 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1466/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1467/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.5938 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1468/1500\n",
            "18/18 [==============================] - 0s 24ms/step - loss: 0.4376 - accuracy: 0.5955 - val_loss: 0.6130 - val_accuracy: 0.5677\n",
            "Epoch 1469/1500\n",
            "18/18 [==============================] - 1s 33ms/step - loss: 0.4378 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1470/1500\n",
            "18/18 [==============================] - 0s 18ms/step - loss: 0.4375 - accuracy: 0.6007 - val_loss: 0.6130 - val_accuracy: 0.5573\n",
            "Epoch 1471/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.5938 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1472/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.6024 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1473/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.5972 - val_loss: 0.6128 - val_accuracy: 0.5781\n",
            "Epoch 1474/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.6007 - val_loss: 0.6127 - val_accuracy: 0.5781\n",
            "Epoch 1475/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.6024 - val_loss: 0.6128 - val_accuracy: 0.5677\n",
            "Epoch 1476/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5625\n",
            "Epoch 1477/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4375 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1478/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4377 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1479/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1480/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.5938 - val_loss: 0.6130 - val_accuracy: 0.5625\n",
            "Epoch 1481/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4376 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5677\n",
            "Epoch 1482/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4375 - accuracy: 0.5955 - val_loss: 0.6130 - val_accuracy: 0.5625\n",
            "Epoch 1483/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4376 - accuracy: 0.5920 - val_loss: 0.6132 - val_accuracy: 0.5625\n",
            "Epoch 1484/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4374 - accuracy: 0.5955 - val_loss: 0.6131 - val_accuracy: 0.5625\n",
            "Epoch 1485/1500\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4375 - accuracy: 0.5920 - val_loss: 0.6130 - val_accuracy: 0.5781\n",
            "Epoch 1486/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5781\n",
            "Epoch 1487/1500\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4376 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1488/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1489/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.6024 - val_loss: 0.6129 - val_accuracy: 0.5729\n",
            "Epoch 1490/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.6007 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1491/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1492/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4376 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5625\n",
            "Epoch 1493/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5625\n",
            "Epoch 1494/1500\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4378 - accuracy: 0.5990 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1495/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.5955 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1496/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4374 - accuracy: 0.5972 - val_loss: 0.6129 - val_accuracy: 0.5625\n",
            "Epoch 1497/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5729\n",
            "Epoch 1498/1500\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.6007 - val_loss: 0.6128 - val_accuracy: 0.5625\n",
            "Epoch 1499/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4373 - accuracy: 0.5955 - val_loss: 0.6128 - val_accuracy: 0.5625\n",
            "Epoch 1500/1500\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.5990 - val_loss: 0.6128 - val_accuracy: 0.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "8DEpD0_2CxKt",
        "outputId": "e189e1e4-5166-47d7-ce12-304713f190d1"
      },
      "id": "8DEpD0_2CxKt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3f3f3053c0>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This graph is optimal because the train data is too perfect for the dataset, However the validation loss shows a messy graph. This may be caused by the huge amount of epoch used in the diabetes data."
      ],
      "metadata": {
        "id": "lyFK5PVnJg4O"
      },
      "id": "lyFK5PVnJg4O"
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the roc curve for the predictions\n",
        "\n",
        "print('accuracy is {:.3f}'.format(accuracy_score(y_test,Rf.predict(X_test))))\n",
        "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,Rf.predict_proba(X_test)[:,1])))\n",
        "\n",
        "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "BGXKPf5IE7_I",
        "outputId": "95b3e61b-bd17-48f6-b719-f5c9b1d273b7"
      },
      "id": "BGXKPf5IE7_I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy is 0.771\n",
            "roc-auc is 0.836\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqQAAAKqCAYAAADsTEzZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABuhklEQVR4nO3de3zP9f//8fs2O3iPmTJzSDl0QPqkiI/Ghwqr5JNPyRxySih0WiWnCGlKpINjYRWzyUelEhb5lCjlUCrkmIQhh7HZ9t72/P3Rd++f2cGO79f7cLteLrvU++X1er8e2/P93u57PF+v53yMMUYAAACARXytLgAAAADejUAKAAAASxFIAQAAYCkCKQAAACxFIAUAAIClCKQAAACwFIEUAAAAliKQAgAAwFIEUgAAAFiKQAqgQFOmTFH9+vXl5+enpk2bWl0OXEi/fv1Ut27dXNt8fHz0wgsvFPu5YmNj5ePjox9++KFsivMi7dq1U5MmTS6534EDB+Tj46PY2NjyLwooAQIpXFbOD6mcjwoVKqh27drq16+f/vzzz3yPMcbo/fff17/+9S+FhobKZrPphhtu0IQJE5SSklLguT788EPdddddqlatmgICAlSrVi1169ZNa9euLVKtaWlpeu2119SyZUtVqVJFQUFBuvbaazVs2DD99ttvJfr8rbZ69WoNHz5cERERWrBggV566aVyPV+/fv3k4+Ojf/zjH8rvLxr7+Pho2LBhjsc5P2B9fHz03//+N8/+L7zwgnx8fHTixIlyrbuocurJ+bDZbGrcuLHGjBmj5ORkx375hbOcY319ffXHH3/kee7k5GRVrFgxz9foQjt27JCPj4+CgoJ0+vTpMv/8XM2KFStKFI4BWKOC1QUAlzJhwgTVq1dPaWlp+vbbbxUbG6v169fr559/VlBQkGO/rKws9ezZU0uWLFGbNm30wgsvyGaz6euvv9b48eP1wQcf6IsvvlB4eLjjGGOMHnroIcXGxuqmm25SdHS0atSooSNHjujDDz/UHXfcoW+++Ua33nprgfWdOHFCd955pzZv3qx77rlHPXv2VKVKlbRr1y7Fx8dr7ty5ysjIKNevUXlYu3atfH19NW/ePAUEBDjtvNu3b9eyZct0//33F/mYCRMm6L777pOPj085VlY2Zs2apUqVKuncuXNavXq1Jk2apLVr1+qbb765ZP2BgYFavHixhg8fnmv7smXLLnnehQsXqkaNGjp16pSWLl2qhx9+uFSfR37Onz+vChVc48fKihUrNGPGDEIp4CZc4zsHUIi77rpLzZs3lyQ9/PDDqlatml5++WUtX75c3bp1c+z3yiuvaMmSJXrmmWc0ZcoUx/ZBgwapW7du6tKli/r166fPP//c8W9Tp05VbGysnnzySU2bNi1XIBg9erTef//9S/6A7devn7Zu3aqlS5fmCVETJ07U6NGjS/X558jMzFR2drbTwuGxY8dUsWLFMjufMUZpaWmqWLFigftUrFhRderUKVbAbNq0qbZt26YPP/xQ9913X5nUWp66du2qatWqSZIeeeQR3X///Vq2bJm+/fZbtWrVqtBj77777nwDaVxcnDp16pRvp1j6+2sfFxennj17av/+/Vq0aFG5BNILf0FEyaSkpCg4ONjqMgCnY8oebqdNmzaSpL179zq2nT9/XlOmTNG1116rmJiYPMd07txZffv21cqVK/Xtt986jomJiVHDhg316quv5ht+evfurRYtWhRYy3fffafPPvtMAwYMyLejFxgYqFdffdXxuF27dmrXrl2e/S6+Hi9nOvrVV1/V9OnT1aBBAwUGBmrr1q2qUKGCxo8fn+c5du3aJR8fH7311luObadPn9aTTz6pOnXqKDAwUFdffbVefvllZWdnF/g5SX9Pjy9YsEApKSmOKeaca88yMzM1ceJER01169bVqFGjlJ6enus56tatq3vuuUerVq1S8+bNVbFiRc2ZM6fQ8/r6+mrMmDH66aef9OGHHxa6b47u3bvr2muv1YQJE/Kd6i+KrVu36q677lJISIgqVaqkO+64w/E6yZEzlf7NN98oOjpaYWFhCg4O1n/+8x8dP368ROeVpNtvv12StH///kvu27NnT23btk07d+50bDt69KjWrl2rnj17FnjcN998owMHDqh79+7q3r27vvrqKx06dKjINX700Udq0qSJgoKC1KRJkwLH5uJrSH///XcNGTJE1113nSpWrKjLL79cDzzwgA4cOJDv8ampqRo8eLAuv/xyhYSEqE+fPjp16lSe/T7//HO1adNGwcHBqly5sjp16qRffvnF8e/9+vXTjBkzHDXlfOTIzs7W9OnTdf311ysoKEjh4eEaPHhwnnP98MMPioyMVLVq1VSxYkXVq1dPDz300CW/Xjmv/dWrV6tp06YKCgpS48aN83Syc15T//vf/zRkyBBVr15dV1xxhePfZ86cqeuvv16BgYGqVauWhg4dWuDlFps3b9att97qqHP27NmXrFOSdu7cqa5du+qyyy5TUFCQmjdvruXLl+db5/r16/X4448rLCxMoaGhGjx4sDIyMnT69Gn16dNHVatWVdWqVTV8+PASvxfhvQikcDs5P8yqVq3q2LZ+/XqdOnVKPXv2LLCj2adPH0nSp59+6jjm5MmT6tmzp/z8/EpUS8437t69e5fo+EtZsGCB3nzzTQ0aNEhTp05VzZo11bZtWy1ZsiTPvgkJCfLz89MDDzwg6e8f7m3bttXChQvVp08fvfHGG4qIiNDIkSMVHR1d6Hnff/99tWnTRoGBgXr//fcd1+VKf3epx44dq5tvvlmvvfaa2rZtq5iYGHXv3j3P8+zatUs9evRQhw4d9PrrrxfpxqiePXvqmmuuKXLA9PPz05gxY/Tjjz8WOcRe6JdfflGbNm30448/avjw4Xr++ee1f/9+tWvXTt99912e/R977DH9+OOPGjdunB599FF98sknBV63WRQ5v1hdfvnll9z3X//6l6644grFxcU5tiUkJKhSpUrq1KlTgcctWrRIDRo00C233KLOnTvLZrNp8eLFRapv9erVuv/+++Xj46OYmBh16dJF/fv3L9INSN9//702bNig7t2764033tAjjzyiNWvWqF27dkpNTc2z/7Bhw7Rjxw698MIL6tOnjxYtWqQuXbrkeh28//776tSpkypVqqSXX35Zzz//vH799Ve1bt3a8b1h8ODB6tChg2P/nI8cgwcP1rPPPquIiAi9/vrr6t+/vxYtWqTIyEjZ7XZJf88QdOzYUQcOHNCIESP05ptvqlevXnl+USnI7t27FRUVpbvuuksxMTGqUKGCHnjgASUmJubZd8iQIfr11181duxYjRgxQtLf1w0PHTpUtWrV0tSpU3X//fdrzpw56tixo6PGHKdOndLdd9+tZs2a6ZVXXtEVV1yhRx99VPPnzy+0xl9++UX//Oc/tWPHDo0YMUJTp05VcHCwunTpku976bHHHtPu3bs1fvx4/fvf/9bcuXP1/PPPq3PnzsrKytJLL72k1q1ba8qUKbm+3kCRGMBFLViwwEgyX3zxhTl+/Lj5448/zNKlS01YWJgJDAw0f/zxh2Pf6dOnG0nmww8/LPD5Tp48aSSZ++67zxhjzOuvv37JYy7lP//5j5FkTp06VaT927Zta9q2bZtne9++fc1VV13leLx//34jyYSEhJhjx47l2nfOnDlGktm+fXuu7Y0bNza333674/HEiRNNcHCw+e2333LtN2LECOPn52cOHjxYaK19+/Y1wcHBubZt27bNSDIPP/xwru3PPPOMkWTWrl3r2HbVVVcZSWblypWFnie/87377rtGklm2bJnj3yWZoUOHOh7nfI2mTJliMjMzzTXXXGNuvPFGk52dbYwxZty4cUaSOX78eKHn7dKliwkICDB79+51bDt8+LCpXLmy+de//uXYlvN6bN++veMcxhjz1FNPGT8/P3P69OlCz5NTz65du8zx48fN/v37zZw5c0xgYKAJDw83KSkpuc7z/fff5zn2+PHj5plnnjFXX321499uueUW079//3y/RsYYk5GRYS6//HIzevRox7aePXuaG2+8sdB6czRt2tTUrFkz1+e3evVqIynXazbn/OPGjXM8Tk1NzfN8GzduNJLMe++959iW8zk3a9bMZGRkOLa/8sorRpL5+OOPjTHGnD171oSGhpqBAwfmes6jR4+aKlWq5No+dOhQk9+PuK+//tpIMosWLcq1feXKlbm2f/jhh3nGoahyXvv//e9/HdvOnDljatasaW666aY8n3fr1q1NZmamY/uxY8dMQECA6dixo8nKynJsf+utt4wkM3/+fMe2tm3bGklm6tSpjm3p6emmadOmpnr16o6vZ877ZcGCBY797rjjDnPDDTeYtLQ0x7bs7Gxz6623mmuuuSZPnZGRkble+61atTI+Pj7mkUcecWzLzMw0V1xxRb7f54DC0CGFy2vfvr3CwsJUp04dde3aVcHBwVq+fHmuqa2zZ89KkipXrlzg8+T8W84dzTn/LeyYSymL5yjM/fffr7CwsFzb7rvvPlWoUEEJCQmObT///LN+/fVXRUVFObZ98MEHatOmjapWraoTJ044Ptq3b6+srCx99dVXxa5nxYoVkpSnw/r0009Lkj777LNc2+vVq6fIyMhin6dXr14l7pJ+9NFHRT5PVlaWVq9erS5duqh+/fqO7TVr1lTPnj21fv36XHfAS39fk3zh9G+bNm2UlZWl33//vUjnvO666xQWFqZ69epp8ODBuvrqq/XZZ5/JZrMV6fiePXtqz549+v777x3/LWy6/vPPP9dff/2lHj16OLb16NFDP/74Y65p7vwcOXJE27ZtU9++fVWlShXH9g4dOqhx48aXrPXC64Xtdrv++usvXX311QoNDdWWLVvy7D9o0CD5+/s7Hj/66KOqUKGC43WXmJio06dPq0ePHrle035+fmrZsqW+/PLLS9b0wQcfqEqVKurQoUOu52jWrJkqVarkeI7Q0FBJf8+oXNyRLIpatWrpP//5j+NxziUIW7du1dGjR3PtO3DgwFyzNF988YUyMjL05JNPytfXN9d+ISEhed5nFSpU0ODBgx2PAwICNHjwYB07dkybN2/Ot76TJ09q7dq16tatm86ePev4Ovz111+KjIzU7t2786xmMmDAgFyv/ZYtW8oYowEDBji2+fn5qXnz5tq3b19RvkyAA4EULm/GjBlKTEzU0qVLdffdd+vEiRMKDAzMtU9OIMwJpvm5OLSGhIRc8phLKYvnKEy9evXybKtWrZruuOOOXNP2CQkJqlChQq6benbv3q2VK1cqLCws10f79u0l/T0lWVy///67fH19dfXVV+faXqNGDYWGhuYJZfnVXxQ5AXPbtm1FDpi9evXS1VdfXaxrSY8fP67U1FRdd911ef6tUaNGys7OzrPM0pVXXpnrcc6lI/ld65if//73v0pMTNS6deu0Z88e/fzzz2rWrFmRjpWkm266SQ0bNlRcXJwWLVqkGjVqOK5Dzc/ChQtVr149BQYGas+ePdqzZ48aNGggm82mRYsWFXqunPG85ppr8vxbfl+zi50/f15jx451XMNcrVo1hYWF6fTp0zpz5kye/S8+T6VKlVSzZk3HVPzu3bsl/X3d7cWv69WrVxfpNb17926dOXNG1atXz/Mc586dczxH27Ztdf/992v8+PGqVq2a7r33Xi1YsCDPtdIFufrqq/Ncl37ttddKUp5raC9+n+R83S/+GgcEBKh+/fp53me1atXKcyNUQefKsWfPHhlj9Pzzz+f5OowbN05S3u8RF7/2c35JqVOnTp7tRX0/ADm4yx4ur0WLFo677Lt06aLWrVurZ8+e2rVrlypVqiTp7/AgST/99JO6dOmS7/P89NNPkuTo7DRs2FDS38sMFXTMpVz4HDk3WxXGx8cn37CUlZWV7/4F3ZHevXt39e/fX9u2bVPTpk21ZMkS3XHHHY67t6W/b9zo0KFDnjuyc+T8wCqJoi6vVNgd9ZfSq1cvTZw4URMmTCjS+OSE2H79+unjjz8u8XmLcp78FDUE/+tf/8o1TiXRs2dPzZo1S5UrV1ZUVFSuLtqFkpOT9cknnygtLS3fUBkXF6dJkyaV23JZjz32mBYsWKAnn3xSrVq1UpUqVeTj46Pu3btf8sa6/OQc8/7776tGjRp5/r0oS05lZ2erevXqBYbxnBkJHx8fLV26VN9++60++eQTrVq1Sg899JCmTp2qb7/91vG9pyyU5n1SUjlfy2eeeabAWYyLf/Es6LWf3/aivh+AHARSuBU/Pz/FxMTotttu01tvveW4AaB169YKDQ1VXFycRo8ene83yPfee0+SdM899ziOqVq1qhYvXqxRo0aV6Mamzp07KyYmRgsXLixSIK1atWq+U1lFne7N0aVLFw0ePNgxbf/bb79p5MiRufZp0KCBzp075+iIloWrrrpK2dnZ2r17t+OXAElKSkrS6dOnddVVV5XZuUoSMB988EG9+OKLjpsuLiUsLEw2m027du3K8287d+6Ur69vnu6PK+jZs6fGjh2rI0eOFHrzyLJly5SWlqZZs2blCcG7du3SmDFj9M0336h169b5Hp8znjmdyYuPv5SlS5eqb9++mjp1qmNbWlpagXeK7969W7fddpvj8blz53TkyBHdfffdkv5+TUtS9erVL/m6LihkN2jQQF988YUiIiKKFAT/+c9/6p///KcmTZqkuLg49erVS/Hx8ZdcNiunA3lhHTl/JOPiv3B1sZyv+65du3JdSpKRkaH9+/fn+dwPHz6cZ7moS50r53n9/f3L9HsEUFJM2cPttGvXTi1atND06dOVlpYmSbLZbHrmmWe0a9eufNf9/OyzzxQbG6vIyEj985//dBzz3HPPaceOHXruuefy/Y1+4cKF2rRpU4G1tGrVSnfeeafeeeedfKeWMzIy9MwzzzgeN2jQQDt37sy1TNCPP/6ob775psifv/T39W2RkZFasmSJ4uPjFRAQkKeL2K1bN23cuFGrVq3Kc/zp06eVmZlZrHNKcgSD6dOn59o+bdo0SSr0Tu+SePDBB3X11Vfnu8xVfi6c6r946ZqC9u/YsaM+/vjjXFObSUlJiouLU+vWrR2XZbiSBg0aaPr06YqJiSl0WbKFCxeqfv36euSRR9S1a9dcH88884wqVapU6LR9zZo11bRpU7377ru5ptgTExP166+/XrJOPz+/PO+rN998s8AZgblz5+a6XnPWrFnKzMzUXXfdJUmKjIxUSEiIXnrppXyv67zwfZUTzi4Ov926dVNWVpYmTpyY5/jMzEzH/qdOncpTe84qEUWZtj98+HCuO9WTk5P13nvvqWnTpvl2dy/Uvn17BQQE6I033shVw7x583TmzJk877PMzMxcS6plZGRozpw5CgsLK/BykOrVq6tdu3aaM2eOjhw5kuffS7OUGVASdEjhlp599lk98MADio2N1SOPPCJJGjFihLZu3aqXX35ZGzdu1P3336+KFStq/fr1WrhwoRo1aqR33303z/P88ssvmjp1qr788kt17dpVNWrU0NGjR/XRRx9p06ZN2rBhQ6G1vPfee+rYsaPuu+8+de7cWXfccYeCg4O1e/duxcfH68iRI461SB966CFNmzZNkZGRGjBggI4dO6bZs2fr+uuvz3PzzKVERUXpwQcf1MyZMxUZGem4CePCz2358uW655571K9fPzVr1kwpKSnavn27li5dqgMHDhR76vjGG29U3759NXfuXJ0+fVpt27bVpk2b9O6776pLly65ultlwc/PT6NHj1b//v2LfEzOVP+2bduKtP+LL76oxMREtW7dWkOGDFGFChU0Z84cpaen65VXXilh5eXviSeeKPTfDx8+rC+//FKPP/54vv8eGBioyMhIffDBB3rjjTdy3Ux0oZiYGHXq1EmtW7fWQw89pJMnT+rNN9/U9ddfr3PnzhVawz333KP3339fVapUUePGjbVx40Z98cUXBS5xlZGRoTvuuEPdunXTrl27NHPmTLVu3drR7Q4JCdGsWbPUu3dv3XzzzerevbvCwsJ08OBBffbZZ4qIiHCsw5sTxB5//HFFRkbKz89P3bt3V9u2bTV48GDFxMRo27Zt6tixo/z9/bV792598MEHev3119W1a1e9++67mjlzpv7zn/+oQYMGOnv2rN5++22FhIQ4fjErzLXXXqsBAwbo+++/V3h4uObPn6+kpCQtWLDgkseGhYVp5MiRGj9+vO688079+9//dnw9brnlFj344IO59q9Vq5ZefvllHThwQNdee60SEhK0bds2zZ07t8Bxlf6+Pr9169a64YYbNHDgQNWvX19JSUnauHGjDh06pB9//PGStQJlxpqb+4FLy2/5mxxZWVmmQYMGpkGDBrmWS8nKyjILFiwwERERJiQkxAQFBZnrr7/ejB8/3pw7d67Acy1dutR07NjRXHbZZaZChQqmZs2aJioqyqxbt65ItaampppXX33V3HLLLaZSpUomICDAXHPNNeaxxx4ze/bsybXvwoULTf369U1AQIBp2rSpWbVqVYHLPk2ZMqXAcyYnJ5uKFSsaSWbhwoX57nP27FkzcuRIc/XVV5uAgABTrVo1c+utt5pXX3011/I6+clv2SdjjLHb7Wb8+PGmXr16xt/f39SpU8eMHDky19Ixxvy99E2nTp0KPUdRz9egQYNCl326WM5rR0VY9skYY7Zs2WIiIyNNpUqVjM1mM7fddpvZsGFDvs958evxyy+/NJLMl19+Weg5iroM1aWWfSrMhV+jqVOnGklmzZo1Be4fGxuba1mlgvz3v/81jRo1MoGBgaZx48Zm2bJleV6zOee/cNmnU6dOmf79+5tq1aqZSpUqmcjISLNz505z1VVXmb59++b5nP/3v/+ZQYMGmapVq5pKlSqZXr16mb/++itPPV9++aWJjIw0VapUMUFBQaZBgwamX79+5ocffnDsk5mZaR577DETFhZmfHx88iwBNXfuXNOsWTNTsWJFU7lyZXPDDTeY4cOHm8OHDxtj/n5N9OjRw1x55ZUmMDDQVK9e3dxzzz25zlGQnNf+qlWrzD/+8Q8TGBhoGjZsaD744INc+xX2Pc6Yv5d5atiwofH39zfh4eHm0UcfzbPEXNu2bc31119vfvjhB9OqVSsTFBRkrrrqKvPWW2/l2i+/ZZ+MMWbv3r2mT58+pkaNGsbf39/Url3b3HPPPWbp0qWXrLOg12VB72WgMD7GcOUxAABlpW7dumrSpInjj3AAuDSuIQUAAIClCKQAAACwFIEUAAAAluIaUgAAAFiKDikAAAAsRSAFAACApdxiYfzs7GwdPnxYlStXLre/uQwAAICSM8bo7NmzqlWrlnx9i9fzdItAevjwYZf8e9IAAADI7Y8//tAVV1xRrGPcIpBWrlxZ0t+f4IV/V9put2v16tWOP/0Gz8MYewfG2Tswzp6PMfYOBY1zcnKy6tSp48htxVHsQPrVV19pypQp2rx5s44cOaIPP/xQXbp0KfSYdevWKTo6Wr/88ovq1KmjMWPGqF+/fkU+Z840fUhISJ5AarPZFBISwgvfQzHG3oFx9g6Ms+djjL3Dpca5JJdXFvumppSUFN14442aMWNGkfbfv3+/OnXqpNtuu03btm3Tk08+qYcfflirVq0qdrEAAADwPMXukN5111266667irz/7NmzVa9ePU2dOlWS1KhRI61fv16vvfaaIiMji3t6AAAA6O+biFJTU51+XrvdrrS0NJXlUvblfg3pxo0b1b59+1zbIiMj9eSTTxZ4THp6utLT0x2Pk5OTJf39BbDb7Y7tOf9/4TZ4FsbYOzDO3oFx9nyMsfMYY9SuXTtt3LjRshqOHTum0NBQx+PSjHu5B9KjR48qPDw817bw8HAlJyfr/PnzqlixYp5jYmJiNH78+DzbV69eLZvNlmd7YmJi2RUMl8QYewfG2Tswzp6PMS5/aWlploZRSVq7dq2CgoIcj0vTrXXJu+xHjhyp6Ohox+Ocu7Y6duyY56amxMREdejQgYunPRRj7B0YZ+/AOHs+xth5UlJSHP9/6NAhBQcHl/s59+zZo+joaM2YMUO//vqr7rnnHgUEBDj+PWdGuyTKPZDWqFFDSUlJubYlJSUpJCQk3+6oJAUGBiowMDDPdn9//3xf4AVth+dgjL0D4+wdGGfPxxiXvwu/vqGhoeUeSI0xOnz4sBISElStWjXt27dPAQEBueoozZiX+58ObdWqldasWZNrW2Jiolq1alXepwYAAEAp7dy5U7169dK///1v1axZs1zOUexAeu7cOW3btk3btm2T9PeyTtu2bdPBgwcl/T3d3qdPH8f+jzzyiPbt26fhw4dr586dmjlzppYsWaKnnnqqbD4DAAAAlIsjR45o6NChmjZtWrmep9iB9IcfftBNN92km266SZIUHR2tm266SWPHjpX0d+E54VSS6tWrp88++0yJiYm68cYbNXXqVL3zzjss+QQAAODCdu3apcDAQC1btkw1atQo13MV+xrSdu3aFbruVGxsbL7HbN26tbinAgAAgAV++eUXPfHEE4qLi9Nll11W7udzybvsAQAALmTVIvCu6sK77MvDkiVLFBcXp+rVq5freXIQSAEAgEszxqh169basGGD1aV4vO3btysxMTHf9eDLE4EUAAC4tNTUVMJoASIiIvL9o0ElsX37dkVHR2vx4sVl8nzFQSAFAABuIykpySmLwLsLm80mHx+fUj/PiRMnFBoaqsWLF6tatWplUFnxEEgBAIDbCA4OJpCWsW3btunZZ5/Vp59+mu8fJnKGcl8YHwAAAK4pIyNDEydOVEJCgmVhVKJDCgAA4JW2bNmilJQULV26tEym/UuDDikAAICX2bx5s0aMGKEmTZpYHkYlOqQAAABeJTs7W4cOHdKSJUsUGhpqdTmSCKQAAFjKkxZ8t9vtSktLU0pKivz9/cvsect7EXhv8v3332vmzJlasGCB1aXkQiAFAMAiLPgOZ9q3b5+ef/55JSQkWF1KHlxDCgCARVjwvXjKchF4b7N161Zddtll+u9//6sqVapYXU4edEgBAHABnrDgu91u16pVqxQZGVmmU/Y5ymoReG+zceNGTZgwQQkJCS77GiOQAgDgAjxhwXe73a6goCAFBweXSyBFyaxcuVIJCQkKCQmxupQCEUgBAAA80IYNG7RlyxaNHz/e6lIuiUAKAADgYTZu3KhJkyYpPj7e6lKKhEAKAADgQY4ePapatWopISFBlSpVsrqcIuEuewAAAA/x1VdfaeDAgapdu7bbhFGJQAoAAOARUlJSNGPGDMXHx6tCBfeaBHevagEAAJDHunXrZLPZXHLR+6KgQwoAAODGvvzyS02bNk1NmjSxupQSI5ACAAC4qczMTJ09e1bx8fFu/VesmLIHAABwQ1988YWWLVummTNnWl1KqRFIAQAA3MzPP/+st956S4sXL7a6lDLBlD0AAIAb2bBhg6688krFx8erYsWKVpdTJgikAAAAbmLVqlV69dVXFRAQoKCgIKvLKTNM2QMAnMIYo7S0NKWkpMjf39/qclxCSkqK1SXAjRhjtHHjRsXFxXlUGJUIpAAAJzDGqF27dtq4caPVpQBuacWKFTp8+LBeeOEFq0spFwRSAEC5S01NJYwWIiIiwq2X7EH5WrVqlRYsWKCFCxdaXUq5IZACAJzq0KFDCg0NtboMl2Kz2eTj42N1GXBBf/zxhxo1aqSFCxcqMDDQ6nLKDYEUAOBUwcHBCg4OtroMwOUtX75ccXFxWrx4scf/wsJd9gAAAC7m5MmTWrZsmd577z2PD6MSHVIAAACX8tFHH6levXqKjY21uhSnoUMKAADgIpYtW6aEhAQ1btzY6lKcikAKAADgAjIyMhQQEKD33nvP69bqZcoeALyQMUapqalOOx8LwAOFW7p0qb777jtNmTLF6lIsQSAFAC9jjFHr1q21YcMGq0sBIOnbb7/VRx995FXXjF6MKXsA8DKpqamWhdFGjRqxADxwgS+++ELXX3+9YmNjVaGC9/YJvfczBwAoKSnJaWuC2u12rVu3ziuWsAGKYvHixfr888/Vrl07rw6jEoEUALyaMxept9vthFHg/2RlZWn//v2aP3++14dRiUAKAADgVIsWLZKPj49GjRpldSkug2tIAQAAnCQhIUFr1qxRVFSU1aW4FDqkAAAATrBv3z5FRESoa9eu8vPzs7ocl0KHFAAAoJzFxsZq8uTJuuKKKwij+aBDCgBO4uzF6AvCIvWAcx05ckTff/+9Zs+ebXUpLotACgBOwGL0gHd699131apVK82YMcPqUlwaU/YA4ARWLkZfkIiICBapB8rRO++8o40bN+rqq6+2uhSXR4cUAJzMmYvRF8Zms7EuKFBO0tLSdMUVV+ihhx6Sry/9v0shkAKAkzlzMXoAzjdnzhwlJSVp7NixVpfiNgikAAAAZSQxMVHbt2/Xm2++aXUpboVACgAAUAY+/vhjdejQQe3bt+dymGLiogYAAIBSmjFjhtauXauKFSsSRkuAQAoAAFAKGRkZSktL0/Tp0wmjJcSUPQAUoCwXsmcxesAzvf7666pbt66efvppq0txawRSAMgHC9kDuJQ5c+bo4MGDevzxx60uxe0RSAEgH+W1kD2L0QOeYefOnercubNq1qzJNH0ZIJACwCWU5UL2LEYPuL+pU6fq+PHjmjx5stWleAwCKQBcAgvZA8ixd+9enTx5UjExMVaX4lG4yx4AAKAIpk+froCAAE2aNImZjjJGhxQAAOASJk+erLNnz+qKK66wuhSPRCAFAAAoREpKilq2bKl27drRGS0nBFIAljLGKCUlRWlpaUpJSZG/v7/VJUli3VAAf3vxxRcVEhLC0k7ljEAKwDKs9QnAlS1dulR2u12PPfaY1aV4PAIpAMuU11qfZYl1QwHvtHjxYt1///3q2rWr1aV4BQIpAJcQGxure++912Wm7HOwbijgfV544QX5+voqICDA6lK8BoEUgEsICgpScHCwywVSAN7DGKPU1FTVrFlTgwcPtrocr8I6pAAAwOsZYzR27Fht2rSJMGoBAikAAPB6kydPls1m02233WZ1KV6JKXsAAOC1jDHavn27Hn74YYWFhVldjteiQwoAALySMUYjR47UqlWrCKMWo0MKwGlybhjIweLzAKy0fft2hYWF6emnn7a6FK9HhxSAU+Qsgl+pUiXHR3h4uNVlAfBCxhiNHz9eNWvWJIy6CAIpAKcobBH8W2+9VYGBgU6uCIA3Msbo2WefVUhICNP0LoQpewBOl5SUpODgYMdjf39/ff755xZWBMAbGGN09uxZ3Xfffbr11lutLgcXIJACcLrg4OBcgdRut1tYDQBvYIxRdHS0br75ZvXu3dvqcnARpuwBAIDHW7BggerXr08YdVF0SAEAgMcyxmj+/Pnq16+f/Pz8rC4HBaBDCgAAPJIxRo8//rgyMjIIoy6ODikAAPA4xhidOXNGrVq1Us+ePa0uB5dAIAVQoIsXsi8NFsEH4CzZ2dkaNmyYHnroIcKomyCQAshXzkL2Ba0dCgCuasSIEbrpppvUvHlzq0tBERFIAeSrsIXsSyMiIkI2m63MnxcAsrOztWXLFo0YMUKXXXaZ1eWgGAikAC7p4oXsS8Nms8nHx6dMngsAcmRnZ+uRRx5Rq1at6Iy6IQIpgEu6eCF7AHA13333nVq1aqX+/ftbXQpKgGWfAACA28rKytIzzzyj66+/njDqxgikAADALWVnZ2vQoEG68cYbFRISYnU5KAWm7AEAgNvJysrS2bNnNWTIEDVr1szqclBKdEgBAIBbycrK0oABA/T1118TRj0EHVLACxVlwXsWsgfgqt566y117NhRnTt3troUlBECKeBlWPAegLvKzMzU22+/rccff5zl4zwMU/aAlynugvcsZA/AFWRmZqp///667LLLCKMeiA4p4MWKsuA9C9kDsFp2drZOnTqlbt26MU3voeiQAl4sZ8H7wj4IowCsZLfb1bt3b/3111+EUQ9GIAUAAC7rscce03333aeGDRtaXQrKEVP2AADA5djtdm3ZskWvvPIKi957ATqkAADApWRkZOjBBx/UkSNHCKNegg4p4OEuXnOU9UUBuLqvv/5aPXv21L333mt1KXASAingwVhzFIA7ycjI0FNPPaWpU6cqKCjI6nLgREzZAx6ssDVHWV8UgCux2+168MEHdddddxFGvRAdUsBLXLzmKOuLAnAV6enpSk1N1dixY9WkSROry4EF6JACXoL1RQG4orS0NPXs2VM//vgjYdSLEUgBAIBlXnvtNT388MNq166d1aXAQkzZAwAAp0tLS9O8efM0YsQIZmxAhxQAADhXWlqaevTooWuuuYYwCkl0SAEAgBNlZWXp5MmTevzxx3XbbbdZXQ5cBB1SwI0ZY5SSklLoBwC4itTUVN13333KzMwkjCIXOqSAm2LRewDuZtCgQXriiSd05ZVXWl0KXAyBFHBThS16fzEWwQdgpdTUVG3btk1z5szJtR4ykINACniAixe9vxiL4AOwSkpKirp3765nnnmGMIoCEUgBD5Cz2D0AuJovv/xSzzzzjNq2bWt1KXBhJbqpacaMGapbt66CgoLUsmVLbdq0qdD9p0+fruuuu04VK1ZUnTp19NRTTyktLa1EBQMAANd37tw5DRw4UHfeeSdhFJdU7ECakJCg6OhojRs3Tlu2bNGNN96oyMhIHTt2LN/94+LiNGLECI0bN047duzQvHnzlJCQoFGjRpW6eAAA4HrOnz+v7t27q2/fvqpQgclYXFqxA+m0adM0cOBA9e/fX40bN9bs2bNls9k0f/78fPffsGGDIiIi1LNnT9WtW1cdO3ZUjx49LtlVBQAA7uf8+fNKT0/XtGnT1Lp1a6vLgZso1q8tGRkZ2rx5s0aOHOnY5uvrq/bt22vjxo35HnPrrbdq4cKF2rRpk1q0aKF9+/ZpxYoV6t27d4HnSU9PV3p6uuNxcnKyJMlut8tutzu25/z/hdvgWRjjgl38XnDnrxHj7B0YZ8938uRJTZkyRXXq1FGLFi0Yaw9V0Hu5NONdrEB64sQJZWVlKTw8PNf28PBw7dy5M99jevbsqRMnTqh169YyxigzM1OPPPJIoVP2MTExGj9+fJ7tq1evznfpmsTExOJ8GnBDnjzGxphcv4AV1YXXYa9atUpBQUFlWZYlPHmc8f8xzp5r8eLF6tatm06cOKEVK1ZYXQ7K2cXv5dTU1BI/V7lf2LFu3Tq99NJLmjlzplq2bKk9e/boiSee0MSJE/X888/ne8zIkSMVHR3teJycnKw6deqoY8eOCgkJcWy32+1KTExUhw4d5O/vX96fCizg6WNsjFG7du0KnGEoqsjISLe+y97Txxl/Y5w915kzZ7Rw4ULNnz+fMfYCBb2Xc2a0S6JYgbRatWry8/NTUlJSru1JSUmqUaNGvsc8//zz6t27tx5++GFJ0g033KCUlBQNGjRIo0ePlq9v3stYAwMDFRgYmGe7v79/vi/wgrbDc3jqGKekpJQ6jEZERKhKlSoesc6op44zcmOcPcuZM2f04IMPasKECY5xZYy9w8XjXJoxL1YgDQgIULNmzbRmzRp16dJFkpSdna01a9Zo2LBh+R6TmpqaJ3T6+flJ+rs7BOBvl1rcviAseg/AKna7XadPn9aLL76o5s2bc80oSqzYU/bR0dHq27evmjdvrhYtWmj69OlKSUlR//79JUl9+vRR7dq1FRMTI0nq3Lmzpk2bpptuuskxZf/888+rc+fOjmAKgMXtAbiX06dPKyoqSgsXLlTz5s2tLgdurtiBNCoqSsePH9fYsWN19OhRNW3aVCtXrnTc6HTw4MFcHdExY8bIx8dHY8aM0Z9//qmwsDB17txZkyZNKrvPAgAAOI0xRg899JAmTZqksLAwq8uBByjRTU3Dhg0rcIp+3bp1uU9QoYLGjRuncePGleRUAADAhZw6dUo7duxQXFycR6zuAddQoj8dCgAAvM/JkycVFRWloKAgwijKFH/PCwAAFMm6dev08ssv66abbrK6FHgYAikAACjUX3/9pWeffVbz5s1jVQ+UC6bsAQBAgc6cOaPu3bvrySefJIyi3NAhBQAA+Tpx4oT8/f31zjvv6KqrrrK6HHgwOqQAACCP48ePq3v37jpy5AhhFOWOQAoAAPJ47bXXNH36dDVs2NDqUuAFmLIHAAAOx44d05IlS/TSSy9ZXQq8CB1SAAAgSUpKSlKPHj10++23W10KvAwdUgAAoPT0dJ07d05vvfWWGjVqZHU58DJ0SAEnMsYoJSUl1wcAWO3IkSPq1KmTwsLCCKOwBB1SwEmMMWrdurU2bNhgdSkA4JCdna2BAwdqxowZCgkJsboceCkCKeAkqampBYbRiIgI2Ww2J1cEwNsdPnxYv//+u5YtW6aAgACry4EXY8oesEBSUpLOnTvn+Pj666/5CygAnOrPP//Ugw8+qGrVqhFGYTk6pIAFgoODFRwcbHUZALzY+vXrNWfOHF1zzTVWlwLQIQUAwJscOnRIAwYMULdu3QijcBl0SAEA8BLHjh1Tnz599Pbbb3OZEFwKgRQAAC9w6NAhhYSEaNGiRapZs6bV5QC5MGUPAICH+/3339WnTx+dPn2aMAqXRIcUKIQxRqmpqWXyXCyCD8Aqb731lubPn68rr7zS6lKAfBFIgQKwkD0Ad3fgwAGtWLFCU6ZMsboUoFBM2QMFKGwh+9JgEXwAzrB//3499NBDuueee6wuBbgkOqRAESQlJZXZuqE2m427WwGUq9TUVGVkZCg2NpZpergFAilQBCxkD8Bd7N27V4MHD9ann36qoKAgq8sBioQpewAAPITdbtdjjz2m2NhYwijcCh1SAAA8wO7du3Xq1CktX75cFSrw4x3uhQ4pAABubvfu3Ro8eLBq165NGIVb4lULAIAbM8bo+++/18KFC1WrVi2rywFKhEAKAICb2rVrl6ZOnaq5c+daXQpQKgRSAADc0MGDBzVkyBAtWrTI6lKAUuMaUgAA3MzevXtVtWpVLVmyRDVq1LC6HKDUCKQAALiRX3/9VYMGDVJaWpouv/xyq8sBygSBFAAANzJv3jwtXrxYYWFhVpcClBmuIQUAwA38/PPP2rhxo6ZOnWp1KUCZo0MKAICL2759u5588kl16dLF6lKAckGHFAAAF3b27FlVqFBB8fHxqlatmtXlAOWCDikAAC7qxx9/VNeuXXXNNdcQRuHR6JAC/8cYo9TUVMfjlJQUC6sB4O1SU1M1atQoxcXF8edA4fF4hQP6O4y2bt1aGzZssLoUANDWrVslSZ988ol8fZnMhOfjVQ7o705EQWE0IiJCNpvNyRUB8FZbtmzRc889p6uuuoowCq9BhxS4SFJSkoKDgx2PbTabfHx8LKwIgLcwxujXX39VQkKCqlatanU5gNMQSIGLBAcH5wqkAOAMP/zwgxYsWKAZM2ZYXQrgdARSAAAstnPnTo0ePVoJCQlWlwJYgotTAACw0C+//KLatWvrgw8+UGhoqNXlAJYgkAIAYJHvvvtOzzzzjIwxCgkJsbocwDIEUgAALGCMUUJCghISEgij8HpcQwoAgJNt3LhRu3bt0rRp06wuBXAJdEgBAHCiDRs2aOLEibr//vutLgVwGQRSAACc5NSpUwoNDVVCQoIqV65sdTmAyyCQAgDgBF9//bX69eunhg0bEkaBixBIAQAoZ6dPn9a0adO0aNEi/hwokA9uagIAoBz973//U7Vq1bRs2TL+DDFQAH5NAwCgnKxbt06vvvqq6tatSxgFCkGHFACAcpCdna0///xTCQkJstlsVpcDuDQCKdyCMUYpKSnl9vzl+dwAvM+aNWu0YsUKTZ061epSALdAIIXLM8aoXbt22rhxo9WlAMAlbd68WW+88Ybi4+OtLgVwG1xDCpeXnp7utDAaERHB1BqAEvvhhx903XXXKT4+XhUrVrS6HMBt0CGFW0lKSlJwcHC5Pb/NZuPGAwAlsmrVKs2ePVuLFy9WUFCQ1eUAboVACrcSHBxcroEUAEoiOztbX3zxBWEUKCECKQAApbBy5UqdPn1aU6ZMsboUwG1xDSkAACX0+eef65133tF//vMfq0sB3BqBFACAEjh+/Ljq1q2rRYsWKTAw0OpyALdGIAUAoJg++eQTPfHEE2rYsCFhFCgDXEOKMmGMUWpqapk/r91uV1paWpk/LwCU1NGjR7V48WLFxsayKgdQRgikKDVjjFq3bq0NGzZYXQoAlKtPP/1UDRs21KJFiwijQBliyh6llpqa6pQwyqL1AKz04YcfauHChbrqqqsIo0AZo0OKMlXWC9fb7XatWrVKkZGRqlKlCj8EAFgiKytLaWlpev/99+Xv7291OYDHIZCiTJX1wvV2u11BQUEKDg4mjAKwxH//+19t27ZNEydOtLoUwGMRSAEAKMD//vc/LVu2TLGxsVaXAng0AikAAPlYv369mjVrpnfffVcVKvDjEihP3NQEAMBFEhISNHfuXAUFBRFGAScgkAIAcAG73a6ffvpJ8+fPJ4wCTsI7DcV28SL4KSkpFlYDAGUnLi5OlSpV0qRJk6wuBfAqdEhRLDmL4FeqVMnxER4ebnVZAFBqixcvVmJiojp16mR1KYDXoUOKYilsEXwWrgfgrg4fPqybb75Z3bp1k5+fn9XlAF6HQIoSu3gRfJvNxlqhANzOe++9pw0bNmj27NlWlwJ4LQIpSqysF8EHAGfbv3+/vvnmG82cOdPqUgCvxjWkAACvtGjRIlWoUEFz5sxhmh6wGIEUAOB15s+fr6+//lq1a9e2uhQAIpACALxMZmamQkJCNHPmTPn68mMQcAVcQwoA8Bpz587V6dOnNXz4cKtLAXABAikAwCt88skn+vHHH/Xmm29aXQqAixBIAQAeLzExUbfffrs6derEND3ggnhXAgA82syZM7V8+XLZbDbCKOCieGcCADxWamqqTp06pTfeeIM/3AG4MKbsAQAe6a233lKjRo00evRoq0sBcAl0SAEAHmfmzJnat2+fbr/9dqtLAVAEdEgBAB7l4MGDioyM1KOPPso0PeAm6JACADzGa6+9ptmzZ6tBgwaEUcCN0CFFoYwxSk1NdTxOSUmxsBoAKNjPP/+spKQkxcTEWF0KgGKiQ4oCGWPUunVrVapUyfERHh5udVkAkMesWbNUvXp1TZ48mc4o4IbokKJAqamp2rBhQ77/FhERIZvN5uSKACCvV155RadOnVJYWJjVpQAoIQIpiiQpKUnBwcGOxzabjS4EAMulp6erYcOG6ty5M9+TADdGIEWRBAcH5wqkAGC1l156SZdffrkGDx5sdSkASolrSAEAbuf9999XWlqaBg0aZHUpAMoAHVIAgFtZvny5HnjgAQUGBjJND3gIOqQAALcxYcIEbd26VUFBQYRRwIPQIQUAuIXTp0+rSpUqeuKJJ6wuBUAZo0MKAHBpxhi98MIL+u233wijgIcikAIAXNqkSZPk7++vFi1aWF0KgHLClD0AwCUZY7R371716dNHV155pdXlAChHdEgBAC7HGKPRo0fr448/JowCXoBACgBwOd99951CQ0P19NNPW10KACcgkAIAXIYxRpMnT1ajRo00fPhwq8sB4CQEUgCASzDG6LnnnlNAQICqVKlidTkAnIibmgAAljPG6Pz582rfvr06duxodTkAnIxACgCwlDFGTz/9tFq2bKmoqCirywFgAQKpFzDGKDU1tdjHpaSklEM1AJDbjBkzVLduXcIo4MUIpB7OGKPWrVtrw4YNVpcCALkYY/TBBx/okUceUYUK/DgCvFmJbmrK+W02KChILVu21KZNmwrd//Tp0xo6dKhq1qypwMBAXXvttVqxYkWJCkbxpKamljqMRkREyGazlVFFAPB3GH3iiSd0/PhxwiiA4ndIExISFB0drdmzZ6tly5aaPn26IiMjtWvXLlWvXj3P/hkZGerQoYOqV6+upUuXqnbt2vr9998VGhpaFvWjGJKSkhQcHFzs42w2m3x8fMqhIgDe6tixY7rpppvUv39/q0sB4AKKHUinTZumgQMHOr6JzJ49W5999pnmz5+vESNG5Nl//vz5OnnypDZs2CB/f39JUt26dUtXNUokODi4RIEUAMpKdna2nnzySQ0dOpQwCsChWFP2GRkZ2rx5s9q3b///n8DXV+3bt9fGjRvzPWb58uVq1aqVhg4dqvDwcDVp0kQvvfSSsrKySlc5AMDtxMbGqkmTJmrcuLHVpQBwIcXqkJ44cUJZWVkKDw/PtT08PFw7d+7M95h9+/Zp7dq16tWrl1asWKE9e/ZoyJAhstvtGjduXL7HpKenKz093fE4OTlZkmS322W32x3bc/7/wm3I7eKvl7t9rRhj78A4e77s7Gz9+uuv6tKli6KiohhrD8V72TsUNM6lGfdyv5I8Oztb1atX19y5c+Xn56dmzZrpzz//1JQpUwoMpDExMRo/fnye7atXr8735prExMQyr9tTpKWlOf5/1apVCgoKsrCakmOMvQPj7Jmys7M1Z84cXXvttbrjjjsYZy/AGHuHi8e5JEtM5ihWIK1WrZr8/PyUlJSUa3tSUpJq1KiR7zE1a9aUv7+//Pz8HNsaNWqko0ePKiMjQwEBAXmOGTlypKKjox2Pk5OTVadOHXXs2FEhISGO7Xa7XYmJierQoYPj+lRvd/GaoxeuJRoZGel215Ayxt6BcfZsa9as0f33369evXoxzh6O97J3KGicc2a0S6JYgTQgIEDNmjXTmjVr1KVLF0l//+a7Zs0aDRs2LN9jIiIiFBcXp+zsbPn6/n3J6m+//aaaNWvmG0YlKTAwUIGBgXm2+/v75/sCL2i7t7nUmqPu/HVy59pRdIyzZ8nOzta4ceM0atQoVaxY0TGdxzh7PsbYO1w8zqUZ82KvQxodHa23335b7777rnbs2KFHH31UKSkpjrsl+/Tpo5EjRzr2f/TRR3Xy5Ek98cQT+u233/TZZ5/ppZde0tChQ0tcNPJX2JqjrCUKwJmysrI0aNAgXX311apYsaLV5QBwccW+hjQqKkrHjx/X2LFjdfToUTVt2lQrV6503Oh08OBBRydUkurUqaNVq1bpqaee0j/+8Q/Vrl1bTzzxhJ577rmy+yyQx8VrjrKWKABnycrK0vnz59W3b1+1adPG6nIAuIES3dQ0bNiwAqfo161bl2dbq1at9O2335bkVCgh1hwFYIWsrCw9/PDDioqK0p133ml1OQDcRIn+dCgAAPl55ZVX1L59e8IogGLhDwgDAEotMzNTCQkJGj58eK5VVQCgKOiQAgBKJTMzUw899JD8/PwIowBKhA4pAKDEjDE6cuSI7r33Xt1///1WlwPATdEhdWPGGKWkpOT6AABnyczMVN++fZWdnU0YBVAqdEjd1KUWwQeA8jZ48GD9+9//1lVXXWV1KQDcHIHUTbEIPgCr2O12/fbbb5o8ebLCwsKsLgeAByCQegAWwQfgLHa7XX369FFUVJSuv/56q8sB4CEIpB6ARfABOMuKFSsUFRWlLl26WF0KAA9CIAUAXFJGRoZGjRqlyZMnq0IFfnQAKFvcZQ8AKFRGRoYefPBBtW3bljAKoFzwnQUAUKD09HRlZGTo2Wef1S233GJ1OQA8FB1SAEC+0tPT1atXL/3000+EUQDlig6pCzLGKDU1tdB9WAQfQHmbOHGiHnroIUVERFhdCgAPRyB1MSx4D8BqaWlpSkhI0MSJE1lCDoBTMGXvYgpb8D4/LIIPoCylpaWpR48eqlGjBmEUgNPQIXVhFy94nx8WwQdQVowxOnTokIYMGaIOHTpYXQ4AL0KH1IXlLHhf2AdhFEBZOH/+vLp27aqQkBDCKACnI5ACgJczxqhv374aMmSIqlevbnU5ALwQU/YA4MVSU1O1d+9ezZ07V6GhoVaXA8BL0SEFAC+VkpKiqKgonThxgjAKwFJ0SAHAS33yySd6+umn1a5dO6tLAeDlCKROxIL3AFxBSkqKRo8erWnTpsnXl4kyANYjkDoJC94DcAU50/TPPfccYRSAyyCQOgkL3gOw2rlz5yRJMTExuuGGGyyuBgD+PwKpBVjwHoCznT17VlFRUYqJidGNN95odTkAkAuB1AI5i9oDgLOMHz9eY8aMIYwCcEkEUgDwYMnJyVq2bJmmTJnCrAsAl8UV7QDgoc6cOaNu3bqpYcOGhFEALo0OKQB4oOzsbP35558aP368WrZsaXU5AFAoOqTlxBijlJSUXB8A4AynT59W586dVbt2bcIoALdAh7QcsOYoAKtkZ2frwQcf1AsvvKAqVapYXQ4AFAmBtBwUtuYo64sCKC+nTp3SH3/8ocWLF6ty5cpWlwMARcaUfTlLSkrSuXPnHB9ff/01NxcAKHOnTp1SVFSUMjMzCaMA3A4d0nLGmqMAnGH58uWaPHmybr75ZqtLAYBiI5ACgBs7efKkXnjhBb3++uvMvgBwW0zZA4CbOnXqlLp3764BAwYQRgG4NTqkAOCGTp48KX9/f82YMUPXXHON1eUAQKnQIQUAN3PixAl169ZNR48eJYwC8AgEUgBwM+PHj9drr71GGAXgMZiyBwA3cezYMa1YsUJvvPEG14wC8Ch0SAHADRw7dkw9evRQixYtCKMAPA6BFABcXGZmpo4cOaI333xTjRs3trocAChzBFIAcGFHjx5Vp06ddO211xJGAXgsAikAuCi73a6+ffvq9ddfV8WKFa0uBwDKDTc1AYALOnLkiP766y99+OGHstlsVpcDAOWKDikAuJjDhw+rV69eCggIIIwC8Ap0SAHAxaxYsUJz5sxhnVEAXoNACgAu4s8//9Qrr7yi119/3epSAMCpCKQA4AKOHDmi3r17a+7cuVaXAgBORyAFAIsdPXpUlSpVUmxsrK688kqrywEAp+OmJgCw0MGDB9WjRw8lJycTRgF4LQIpAFgoJiZG8+fPV+3ata0uBQAsw5Q9AFjg999/11dffaVZs2ZZXQoAWI4OKQA42YEDB9S/f3/961//sroUAHAJBFIAcKKMjAz99ddfWrBgga666iqrywEAl0AgBQAn2bdvn/7973/rH//4B2EUAC7ANaQA4ATnz5/X4MGDNX/+fPn7+1tdDgC4FAIpAJSzPXv2yG6369NPP1VgYKDV5QCAy2HKHgDK0Z49ezR48GCFhIQQRgGgAARSAChHa9as0Xvvvcc6owBQCKbsAaAc/Pbbb5ozZ46mTp1qdSkA4PIIpABQxvbt26dHH31UCxcutLoUAHALBFIAKEMHDx5UWFiY4uLiFB4ebnU5AOAWuIYUAMrIjh071L9/f2VkZBBGAaAY6JCWAWOMUlNTHY9TUlIsrAaAFYwxeu211xQXF6fLL7/c6nIAwK0QSEvJGKPWrVtrw4YNVpcCwCK//PKLfvrpJ82dO9fqUgDALTFlX0qpqakFhtGIiAjZbDYnVwTAmX7++Wc98cQTat++vdWlAIDbokNahpKSkhQcHOx4bLPZ5OPjY2FFAMpTWlqaUlNTtXjxYoWFhVldDgC4LTqkZSg4ODjXB2EU8Fw//fSTunbtqubNmxNGAaCU6JACQDGdOXNGzz77rOLi4uTry+/1AFBaBFIAKIZt27YpODhYn376qfz9/a0uBwA8Ar/aA0ARbd26VcOHD9fll19OGAWAMkQgBYAi+u677xQfH6/LLrvM6lIAwKMwZQ8Al7B582Z98MEHmjx5stWlAIBHIpACQCF+/vlnjRo1SgkJCVaXAgAeiyl7ACjA7t27deWVVyohIUGhoaFWlwMAHotACgD52LRpk4YNGyYfHx/CKACUMwIpAFwkOztb8+bN05IlS1S5cmWrywEAj8c1pABwgW+//VZ//vmn5syZY3UpAOA16JACwP/ZuHGjJkyYoA4dOlhdCgB4FTqkACApJSVFfn5+SkhIYJoeAJyMDikAr7d+/Xr17dtXt9xyC2EUACxAhxSAVzt27JhefvllLV68WD4+PlaXAwBeiQ4pAK+1fv16paam6qOPPlKlSpWsLgcAvBaBFIBX+t///qeXX35ZYWFh8vPzs7ocAPBqBFIAXscYox07dig+Pl7BwcFWlwMAXo9rSAF4lS+//FLr1q3T+PHjrS4FAPB/CKQAvMa3336r6dOna/HixVaXAgC4AFP2ALzCzz//rEaNGmnx4sWy2WxWlwMAuACBFIDHS0xM1PPPP6/AwEDCKAC4IAIpAI+WmZmpjz76SIsXL1ZQUJDV5QAA8sE1pAA81qpVq2S32zVjxgyrSwEAFIIOKQCPtHLlSs2dO1ft27e3uhQAwCXQIQXgcZKTk3X55ZcrLi5OgYGBVpcDALgEOqQAPMqnn36qxx57TLfccgthFADcBB1SAB7j999/13vvvaf333/f6lIAAMVAhxSAR/j8889VoUIFxcfH0xkFADdDIAXg9j7++GO9++67CgsLk68v39YAwN3wnRuAWzPGKCkpSe+9954CAgKsLgcAUAJcQ1pMxhilpqY6HqekpFhYDeDdli1bpt9++00jRoywuhQAQCkQSIvBGKPWrVtrw4YNVpcCeL3ExEQtXbpU7777rtWlAABKiUBaDKmpqQWG0YiICP5GNuAkmzdvVosWLdSuXTv5+/tbXQ4AoJQIpCWUlJSk4OBgx2ObzSYfHx8LKwK8w5IlS7R8+XLFxsaqQgW+hQGAJ+C7eQkFBwfnCqQAyt/58+f17bffEkYBwMPwHR2AW4iPj1f16tU1bdo0q0sBAJQxln0C4PIWL16slStX6l//+pfVpQAAygEdUgAu7eTJk2rYsKG6desmPz8/q8sBAJQDAikAl/X+++/ru+++01tvvWV1KQCAckQgBeCSfv31V61bt05z5861uhQAQDkr0TWkM2bMUN26dRUUFKSWLVtq06ZNRTouPj5ePj4+6tKlS0lOC8BLfPDBBwoLC9M777zDND0AeIFiB9KEhARFR0dr3Lhx2rJli2688UZFRkbq2LFjhR534MABPfPMM2rTpk2JiwXg+RYsWKDExERdfvnlrO0LAF6i2IF02rRpGjhwoPr376/GjRtr9uzZstlsmj9/foHHZGVlqVevXho/frzq169fqoIBeK7s7GxJ0uzZs+XryyIgAOAtivUdPyMjQ5s3b1b79u3//xP4+qp9+/bauHFjgcdNmDBB1atX14ABA0peKQCPlpiYqFmzZql///6EUQDwMsW6qenEiRPKyspSeHh4ru3h4eHauXNnvsesX79e8+bN07Zt24p8nvT0dKWnpzseJycnS5Lsdrvsdrtje87/X7itPF18bmed15s5e4xhjSVLlmjv3r2aPHkyY+3BeD97PsbYOxQ0zqUZ93K9y/7s2bPq3bu33n77bVWrVq3Ix8XExGj8+PF5tq9evVo2my3P9sTExFLVWVRpaWmO/1+1apWCgoKccl44b4zhfDt37tSVV16pQYMGac2aNVaXAyfg/ez5GGPvcPE4p6amlvi5fIwxpqg7Z2RkyGazaenSpbnulO/bt69Onz6tjz/+ONf+27Zt00033ZTrLtmca8R8fX21a9cuNWjQIM958uuQ1qlTRydOnFBISIhju91uV2Jiojp06CB/f/+ifhollpKSoqpVq0qSTp06xd+ydwJnjzGca+7cufrll180ZcoUffHFF4yzh+P97PkYY+9Q0DgnJyerWrVqOnPmTK68VhTF6pAGBASoWbNmWrNmjSOQZmdna82aNRo2bFie/Rs2bKjt27fn2jZmzBidPXtWr7/+uurUqZPveQIDAxUYGJhnu7+/f74v8IK2l7ULz+Gsc+JvfL09z5kzZ3TkyBHNmDFDmZmZkhhnb8E4ez7G2DtcPM6lGfNiT9lHR0erb9++at68uVq0aKHp06crJSVF/fv3lyT16dNHtWvXVkxMjIKCgtSkSZNcx4eGhkpSnu0AvMfMmTPVrFkzvfjii1aXAgBwAcUOpFFRUTp+/LjGjh2ro0ePqmnTplq5cqXjRqeDBw9yhyyAAs2YMUO7d+/Wo48+anUpAAAXUaKbmoYNG5bvFL0krVu3rtBjY2NjS3JKAB7g2LFjatOmjYYMGcKi9wAAB/6WPQCnmD59uk6cOME0PQAgDwIpgHK3adMmHTp0SFOmTLG6FACAC+JiTwDlat68ebruuus0ZcoUpukBAPmiQwqg3EyZMkV//fWXQkJCCKMAgAIRSAGUi8zMTNWqVUvPPPMMYRQAUCgCKYAyN3nyZNWsWVN9+/a1uhQAgBvgGlIAZWrevHlKSUlRnz59rC4FAOAm6JACKDNr165V9+7dZbPZmKYHABQZgRRAmZg4caKysrJ0++23W10KAMDNEEgBlNqxY8cUGBio4cOHW10KAMANcQ0pgFKZMGGCjh07RhgFAJQYgRRAiU2YMEG+vr5q0qSJ1aUAANwYU/YAis0YoyNHjqhbt25q2LCh1eUAANwcHVIAxWKM0fPPP6/4+HjCKACgTBBIARTLmjVrVKlSJUVHR1tdCgDAQzBlD6BIjDF6/fXXNXjwYLVv397qcgAAHoQOKYBLMsZoxIgRyszMVMWKFa0uBwDgYeiQAiiUMUbp6elq1aqVunTpYnU5AAAPRCAFUCBjjJ599lm1bt2aMAoAKDdM2QMo0LRp01SnTh3CKACgXNEhBZCHMUYrV67U0KFDFRQUZHU5AAAPR4cUQC7GGD355JPau3cvYRQA4BR0SAHkcvDgQV1//fUaNGiQ1aUAALwEHdJLMMYoJSXF8QF4KmOMnnrqKWVnZxNGAQBORSAthDFGrVu3VqVKlVSpUiWFh4dbXRJQbp566ildd911qlevntWlAAC8DFP2hUhNTdWGDRvybI+IiJDNZrOgIqDsZWdn69ChQ3r88cdVv359q8sBAHghAmkRJSUlKTg4WJJks9nk4+NjcUVA6WVnZ2vo0KFq2bKl+vXrZ3U5AAAvRSAtouDgYEcgBTzF8uXL1axZM8IoAMBSBFLAC2VnZysmJkbDhw+Xv7+/1eUAALwcNzUBXiY7O1uDBw9W7dq1CaMAAJdAhxTwIllZWUpLS1PXrl0VGRlpdTkAAEiiQwp4jaysLA0cOFCbNm0ijAIAXAqBFPAS48eP1+23367bbrvN6lIAAMiFKXvAw2VlZemzzz7TmDFjFBAQYHU5AADkQYcU8GCZmZl66KGHlJKSQhgFALgsOqSAB9u7d686deqkbt26WV0KAAAFokMKeKDMzEwNGDBAVapUIYwCAFwegRTwMMYYDRgwQHfeeadq1KhhdTkAAFwSU/aAB7Hb7Tp06JBefPFF1alTx+pyAAAoEjqkgIew2+3q06ePfvzxR8IoAMCtEEgBD7FkyRI98MAD6tKli9WlAABQLEzZA24uIyNDkyZN0rhx4+Try++YAAD3w08vwI1lZGSod+/euvnmmwmjAAC3RYcUcFMZGRlKT0/XsGHD1KZNG6vLAQCgxGipAG4oPT1dvXr10s6dOwmjAAC3RyAF3NCoUaPUr18/3XLLLVaXAgBAqTFlD7iRtLQ0rVixQi+//LIqVODtCwDwDHRIATeRlpamnj17ymazEUYBAB6Fn2qAm/jtt980ePBgRUZGWl0KAABlig4p4OLOnz+v7t2768orrySMAgA8EoEUcGHZ2dnq1auXBgwYoNDQUKvLAQCgXDBlD7io1NRUHT16VDNnzlSNGjWsLgcAgHJDhxRwQampqerRo4d+//13wigAwOMRSAEXFBcXpyeeeEK33Xab1aUAAFDumLIHXEhKSopeeuklvfjii/Lx8bG6HAAAnIIOKeAiUlJSFBUVpY4dOxJGAQBehQ4p4AJSU1OVlZWlF154Qc2bN7e6HAAAnIoOKWCxc+fO6YEHHtCff/5JGAUAeCUCKWCxZ599VqNGjVKjRo2sLgUAAEswZQ9Y5OzZs1q9erVmzJghX19+NwQAeC9+CgIWSE5OVrdu3VSrVi3CKADA69EhBZzMGKOdO3dq3Lhx+uc//2l1OQAAWI7WDOBEZ86c0X333acmTZoQRgEA+D8EUsBJMjMz1b17d40cOVI2m83qcgAAcBlM2QNOcPr0aZ08eVLvv/++qlWrZnU5AAC4FDqkQDk7deqUunXrppMnTxJGAQDIBx1SoJwtXrxYMTExatasmdWlAADgkgikQDk5efKkpk6dqkmTJlldCgAALo0pe6AcnDx5Ut27d1fXrl2tLgUAAJdHhxQoY8nJyfLz89P06dPVuHFjq8sBAMDl0SEFytCJEyd033336dSpU4RRAACKiEAKlKHhw4dr2rRpqlu3rtWlAADgNpiyB8rA8ePH9dVXX2nevHny8fGxuhwAANwKHVKglI4dO6bu3bvruuuuI4wCAFACdEiBUjDG6LffftMbb7yh66+/3upyAABwS3RIgRJKSkrSvffeq5YtWxJGAQAoBTqkQAmkpaWpV69eevPNN+Xv7291OQAAuDUCKVBMR44cUXp6upYuXarQ0FCrywEAwO0xZQ8Uw5EjR9SrVy+lp6cTRgEAKCMEUqAYEhISNGvWLF133XVWlwIAgMdgyh4ogj///FOzZs3Siy++aHUpAAB4HDqkwCUcPnxYffr0Ub9+/awuBQAAj0SHFCjEX3/9pYoVK+rtt99W/fr1rS4HAACPRIcUKMAff/yhBx54QBkZGYRRAADKEYEUyIcxRqNGjdI777yj8PBwq8sBAMCjMWUPXOT333/Xli1b9N577/G36QEAcAI6pMAFDhw4oP79++umm24ijAIA4CQEUuD/ZGVl6cCBA5o/f77q1q1rdTkAAHgNAikgaf/+/brvvvv0r3/9izAKAICTcQ0pvF5ycrIGDBig2NhY+fryOxoAAM5GIIVX27t3rwICArR8+XJVqlTJ6nIAAPBKtIPgtfbs2aNBgwbJ19eXMAoAgIUIpPBaH3/8sd577z3Vrl3b6lIAAPBqTNnD6+zevVsLFy7U+PHjrS4FAACIQAovs2fPHj3yyCN6//33rS4FAAD8HwIpvMbRo0d12WWXaeHChapZs6bV5QAAgP/DNaTwCjt37lTPnj3l6+tLGAUAwMUQSOHxjDGaOHGi4uLiFBoaanU5AADgIkzZw6P9+uuv2rt3rxYtWmR1KQAAoAB0SOGxfvnlFz3++ONq2bKl1aUAAIBCEEjhkTIzM5WUlKS4uDhVr17d6nIAAEAhCKTwONu3b1f37t112223EUYBAHADXEMKj3L8+HFFR0dr8eLF8vHxsbocAABQBHRI4TG2b98uu92u5cuXq1q1alaXAwAAiohACo+wbds2Pf300woMDFTFihWtLgcAABQDU/bwCImJiYqPj9dll11mdSkAAKCYCKRwa1u2bNGKFSs0ZswYq0sBAAAlRCCF2/rxxx81cuRIxcfHW10KAAAoBa4hhVv6448/VKtWLcXHx6tq1apWlwMAAEqBQAq38/333+vhhx9WcHAwYRQAAA9QokA6Y8YM1a1bV0FBQWrZsqU2bdpU4L5vv/222rRpo6pVq6pq1apq3759ofsDhcnMzNTrr7+uJUuWyGazWV0OAAAoA8UOpAkJCYqOjta4ceO0ZcsW3XjjjYqMjNSxY8fy3X/dunXq0aOHvvzyS23cuFF16tRRx44d9eeff5a6+NIwxiglJeWSH3Ad3333ndasWaOFCxeqSpUqVpcDAADKSLED6bRp0zRw4ED1799fjRs31uzZs2Wz2TR//vx891+0aJGGDBmipk2bqmHDhnrnnXeUnZ2tNWvWlLr4kjLGqHXr1qpUqVKhH+Hh4ZbViNy+++47vfDCC2rVqpXVpQAAgDJWrLvsMzIytHnzZo0cOdKxzdfXV+3bt9fGjRuL9Bypqamy2+2FrheZnp6u9PR0x+Pk5GRJkt1ul91ud2zP+f8LtxVFSkqKNmzYUOT9b731Vvn7+xf7PCi9nDE/c+aMFi5cqIoVKzIOHqik72W4F8bZ8zHG3qGgcS7NuBcrkJ44cUJZWVl5Oofh4eHauXNnkZ7jueeeU61atdS+ffsC94mJidH48ePzbF+9enW+1w0mJiYW6dw50tLSHP8fGxuroKCgQvcPDAzU559/XqxzoGzs3LlTK1asUHR0tNavX291OShnxX0vwz0xzp6PMfYOF49zampqiZ/LqeuQTp48WfHx8Vq3bl2hIXDkyJGKjo52PE5OTnZcexoSEuLYbrfblZiYqA4dOsjf37/IdVx4bei9996r4ODgYn4mcIaDBw9q1qxZevTRR4s9xnAvJX0vw70wzp6PMfYOBY1zzox2SRQrkFarVk1+fn5KSkrKtT0pKUk1atQo9NhXX31VkydP1hdffKF//OMfhe4bGBiowMDAPNv9/f3zfYEXtL0gF+5b3GPhHN9++63q16+vpUuXas2aNYyTl2CcvQPj7PkYY+9w8TiXZsyLdVNTQECAmjVrluuGpJwblAq72eSVV17RxIkTtXLlSjVv3rzExcI7fPXVV5o0aZKCg4Pz/cUEAAB4lmJP2UdHR6tv375q3ry5WrRooenTpyslJUX9+/eXJPXp00e1a9dWTEyMJOnll1/W2LFjFRcXp7p16+ro0aOS5LiTHbjYpk2bFB8fr+DgYC6MBwDACxQ7kEZFRen48eMaO3asjh49qqZNm2rlypWOG50OHjwoX9//33idNWuWMjIy1LVr11zPM27cOL3wwgulq76IjDG5LrRlfVHXtG7dOn3//fd69tlnrS4FAAA4UYluaho2bJiGDRuW77+tW7cu1+MDBw6U5BRlJmfN0eIs8wTnW79+vaZNm6b4+HirSwEAAE7m8X/LPjU1tcAwGhERwZ+fdAF79+7Vddddp/j4eMYDAAAv5NRln6yWlJSUa4knm80mHx8fCyvCF198oTfffFNLly7ljkwAALyUVwXS4OBg1hx1IWlpaYqLi1N8fDxhFAAAL+ZVgRSuY/Xq1QoMDNT8+fOtLgUAAFjM468hhetZtWqVZs+erZYtW1pdCgAAcAEEUjhVWlqaAgICFBcXV+ifjwUAAN6DKXs4zYoVK/TRRx9p7ty5VpcCAABcCIEUTrFz504tWLBACxcutLoUAADgYpiyR7lbs2aNwsLCtHjxYv42PQAAyINAinK1fPlyzZkzR5UrV1aFCjTkAQBAXgRSlBtjjPbs2aOFCxcqICDA6nIAAICLomWFcvHRRx/pjz/+UHR0tNWlAAAAF0cgRZlbsWKFEhIS9N5771ldCgAAcAMEUpSpHTt26JZbblGHDh34c6AAAKBIuIYUZWbp0qV68cUXdfnllxNGAQBAkRFIUSaSk5O1du1avfvuu/L15WUFAACKjil7lFpCQoLq1aunmTNnWl0KAABwQ7SyUCrx8fH67LPPdPPNN1tdCgAAcFMEUpTYuXPnVKtWLc2fP59F7wEAQImRIlAiCxcu1JYtWzRt2jSrSwEAAG6OQIpi++GHH7R27Vq9/fbbVpcCAAA8AFP2KJaPP/5Y11xzjd5++235+flZXQ4AAPAABFIUWWxsrD799FNVrlyZMAoAAMoMgRRFkp2dreTkZM2ZM4d1RgEAQJniGlJc0vz58yVJjz/+uMWVAAAAT+TWgdQYo7S0NKWkpBT4pypTUlKcXJVnWbx4sTZt2sSi9wAAoNy4bSA1xqhdu3bauHGj1aV4rB9//FEdOnRQVFQU0/QAAKDcuG3KSE1NLVYYjYiIkM1mK8eKPMucOXM0d+5cXX755YRRAABQrty2Q3qhQ4cOKTQ0tNB9bDabfHx8nFOQmzt+/Lj27t2rt956i68ZAAAodx4RSIODgxUcHGx1GR5h9uzZioiI0CuvvGJ1KQAAwEswFwuHGTNmaMeOHWrSpInVpQAAAC/iER1SlN6ZM2d08803a8iQIUzTAwAApyKQQq+//rpOnz6tcePGWV0KAADwQgRSL/fll1/q4MGDevXVV60uBQAAeCkCqRdbtGiRunTponbt2jFNDwAALMNNTV5q6tSp+vHHH1kOCwAAWI4OqRey2+0KCQlRdHQ0YRQAAFiOQOplXnnlFdWrV08DBw60uhQAAABJTNl7lVmzZunMmTPq2rWr1aUAAAA40CH1Et9//726d++u0NBQpukBAIBLoUPqBSZNmqTly5eratWqhFEAAOByCKQe7uDBg5KkCRMmWFwJAABA/gikHiwmJkaZmZkaPXo0nVEAAOCyuIbUQ40fP14+Pj6qX7++1aUAAAAUikDqYYwxOnnypO655x41a9bM6nIAAAAuiUDqQYwxGjt2rMLCwvT4449bXQ4AAECRcA2pB1m+fLlsNhthFAAAuBU6pB7AGKO5c+eqf//+uvfee60uBwAAoFjokLo5Y4xGjhyp5ORkBQQEWF0OAABAsdEhdWPGGKWlpemGG25Qr169rC4HAACgROiQuiljjJ577jl99dVXhFEAAODWCKRuKiYmRjVr1lRkZKTVpQAAAJQKU/Zuxhijb775RsOGDVNISIjV5QAAAJQaHVI3YoxRdHS0tmzZQhgFAAAegw6pG/ntt990zTXXaMiQIVaXAgAAUGbokLoBY4yGDx+ukJAQwigAAPA4BFIXZ4zRE088oXr16qlmzZpWlwMAAFDmmLJ3YdnZ2Tpx4oQGDRqkJk2aWF0OAABAuaBD6qKys7M1bNgwrVq1ijAKAAA8GoHURcXFxemmm25S7969rS4FAACgXDFl72Kys7P1xhtv6PHHH5evL78vAAAAz0ficSHZ2dl65JFHFBISQhgFAABegw6pi8jOzlZKSoo6deqke++91+pyAAAAnIY2nAvIysrSoEGD9PPPPxNGAQCA1yGQuoBRo0apbdu2atWqldWlAAAAOB1T9hbKysrSV199pXHjxslms1ldDgAAgCXokFokKytLDz/8sA4fPkwYBQAAXo0OqUW2b9+ujh07qkePHlaXAgAAYCk6pE6WmZmpRx99VFdddRVhFAAAQARSpzLGqH///mrXrp2qVq1qdTkAAAAugSl7J8nMzNSJEyc0ZswYXXfddVaXAwAA4DLokDqB3W5X37599f333xNGAQAALkIgdYL58+frvvvuU+fOna0uBQAAwOUwZV+O7Ha7XnvtNT377LPy8fGxuhwAAACXRIe0nGRkZKh379669tprCaMAAACFoENaDux2u1JTU/Xwww+rffv2VpcDAADg0uiQlrGMjAz16tVLf/zxB2EUAACgCAikZeypp55Snz59dMMNN1hdCgAAgFtgyr6MpKen66uvvtLUqVMVFBRkdTkAAABugw5pGUhPT1evXr2UmZlJGAUAACgmOqRlYPPmzXr44Yd15513Wl0KAACA26FDWgppaWnq16+fbrzxRsIoAABACRFISygzM1M9evRQz549FRwcbHU5AAAAbosp+xI4f/68zpw5o2nTpqlevXpWlwMAAODW6JAWU2pqqrp3765du3YRRgEAAMoAgbSY5s6dq8cff1xt27a1uhQAAACPwJR9EaWkpOiNN97QyJEjrS4FAADAo9AhLYKUlBR1795drVq1sroUAAAAj0OH9BLS09OVlpamUaNGEUgBAADKAR3SQpw7d07333+/zpw5QxgFAAAoJwTSQgwbNkwjRoxQ/fr1rS4FAADAYzFln4+zZ89q48aNevvtt+Xv7291OQAAAB6NDulFzp49q6ioKFWqVIkwCgAA4AR0SC/y/fff6/nnn+eaUQAAACchkP6f5ORkPfLII4qNjVVAQIDV5QAAAHgNpuwlpaWlqVu3bnryyScJowAAAE7m9R3S06dPKz09XfPmzVPt2rWtLgcAAMDreHWH9PTp04qKitKff/5JGAUAALCIVwfSOXPmaNKkSbr55putLgUAAMBreeWU/alTpzR79myNHDnS6lIAAAC8ntd1SE+ePKmoqChFRkZaXQoAAADkZR3S1NRUZWZmasqUKbrxxhutLgcAAADyog7pX3/9pXvvvVdZWVmEUQAAABfiNYF06NChevXVV1WzZk2rSwEAAMAFPH7K/sSJE9qyZYsWLlyoChU8/tMFAABwOx7dIT1+/Li6d++uWrVqEUYBAABclMcGUmOMNm/erOnTp6tJkyZWlwMAAIACeGQgPXbsmLp3764OHToQRgEAAFycx81jnz17Vj179tQbb7whPz8/q8sBAADAJXhUID169Kj8/Py0aNEihYeHW10OAAAAiqBEU/YzZsxQ3bp1FRQUpJYtW2rTpk2F7v/BBx+oYcOGCgoK0g033KAVK1aUqNjCHDlyRL169dKpU6cIowAAAG6k2IE0ISFB0dHRGjdunLZs2aIbb7xRkZGROnbsWL77b9iwQT169NCAAQO0detWdenSRV26dNHPP/9c6uIvNG/ePM2cOVPXXnttmT4vAAAAylexA+m0adM0cOBA9e/fX40bN9bs2bNls9k0f/78fPd//fXXdeedd+rZZ59Vo0aNNHHiRN1888166623Sl18jtdee01jxozRddddV2bPCQAAAOco1jWkGRkZ2rx5s0aOHOnY5uvrq/bt22vjxo35HrNx40ZFR0fn2hYZGamPPvqowPOkp6crPT3d8Tg5OVmSZLfbZbfbHf+f4+677871GJ4jv/GG52GcvQPj7PkYY+9Q0DiXZtyLFUhPnDihrKysPNdohoeHa+fOnfkec/To0Xz3P3r0aIHniYmJ0fjx4/NsX716tWw2myQpLS3Nsf3AgQOFPh/cX2JiotUlwAkYZ+/AOHs+xtg7XDzOqampJX4ul7zLfuTIkbm6qsnJyapTp446duyokJAQSX8vfH/s2DGtXbtW99xzjwICAqwqF+XIbrcrMTFRHTp0kL+/v9XloJwwzt6BcfZ8jLF3KGicc2a0S6JYgbRatWry8/NTUlJSru1JSUmqUaNGvsfUqFGjWPtLUmBgoAIDA/Ns9/f3z/WJh4aGKigoSAEBAbzwPdzFYw/PxDh7B8bZ8zHG3uHicS7NmBfrpqaAgAA1a9ZMa9ascWzLzs7WmjVr1KpVq3yPadWqVa79pb9bvAXtDwAAAO9S7Cn76Oho9e3bV82bN1eLFi00ffp0paSkqH///pKkPn36qHbt2oqJiZEkPfHEE2rbtq2mTp2qTp06KT4+Xj/88IPmzp1btp8JAAAA3FKxA2lUVJSOHz+usWPH6ujRo2ratKlWrlzpuHHp4MGD8vX9/43XW2+9VXFxcRozZoxGjRqla665Rh999FGx/sa8MUZS3msT7Ha7UlNTlZyczNSAh2KMvQPj7B0YZ8/HGHuHgsY5J6fl5Lbi8DElOcrJDh06pDp16lhdBgAAAC7hjz/+0BVXXFGsY9wikGZnZ+vw4cOqXLmyfHx8HNtz7r7/448/HHffw7Mwxt6BcfYOjLPnY4y9Q0HjbIzR2bNnVatWrVyz5UXhkss+XczX17fQpB0SEsIL38Mxxt6BcfYOjLPnY4y9Q37jXKVKlRI9V7H/dCgAAABQlgikAAAAsJRbB9LAwECNGzcu30X04RkYY+/AOHsHxtnzMcbeoTzG2S1uagIAAIDncusOKQAAANwfgRQAAACWIpACAADAUgRSAAAAWMrlA+mMGTNUt25dBQUFqWXLltq0aVOh+3/wwQdq2LChgoKCdMMNN2jFihVOqhQlVZwxfvvtt9WmTRtVrVpVVatWVfv27S/5moBrKO57OUd8fLx8fHzUpUuX8i0QpVbcMT59+rSGDh2qmjVrKjAwUNdeey3fs91Accd5+vTpuu6661SxYkXVqVNHTz31lNLS0pxULYrrq6++UufOnVWrVi35+Pjoo48+uuQx69at080336zAwEBdffXVio2NLf6JjQuLj483AQEBZv78+eaXX34xAwcONKGhoSYpKSnf/b/55hvj5+dnXnnlFfPrr7+aMWPGGH9/f7N9+3YnV46iKu4Y9+zZ08yYMcNs3brV7Nixw/Tr189UqVLFHDp0yMmVoziKO8459u/fb2rXrm3atGlj7r33XucUixIp7hinp6eb5s2bm7vvvtusX7/e7N+/36xbt85s27bNyZWjOIo7zosWLTKBgYFm0aJFZv/+/WbVqlWmZs2a5qmnnnJy5SiqFStWmNGjR5tly5YZSebDDz8sdP99+/YZm81moqOjza+//mrefPNN4+fnZ1auXFms87p0IG3RooUZOnSo43FWVpapVauWiYmJyXf/bt26mU6dOuXa1rJlSzN48OByrRMlV9wxvlhmZqapXLmyeffdd8urRJSBkoxzZmamufXWW80777xj+vbtSyB1ccUd41mzZpn69eubjIwMZ5WIMlDccR46dKi5/fbbc22Ljo42ERER5VonykZRAunw4cPN9ddfn2tbVFSUiYyMLNa5XHbKPiMjQ5s3b1b79u0d23x9fdW+fXtt3Lgx32M2btyYa39JioyMLHB/WKskY3yx1NRU2e12XXbZZeVVJkqppOM8YcIEVa9eXQMGDHBGmSiFkozx8uXL1apVKw0dOlTh4eFq0qSJXnrpJWVlZTmrbBRTScb51ltv1ebNmx3T+vv27dOKFSt09913O6VmlL+yyl4VyrKosnTixAllZWUpPDw81/bw8HDt3Lkz32OOHj2a7/5Hjx4ttzpRciUZ44s999xzqlWrVp43A1xHScZ5/fr1mjdvnrZt2+aEClFaJRnjffv2ae3aterVq5dWrFihPXv2aMiQIbLb7Ro3bpwzykYxlWSce/bsqRMnTqh169YyxigzM1OPPPKIRo0a5YyS4QQFZa/k5GSdP39eFStWLNLzuGyHFLiUyZMnKz4+Xh9++KGCgoKsLgdl5OzZs+rdu7fefvttVatWzepyUE6ys7NVvXp1zZ07V82aNVNUVJRGjx6t2bNnW10aytC6dev00ksvaebMmdqyZYuWLVumzz77TBMnTrS6NLgYl+2QVqtWTX5+fkpKSsq1PSkpSTVq1Mj3mBo1ahRrf1irJGOc49VXX9XkyZP1xRdf6B//+Ed5lolSKu447927VwcOHFDnzp0d27KzsyVJFSpU0K5du9SgQYPyLRrFUpL3cs2aNeXv7y8/Pz/HtkaNGuno0aPKyMhQQEBAudaM4ivJOD///PPq3bu3Hn74YUnSDTfcoJSUFA0aNEijR4+Wry99MXdXUPYKCQkpcndUcuEOaUBAgJo1a6Y1a9Y4tmVnZ2vNmjVq1apVvse0atUq1/6SlJiYWOD+sFZJxliSXnnlFU2cOFErV65U8+bNnVEqSqG449ywYUNt375d27Ztc3z8+9//1m233aZt27apTp06ziwfRVCS93JERIT27Nnj+GVDkn777TfVrFmTMOqiSjLOqampeUJnzi8hf98zA3dXZtmrePdbOVd8fLwJDAw0sbGx5tdffzWDBg0yoaGh5ujRo8YYY3r37m1GjBjh2P+bb74xFSpUMK+++qrZsWOHGTduHMs+ubjijvHkyZNNQECAWbp0qTly5Ijj4+zZs1Z9CiiC4o7zxbjL3vUVd4wPHjxoKleubIYNG2Z27dplPv30U1O9enXz4osvWvUpoAiKO87jxo0zlStXNosXLzb79u0zq1evNg0aNDDdunWz6lPAJZw9e9Zs3brVbN261Ugy06ZNM1u3bjW///67McaYESNGmN69ezv2z1n26dlnnzU7duwwM2bM8Lxln4wx5s033zRXXnmlCQgIMC1atDDffvut49/atm1r+vbtm2v/JUuWmGuvvdYEBASY66+/3nz22WdOrhjFVZwxvuqqq4ykPB/jxo1zfuEoluK+ly9EIHUPxR3jDRs2mJYtW5rAwEBTv359M2nSJJOZmenkqlFcxRlnu91uXnjhBdOgQQMTFBRk6tSpY4YMGWJOnTrl/MJRJF9++WW+P2dzxrVv376mbdu2eY5p2rSpCQgIMPXr1zcLFiwo9nl9jKFnDgAAAOu47DWkAAAA8A4EUgAAAFiKQAoAAABLEUgBAABgKQIpAAAALEUgBQAAgKUIpAAAALAUgRQAAACWIpACAADAUgRSAAAAWIpACgAAAEsRSAEAAGCp/wcQP47VwEfGtQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Use different learning rates, numbers of epochs, and network structures.\n",
        "\n",
        "expe = Sequential([\n",
        "    Dense(5, input_shape=(8,), activation=\"tanh\"),\n",
        "    Dense(10, activation=\"relu\")\n",
        "])"
      ],
      "metadata": {
        "id": "o90V_AhUFsTo"
      },
      "id": "o90V_AhUFsTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use a learning rate of .003 and train for 1500 epochs\n",
        "expe.compile(SGD(learning_rate = .001), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "run_hist_5 = expe.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XWsC1NLGDgH",
        "outputId": "1df24a71-013c-4d2d-a00b-82257cd137cc"
      },
      "id": "-XWsC1NLGDgH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "18/18 [==============================] - 1s 16ms/step - loss: 3.1508 - accuracy: 0.1545 - val_loss: 3.1339 - val_accuracy: 0.2031\n",
            "Epoch 2/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.1107 - accuracy: 0.1528 - val_loss: 3.1183 - val_accuracy: 0.2031\n",
            "Epoch 3/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0822 - accuracy: 0.1528 - val_loss: 3.0969 - val_accuracy: 0.2031\n",
            "Epoch 4/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 3.0623 - accuracy: 0.1545 - val_loss: 3.0927 - val_accuracy: 0.2031\n",
            "Epoch 5/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0489 - accuracy: 0.1562 - val_loss: 3.0649 - val_accuracy: 0.2031\n",
            "Epoch 6/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0322 - accuracy: 0.1545 - val_loss: 3.0602 - val_accuracy: 0.2031\n",
            "Epoch 7/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 3.0074 - accuracy: 0.1545 - val_loss: 3.0364 - val_accuracy: 0.2031\n",
            "Epoch 8/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9750 - accuracy: 0.1493 - val_loss: 3.0188 - val_accuracy: 0.1927\n",
            "Epoch 9/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9445 - accuracy: 0.1476 - val_loss: 2.9931 - val_accuracy: 0.1927\n",
            "Epoch 10/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9253 - accuracy: 0.1476 - val_loss: 2.9877 - val_accuracy: 0.1927\n",
            "Epoch 11/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9171 - accuracy: 0.1476 - val_loss: 2.9838 - val_accuracy: 0.1927\n",
            "Epoch 12/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9071 - accuracy: 0.1476 - val_loss: 2.9757 - val_accuracy: 0.1927\n",
            "Epoch 13/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8904 - accuracy: 0.1476 - val_loss: 2.9543 - val_accuracy: 0.1927\n",
            "Epoch 14/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8781 - accuracy: 0.1493 - val_loss: 2.9505 - val_accuracy: 0.1927\n",
            "Epoch 15/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.8362 - accuracy: 0.1562 - val_loss: 2.9263 - val_accuracy: 0.1875\n",
            "Epoch 16/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.7875 - accuracy: 0.1580 - val_loss: 2.9112 - val_accuracy: 0.1875\n",
            "Epoch 17/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.7724 - accuracy: 0.1580 - val_loss: 2.9005 - val_accuracy: 0.1875\n",
            "Epoch 18/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.7656 - accuracy: 0.1597 - val_loss: 2.8838 - val_accuracy: 0.1875\n",
            "Epoch 19/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.7573 - accuracy: 0.1597 - val_loss: 2.8827 - val_accuracy: 0.1875\n",
            "Epoch 20/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.7465 - accuracy: 0.1597 - val_loss: 2.8735 - val_accuracy: 0.1875\n",
            "Epoch 21/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.7342 - accuracy: 0.1615 - val_loss: 2.8585 - val_accuracy: 0.1875\n",
            "Epoch 22/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.7247 - accuracy: 0.1615 - val_loss: 2.8407 - val_accuracy: 0.1875\n",
            "Epoch 23/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.7163 - accuracy: 0.1615 - val_loss: 2.8320 - val_accuracy: 0.1875\n",
            "Epoch 24/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.7082 - accuracy: 0.1476 - val_loss: 2.6664 - val_accuracy: 0.1094\n",
            "Epoch 25/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.6225 - accuracy: 0.1076 - val_loss: 2.6574 - val_accuracy: 0.1094\n",
            "Epoch 26/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.6076 - accuracy: 0.1076 - val_loss: 2.6538 - val_accuracy: 0.1094\n",
            "Epoch 27/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.6011 - accuracy: 0.1111 - val_loss: 2.6518 - val_accuracy: 0.1094\n",
            "Epoch 28/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5886 - accuracy: 0.1111 - val_loss: 2.6473 - val_accuracy: 0.1094\n",
            "Epoch 29/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.5758 - accuracy: 0.1111 - val_loss: 2.6340 - val_accuracy: 0.1146\n",
            "Epoch 30/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.5665 - accuracy: 0.1128 - val_loss: 2.6266 - val_accuracy: 0.1146\n",
            "Epoch 31/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5496 - accuracy: 0.1128 - val_loss: 2.6021 - val_accuracy: 0.1146\n",
            "Epoch 32/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5310 - accuracy: 0.1111 - val_loss: 2.5889 - val_accuracy: 0.1146\n",
            "Epoch 33/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5158 - accuracy: 0.1128 - val_loss: 2.5585 - val_accuracy: 0.1146\n",
            "Epoch 34/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4870 - accuracy: 0.1128 - val_loss: 2.5390 - val_accuracy: 0.1146\n",
            "Epoch 35/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4668 - accuracy: 0.1111 - val_loss: 2.5290 - val_accuracy: 0.1146\n",
            "Epoch 36/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.4544 - accuracy: 0.1111 - val_loss: 2.5253 - val_accuracy: 0.1198\n",
            "Epoch 37/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4435 - accuracy: 0.1128 - val_loss: 2.5113 - val_accuracy: 0.1198\n",
            "Epoch 38/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4194 - accuracy: 0.1128 - val_loss: 2.4788 - val_accuracy: 0.1198\n",
            "Epoch 39/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4047 - accuracy: 0.1111 - val_loss: 2.4626 - val_accuracy: 0.1146\n",
            "Epoch 40/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.3911 - accuracy: 0.1111 - val_loss: 2.4339 - val_accuracy: 0.1094\n",
            "Epoch 41/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.3739 - accuracy: 0.1094 - val_loss: 2.4121 - val_accuracy: 0.1094\n",
            "Epoch 42/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3629 - accuracy: 0.1076 - val_loss: 2.4079 - val_accuracy: 0.1094\n",
            "Epoch 43/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3560 - accuracy: 0.1094 - val_loss: 2.4054 - val_accuracy: 0.1094\n",
            "Epoch 44/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3433 - accuracy: 0.1094 - val_loss: 2.3844 - val_accuracy: 0.1042\n",
            "Epoch 45/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3282 - accuracy: 0.1111 - val_loss: 2.3587 - val_accuracy: 0.1094\n",
            "Epoch 46/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3128 - accuracy: 0.1111 - val_loss: 2.3411 - val_accuracy: 0.1042\n",
            "Epoch 47/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3047 - accuracy: 0.1111 - val_loss: 2.3325 - val_accuracy: 0.1042\n",
            "Epoch 48/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2847 - accuracy: 0.1128 - val_loss: 2.3012 - val_accuracy: 0.1094\n",
            "Epoch 49/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2678 - accuracy: 0.1128 - val_loss: 2.2869 - val_accuracy: 0.1146\n",
            "Epoch 50/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2588 - accuracy: 0.1146 - val_loss: 2.2833 - val_accuracy: 0.1094\n",
            "Epoch 51/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2526 - accuracy: 0.1163 - val_loss: 2.2714 - val_accuracy: 0.1094\n",
            "Epoch 52/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2415 - accuracy: 0.1163 - val_loss: 2.2614 - val_accuracy: 0.1094\n",
            "Epoch 53/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2322 - accuracy: 0.1146 - val_loss: 2.2538 - val_accuracy: 0.1094\n",
            "Epoch 54/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.2264 - accuracy: 0.1146 - val_loss: 2.2460 - val_accuracy: 0.1042\n",
            "Epoch 55/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2004 - accuracy: 0.1128 - val_loss: 2.1874 - val_accuracy: 0.1042\n",
            "Epoch 56/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1783 - accuracy: 0.1094 - val_loss: 2.1784 - val_accuracy: 0.1042\n",
            "Epoch 57/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.1741 - accuracy: 0.1094 - val_loss: 2.1760 - val_accuracy: 0.1042\n",
            "Epoch 58/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1544 - accuracy: 0.1094 - val_loss: 2.1616 - val_accuracy: 0.1042\n",
            "Epoch 59/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1361 - accuracy: 0.1076 - val_loss: 2.1575 - val_accuracy: 0.1042\n",
            "Epoch 60/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1208 - accuracy: 0.1059 - val_loss: 2.1587 - val_accuracy: 0.0990\n",
            "Epoch 61/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.1062 - accuracy: 0.1059 - val_loss: 2.1478 - val_accuracy: 0.1146\n",
            "Epoch 62/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0956 - accuracy: 0.1076 - val_loss: 2.1298 - val_accuracy: 0.1146\n",
            "Epoch 63/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0846 - accuracy: 0.1094 - val_loss: 2.1270 - val_accuracy: 0.1146\n",
            "Epoch 64/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0712 - accuracy: 0.1094 - val_loss: 2.1124 - val_accuracy: 0.1146\n",
            "Epoch 65/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0639 - accuracy: 0.1094 - val_loss: 2.0997 - val_accuracy: 0.1146\n",
            "Epoch 66/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0565 - accuracy: 0.1094 - val_loss: 2.0910 - val_accuracy: 0.1146\n",
            "Epoch 67/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0424 - accuracy: 0.1111 - val_loss: 2.0879 - val_accuracy: 0.1250\n",
            "Epoch 68/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0372 - accuracy: 0.1111 - val_loss: 2.0705 - val_accuracy: 0.1198\n",
            "Epoch 69/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0351 - accuracy: 0.1128 - val_loss: 2.0672 - val_accuracy: 0.1198\n",
            "Epoch 70/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0299 - accuracy: 0.1146 - val_loss: 2.0544 - val_accuracy: 0.1198\n",
            "Epoch 71/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0274 - accuracy: 0.1128 - val_loss: 2.0518 - val_accuracy: 0.1198\n",
            "Epoch 72/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 2.0078 - accuracy: 0.1128 - val_loss: 2.0347 - val_accuracy: 0.1094\n",
            "Epoch 73/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9933 - accuracy: 0.1128 - val_loss: 2.0324 - val_accuracy: 0.1094\n",
            "Epoch 74/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9721 - accuracy: 0.1146 - val_loss: 2.0240 - val_accuracy: 0.1094\n",
            "Epoch 75/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.9638 - accuracy: 0.1146 - val_loss: 2.0263 - val_accuracy: 0.1094\n",
            "Epoch 76/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9574 - accuracy: 0.1128 - val_loss: 2.0245 - val_accuracy: 0.1042\n",
            "Epoch 77/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9520 - accuracy: 0.1146 - val_loss: 2.0104 - val_accuracy: 0.1094\n",
            "Epoch 78/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9327 - accuracy: 0.1198 - val_loss: 1.9640 - val_accuracy: 0.1094\n",
            "Epoch 79/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9143 - accuracy: 0.1181 - val_loss: 1.9589 - val_accuracy: 0.1094\n",
            "Epoch 80/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9038 - accuracy: 0.1181 - val_loss: 1.9546 - val_accuracy: 0.1094\n",
            "Epoch 81/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8948 - accuracy: 0.1181 - val_loss: 1.9507 - val_accuracy: 0.1146\n",
            "Epoch 82/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8729 - accuracy: 0.2066 - val_loss: 2.0303 - val_accuracy: 0.2604\n",
            "Epoch 83/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8806 - accuracy: 0.2569 - val_loss: 1.9707 - val_accuracy: 0.2552\n",
            "Epoch 84/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8633 - accuracy: 0.2465 - val_loss: 1.9602 - val_accuracy: 0.2552\n",
            "Epoch 85/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8094 - accuracy: 0.2413 - val_loss: 1.9049 - val_accuracy: 0.2708\n",
            "Epoch 86/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7631 - accuracy: 0.2396 - val_loss: 1.8993 - val_accuracy: 0.2708\n",
            "Epoch 87/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7560 - accuracy: 0.2326 - val_loss: 1.8878 - val_accuracy: 0.2708\n",
            "Epoch 88/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.2326 - val_loss: 1.8788 - val_accuracy: 0.2708\n",
            "Epoch 89/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.7402 - accuracy: 0.2309 - val_loss: 1.9072 - val_accuracy: 0.2083\n",
            "Epoch 90/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6934 - accuracy: 0.2014 - val_loss: 1.8876 - val_accuracy: 0.2135\n",
            "Epoch 91/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6743 - accuracy: 0.2031 - val_loss: 1.8710 - val_accuracy: 0.2188\n",
            "Epoch 92/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6481 - accuracy: 0.1944 - val_loss: 1.8445 - val_accuracy: 0.2188\n",
            "Epoch 93/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6342 - accuracy: 0.1944 - val_loss: 1.8350 - val_accuracy: 0.2083\n",
            "Epoch 94/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6245 - accuracy: 0.1944 - val_loss: 1.8268 - val_accuracy: 0.2083\n",
            "Epoch 95/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6163 - accuracy: 0.1944 - val_loss: 1.8123 - val_accuracy: 0.2083\n",
            "Epoch 96/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6133 - accuracy: 0.1858 - val_loss: 1.8313 - val_accuracy: 0.1823\n",
            "Epoch 97/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6878 - accuracy: 0.1701 - val_loss: 1.8140 - val_accuracy: 0.1771\n",
            "Epoch 98/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6594 - accuracy: 0.1701 - val_loss: 1.8107 - val_accuracy: 0.1771\n",
            "Epoch 99/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.6511 - accuracy: 0.1667 - val_loss: 1.8030 - val_accuracy: 0.1771\n",
            "Epoch 100/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6437 - accuracy: 0.1719 - val_loss: 1.7820 - val_accuracy: 0.1771\n",
            "Epoch 101/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5587 - accuracy: 0.1719 - val_loss: 1.6847 - val_accuracy: 0.1823\n",
            "Epoch 102/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5017 - accuracy: 0.1753 - val_loss: 1.6738 - val_accuracy: 0.1875\n",
            "Epoch 103/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4944 - accuracy: 0.1753 - val_loss: 1.6638 - val_accuracy: 0.1875\n",
            "Epoch 104/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4853 - accuracy: 0.1719 - val_loss: 1.6506 - val_accuracy: 0.1823\n",
            "Epoch 105/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4710 - accuracy: 0.1684 - val_loss: 1.6307 - val_accuracy: 0.1823\n",
            "Epoch 106/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4621 - accuracy: 0.1719 - val_loss: 1.6265 - val_accuracy: 0.1823\n",
            "Epoch 107/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4560 - accuracy: 0.1719 - val_loss: 1.6207 - val_accuracy: 0.1823\n",
            "Epoch 108/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4517 - accuracy: 0.1736 - val_loss: 1.6118 - val_accuracy: 0.1823\n",
            "Epoch 109/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4477 - accuracy: 0.1701 - val_loss: 1.5921 - val_accuracy: 0.1771\n",
            "Epoch 110/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4433 - accuracy: 0.1701 - val_loss: 1.5894 - val_accuracy: 0.1771\n",
            "Epoch 111/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4396 - accuracy: 0.1701 - val_loss: 1.5810 - val_accuracy: 0.1771\n",
            "Epoch 112/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4361 - accuracy: 0.1701 - val_loss: 1.5681 - val_accuracy: 0.1771\n",
            "Epoch 113/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4339 - accuracy: 0.1719 - val_loss: 1.5652 - val_accuracy: 0.1771\n",
            "Epoch 114/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4324 - accuracy: 0.1701 - val_loss: 1.5630 - val_accuracy: 0.1719\n",
            "Epoch 115/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4280 - accuracy: 0.1684 - val_loss: 1.5548 - val_accuracy: 0.1719\n",
            "Epoch 116/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4217 - accuracy: 0.1667 - val_loss: 1.5487 - val_accuracy: 0.1719\n",
            "Epoch 117/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.4152 - accuracy: 0.1701 - val_loss: 1.5278 - val_accuracy: 0.1771\n",
            "Epoch 118/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4058 - accuracy: 0.1701 - val_loss: 1.5200 - val_accuracy: 0.1667\n",
            "Epoch 119/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3990 - accuracy: 0.1684 - val_loss: 1.5106 - val_accuracy: 0.1615\n",
            "Epoch 120/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3937 - accuracy: 0.1701 - val_loss: 1.5080 - val_accuracy: 0.1562\n",
            "Epoch 121/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3830 - accuracy: 0.1719 - val_loss: 1.5007 - val_accuracy: 0.1562\n",
            "Epoch 122/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3770 - accuracy: 0.1719 - val_loss: 1.4936 - val_accuracy: 0.1562\n",
            "Epoch 123/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3665 - accuracy: 0.1667 - val_loss: 1.4950 - val_accuracy: 0.1615\n",
            "Epoch 124/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3619 - accuracy: 0.1632 - val_loss: 1.4890 - val_accuracy: 0.1667\n",
            "Epoch 125/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3567 - accuracy: 0.1632 - val_loss: 1.4868 - val_accuracy: 0.1615\n",
            "Epoch 126/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.3495 - accuracy: 0.1615 - val_loss: 1.4851 - val_accuracy: 0.1667\n",
            "Epoch 127/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3431 - accuracy: 0.1615 - val_loss: 1.4841 - val_accuracy: 0.1615\n",
            "Epoch 128/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3412 - accuracy: 0.1615 - val_loss: 1.4745 - val_accuracy: 0.1667\n",
            "Epoch 129/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3398 - accuracy: 0.1615 - val_loss: 1.4726 - val_accuracy: 0.1667\n",
            "Epoch 130/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.3352 - accuracy: 0.1580 - val_loss: 1.4701 - val_accuracy: 0.1562\n",
            "Epoch 131/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3297 - accuracy: 0.1580 - val_loss: 1.4737 - val_accuracy: 0.1562\n",
            "Epoch 132/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3257 - accuracy: 0.1597 - val_loss: 1.4677 - val_accuracy: 0.1562\n",
            "Epoch 133/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3212 - accuracy: 0.1597 - val_loss: 1.4612 - val_accuracy: 0.1510\n",
            "Epoch 134/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3151 - accuracy: 0.1597 - val_loss: 1.4585 - val_accuracy: 0.1510\n",
            "Epoch 135/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3130 - accuracy: 0.1580 - val_loss: 1.4520 - val_accuracy: 0.1510\n",
            "Epoch 136/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.3102 - accuracy: 0.1562 - val_loss: 1.4455 - val_accuracy: 0.1510\n",
            "Epoch 137/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2630 - accuracy: 0.1580 - val_loss: 1.3996 - val_accuracy: 0.1667\n",
            "Epoch 138/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2436 - accuracy: 0.1580 - val_loss: 1.3974 - val_accuracy: 0.1667\n",
            "Epoch 139/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2384 - accuracy: 0.1545 - val_loss: 1.3964 - val_accuracy: 0.1667\n",
            "Epoch 140/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2342 - accuracy: 0.1528 - val_loss: 1.3952 - val_accuracy: 0.1667\n",
            "Epoch 141/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2329 - accuracy: 0.1510 - val_loss: 1.3942 - val_accuracy: 0.1615\n",
            "Epoch 142/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2282 - accuracy: 0.1493 - val_loss: 1.3931 - val_accuracy: 0.1510\n",
            "Epoch 143/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2265 - accuracy: 0.1493 - val_loss: 1.3923 - val_accuracy: 0.1458\n",
            "Epoch 144/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2236 - accuracy: 0.1458 - val_loss: 1.4022 - val_accuracy: 0.1458\n",
            "Epoch 145/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2162 - accuracy: 0.1441 - val_loss: 1.4068 - val_accuracy: 0.1458\n",
            "Epoch 146/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2059 - accuracy: 0.1458 - val_loss: 1.3882 - val_accuracy: 0.1354\n",
            "Epoch 147/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.2025 - accuracy: 0.1372 - val_loss: 1.3826 - val_accuracy: 0.1354\n",
            "Epoch 148/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.2014 - accuracy: 0.1372 - val_loss: 1.3689 - val_accuracy: 0.1354\n",
            "Epoch 149/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1973 - accuracy: 0.1372 - val_loss: 1.3564 - val_accuracy: 0.1354\n",
            "Epoch 150/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1909 - accuracy: 0.1354 - val_loss: 1.3491 - val_accuracy: 0.1354\n",
            "Epoch 151/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.1897 - accuracy: 0.1354 - val_loss: 1.3471 - val_accuracy: 0.1354\n",
            "Epoch 152/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1887 - accuracy: 0.1354 - val_loss: 1.3325 - val_accuracy: 0.1354\n",
            "Epoch 153/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.1878 - accuracy: 0.1372 - val_loss: 1.3296 - val_accuracy: 0.1354\n",
            "Epoch 154/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1869 - accuracy: 0.1372 - val_loss: 1.3278 - val_accuracy: 0.1354\n",
            "Epoch 155/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1808 - accuracy: 0.1372 - val_loss: 1.3198 - val_accuracy: 0.1406\n",
            "Epoch 156/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1776 - accuracy: 0.1372 - val_loss: 1.3187 - val_accuracy: 0.1458\n",
            "Epoch 157/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1691 - accuracy: 0.1354 - val_loss: 1.3151 - val_accuracy: 0.1458\n",
            "Epoch 158/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1660 - accuracy: 0.1354 - val_loss: 1.2821 - val_accuracy: 0.1458\n",
            "Epoch 159/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1543 - accuracy: 0.1354 - val_loss: 1.2705 - val_accuracy: 0.1458\n",
            "Epoch 160/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1495 - accuracy: 0.1372 - val_loss: 1.2615 - val_accuracy: 0.1458\n",
            "Epoch 161/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1451 - accuracy: 0.1389 - val_loss: 1.2589 - val_accuracy: 0.1458\n",
            "Epoch 162/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1393 - accuracy: 0.1389 - val_loss: 1.2499 - val_accuracy: 0.1458\n",
            "Epoch 163/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1311 - accuracy: 0.1389 - val_loss: 1.2426 - val_accuracy: 0.1406\n",
            "Epoch 164/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.1277 - accuracy: 0.1389 - val_loss: 1.2362 - val_accuracy: 0.1354\n",
            "Epoch 165/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1256 - accuracy: 0.1424 - val_loss: 1.2339 - val_accuracy: 0.1354\n",
            "Epoch 166/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1232 - accuracy: 0.1406 - val_loss: 1.2314 - val_accuracy: 0.1354\n",
            "Epoch 167/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1195 - accuracy: 0.1493 - val_loss: 1.2298 - val_accuracy: 0.1354\n",
            "Epoch 168/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1181 - accuracy: 0.1493 - val_loss: 1.2285 - val_accuracy: 0.1354\n",
            "Epoch 169/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1172 - accuracy: 0.1476 - val_loss: 1.2187 - val_accuracy: 0.1354\n",
            "Epoch 170/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1164 - accuracy: 0.1458 - val_loss: 1.2163 - val_accuracy: 0.1354\n",
            "Epoch 171/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1143 - accuracy: 0.1458 - val_loss: 1.2085 - val_accuracy: 0.1406\n",
            "Epoch 172/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1073 - accuracy: 0.1441 - val_loss: 1.2070 - val_accuracy: 0.1406\n",
            "Epoch 173/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.1065 - accuracy: 0.1424 - val_loss: 1.2057 - val_accuracy: 0.1406\n",
            "Epoch 174/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1042 - accuracy: 0.1424 - val_loss: 1.2041 - val_accuracy: 0.1406\n",
            "Epoch 175/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0993 - accuracy: 0.1441 - val_loss: 1.2025 - val_accuracy: 0.1406\n",
            "Epoch 176/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0959 - accuracy: 0.1441 - val_loss: 1.2013 - val_accuracy: 0.1406\n",
            "Epoch 177/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0949 - accuracy: 0.1441 - val_loss: 1.2004 - val_accuracy: 0.1406\n",
            "Epoch 178/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0882 - accuracy: 0.1424 - val_loss: 1.1964 - val_accuracy: 0.1406\n",
            "Epoch 179/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0830 - accuracy: 0.1406 - val_loss: 1.1956 - val_accuracy: 0.1406\n",
            "Epoch 180/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0797 - accuracy: 0.1406 - val_loss: 1.1767 - val_accuracy: 0.1354\n",
            "Epoch 181/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0681 - accuracy: 0.1372 - val_loss: 1.1736 - val_accuracy: 0.1406\n",
            "Epoch 182/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0620 - accuracy: 0.1372 - val_loss: 1.1726 - val_accuracy: 0.1354\n",
            "Epoch 183/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.1372 - val_loss: 1.1678 - val_accuracy: 0.1354\n",
            "Epoch 184/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0586 - accuracy: 0.1372 - val_loss: 1.1657 - val_accuracy: 0.1302\n",
            "Epoch 185/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0541 - accuracy: 0.1389 - val_loss: 1.1639 - val_accuracy: 0.1354\n",
            "Epoch 186/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0525 - accuracy: 0.1406 - val_loss: 1.1583 - val_accuracy: 0.1406\n",
            "Epoch 187/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0518 - accuracy: 0.1406 - val_loss: 1.1570 - val_accuracy: 0.1354\n",
            "Epoch 188/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0511 - accuracy: 0.1406 - val_loss: 1.1519 - val_accuracy: 0.1354\n",
            "Epoch 189/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0505 - accuracy: 0.1372 - val_loss: 1.1505 - val_accuracy: 0.1354\n",
            "Epoch 190/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0499 - accuracy: 0.1372 - val_loss: 1.1495 - val_accuracy: 0.1354\n",
            "Epoch 191/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0493 - accuracy: 0.1372 - val_loss: 1.1488 - val_accuracy: 0.1354\n",
            "Epoch 192/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0487 - accuracy: 0.1372 - val_loss: 1.1484 - val_accuracy: 0.1354\n",
            "Epoch 193/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0481 - accuracy: 0.1389 - val_loss: 1.1483 - val_accuracy: 0.1354\n",
            "Epoch 194/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0476 - accuracy: 0.1406 - val_loss: 1.1469 - val_accuracy: 0.1302\n",
            "Epoch 195/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0470 - accuracy: 0.1389 - val_loss: 1.1460 - val_accuracy: 0.1354\n",
            "Epoch 196/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.1406 - val_loss: 1.1451 - val_accuracy: 0.1354\n",
            "Epoch 197/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0430 - accuracy: 0.1424 - val_loss: 1.1436 - val_accuracy: 0.1354\n",
            "Epoch 198/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0414 - accuracy: 0.1406 - val_loss: 1.1429 - val_accuracy: 0.1354\n",
            "Epoch 199/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0408 - accuracy: 0.1406 - val_loss: 1.1422 - val_accuracy: 0.1354\n",
            "Epoch 200/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0387 - accuracy: 0.1406 - val_loss: 1.1410 - val_accuracy: 0.1354\n",
            "Epoch 201/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0378 - accuracy: 0.1406 - val_loss: 1.1367 - val_accuracy: 0.1354\n",
            "Epoch 202/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0372 - accuracy: 0.1406 - val_loss: 1.1356 - val_accuracy: 0.1354\n",
            "Epoch 203/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0367 - accuracy: 0.1406 - val_loss: 1.1347 - val_accuracy: 0.1302\n",
            "Epoch 204/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0362 - accuracy: 0.1424 - val_loss: 1.1340 - val_accuracy: 0.1302\n",
            "Epoch 205/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0341 - accuracy: 0.1424 - val_loss: 1.1330 - val_accuracy: 0.1302\n",
            "Epoch 206/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0332 - accuracy: 0.1424 - val_loss: 1.1324 - val_accuracy: 0.1302\n",
            "Epoch 207/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0327 - accuracy: 0.1441 - val_loss: 1.1317 - val_accuracy: 0.1302\n",
            "Epoch 208/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0273 - accuracy: 0.1458 - val_loss: 1.1242 - val_accuracy: 0.1250\n",
            "Epoch 209/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0206 - accuracy: 0.1406 - val_loss: 1.1235 - val_accuracy: 0.1250\n",
            "Epoch 210/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0151 - accuracy: 0.1424 - val_loss: 1.1245 - val_accuracy: 0.1250\n",
            "Epoch 211/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0121 - accuracy: 0.1389 - val_loss: 1.1238 - val_accuracy: 0.1302\n",
            "Epoch 212/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 1.0092 - accuracy: 0.1389 - val_loss: 1.1231 - val_accuracy: 0.1302\n",
            "Epoch 213/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0083 - accuracy: 0.1389 - val_loss: 1.1225 - val_accuracy: 0.1302\n",
            "Epoch 214/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0078 - accuracy: 0.1354 - val_loss: 1.1173 - val_accuracy: 0.1302\n",
            "Epoch 215/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.0021 - accuracy: 0.1372 - val_loss: 1.1094 - val_accuracy: 0.1302\n",
            "Epoch 216/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.0006 - accuracy: 0.1372 - val_loss: 1.1085 - val_accuracy: 0.1354\n",
            "Epoch 217/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9989 - accuracy: 0.1372 - val_loss: 1.1062 - val_accuracy: 0.1354\n",
            "Epoch 218/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9932 - accuracy: 0.1372 - val_loss: 1.1053 - val_accuracy: 0.1354\n",
            "Epoch 219/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9924 - accuracy: 0.1372 - val_loss: 1.1046 - val_accuracy: 0.1354\n",
            "Epoch 220/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9918 - accuracy: 0.1389 - val_loss: 1.1039 - val_accuracy: 0.1354\n",
            "Epoch 221/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.1389 - val_loss: 1.1033 - val_accuracy: 0.1354\n",
            "Epoch 222/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9894 - accuracy: 0.1406 - val_loss: 1.1028 - val_accuracy: 0.1406\n",
            "Epoch 223/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9863 - accuracy: 0.1372 - val_loss: 1.0982 - val_accuracy: 0.1406\n",
            "Epoch 224/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9857 - accuracy: 0.1372 - val_loss: 1.0970 - val_accuracy: 0.1406\n",
            "Epoch 225/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9799 - accuracy: 0.1354 - val_loss: 1.0966 - val_accuracy: 0.1354\n",
            "Epoch 226/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9764 - accuracy: 0.1354 - val_loss: 1.0958 - val_accuracy: 0.1354\n",
            "Epoch 227/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9757 - accuracy: 0.1354 - val_loss: 1.0951 - val_accuracy: 0.1354\n",
            "Epoch 228/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9716 - accuracy: 0.1372 - val_loss: 1.0944 - val_accuracy: 0.1354\n",
            "Epoch 229/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9692 - accuracy: 0.1372 - val_loss: 1.0916 - val_accuracy: 0.1354\n",
            "Epoch 230/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9656 - accuracy: 0.1372 - val_loss: 1.0911 - val_accuracy: 0.1354\n",
            "Epoch 231/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9651 - accuracy: 0.1372 - val_loss: 1.0863 - val_accuracy: 0.1354\n",
            "Epoch 232/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9645 - accuracy: 0.1372 - val_loss: 1.0813 - val_accuracy: 0.1354\n",
            "Epoch 233/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9641 - accuracy: 0.1372 - val_loss: 1.0802 - val_accuracy: 0.1354\n",
            "Epoch 234/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9636 - accuracy: 0.1372 - val_loss: 1.0793 - val_accuracy: 0.1354\n",
            "Epoch 235/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9563 - accuracy: 0.1372 - val_loss: 1.0722 - val_accuracy: 0.1302\n",
            "Epoch 236/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9517 - accuracy: 0.1372 - val_loss: 1.0667 - val_accuracy: 0.1250\n",
            "Epoch 237/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9426 - accuracy: 0.1285 - val_loss: 1.0509 - val_accuracy: 0.1250\n",
            "Epoch 238/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9338 - accuracy: 0.1250 - val_loss: 1.0500 - val_accuracy: 0.1250\n",
            "Epoch 239/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9327 - accuracy: 0.1233 - val_loss: 1.0494 - val_accuracy: 0.1250\n",
            "Epoch 240/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9320 - accuracy: 0.1250 - val_loss: 1.0418 - val_accuracy: 0.1250\n",
            "Epoch 241/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9314 - accuracy: 0.1250 - val_loss: 1.0349 - val_accuracy: 0.1250\n",
            "Epoch 242/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9308 - accuracy: 0.1215 - val_loss: 1.0336 - val_accuracy: 0.1250\n",
            "Epoch 243/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9302 - accuracy: 0.1233 - val_loss: 1.0286 - val_accuracy: 0.1250\n",
            "Epoch 244/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9297 - accuracy: 0.1215 - val_loss: 1.0272 - val_accuracy: 0.1250\n",
            "Epoch 245/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9292 - accuracy: 0.1215 - val_loss: 1.0265 - val_accuracy: 0.1198\n",
            "Epoch 246/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9271 - accuracy: 0.1233 - val_loss: 1.0263 - val_accuracy: 0.1198\n",
            "Epoch 247/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9238 - accuracy: 0.1267 - val_loss: 1.0269 - val_accuracy: 0.1250\n",
            "Epoch 248/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9192 - accuracy: 0.1319 - val_loss: 1.0262 - val_accuracy: 0.1250\n",
            "Epoch 249/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9178 - accuracy: 0.1319 - val_loss: 1.0267 - val_accuracy: 0.1562\n",
            "Epoch 250/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9146 - accuracy: 0.1510 - val_loss: 1.0261 - val_accuracy: 0.1562\n",
            "Epoch 251/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9141 - accuracy: 0.1493 - val_loss: 1.0255 - val_accuracy: 0.1562\n",
            "Epoch 252/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9137 - accuracy: 0.1493 - val_loss: 1.0250 - val_accuracy: 0.1562\n",
            "Epoch 253/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9118 - accuracy: 0.1493 - val_loss: 1.0176 - val_accuracy: 0.1562\n",
            "Epoch 254/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9102 - accuracy: 0.1528 - val_loss: 1.0171 - val_accuracy: 0.1562\n",
            "Epoch 255/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.9098 - accuracy: 0.1528 - val_loss: 1.0166 - val_accuracy: 0.1562\n",
            "Epoch 256/1000\n",
            "18/18 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.1510 - val_loss: 1.0161 - val_accuracy: 0.1562\n",
            "Epoch 257/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9032 - accuracy: 0.1493 - val_loss: 0.9865 - val_accuracy: 0.1458\n",
            "Epoch 258/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8907 - accuracy: 0.1389 - val_loss: 0.9849 - val_accuracy: 0.1458\n",
            "Epoch 259/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8881 - accuracy: 0.1372 - val_loss: 0.9733 - val_accuracy: 0.1458\n",
            "Epoch 260/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8869 - accuracy: 0.1389 - val_loss: 0.9722 - val_accuracy: 0.1458\n",
            "Epoch 261/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8864 - accuracy: 0.1406 - val_loss: 0.9713 - val_accuracy: 0.1406\n",
            "Epoch 262/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8811 - accuracy: 0.1319 - val_loss: 0.9646 - val_accuracy: 0.1302\n",
            "Epoch 263/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8794 - accuracy: 0.1285 - val_loss: 0.9637 - val_accuracy: 0.1302\n",
            "Epoch 264/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.1285 - val_loss: 0.9624 - val_accuracy: 0.1302\n",
            "Epoch 265/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8709 - accuracy: 0.1285 - val_loss: 0.9484 - val_accuracy: 0.1302\n",
            "Epoch 266/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8619 - accuracy: 0.1319 - val_loss: 0.9393 - val_accuracy: 0.1302\n",
            "Epoch 267/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8573 - accuracy: 0.1302 - val_loss: 0.9324 - val_accuracy: 0.1302\n",
            "Epoch 268/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8556 - accuracy: 0.1302 - val_loss: 0.9282 - val_accuracy: 0.1302\n",
            "Epoch 269/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8550 - accuracy: 0.1302 - val_loss: 0.9223 - val_accuracy: 0.1302\n",
            "Epoch 270/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.1302 - val_loss: 0.9206 - val_accuracy: 0.1302\n",
            "Epoch 271/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8540 - accuracy: 0.1285 - val_loss: 0.9196 - val_accuracy: 0.1354\n",
            "Epoch 272/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.1285 - val_loss: 0.9188 - val_accuracy: 0.1354\n",
            "Epoch 273/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8514 - accuracy: 0.1285 - val_loss: 0.9178 - val_accuracy: 0.1354\n",
            "Epoch 274/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8475 - accuracy: 0.1267 - val_loss: 0.9170 - val_accuracy: 0.1354\n",
            "Epoch 275/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8446 - accuracy: 0.1285 - val_loss: 0.9173 - val_accuracy: 0.1354\n",
            "Epoch 276/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.8433 - accuracy: 0.1181 - val_loss: 0.9175 - val_accuracy: 0.0833\n",
            "Epoch 277/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0066 - accuracy: 0.0330 - val_loss: 2.6384 - val_accuracy: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5726 - accuracy: 0.0000e+00 - val_loss: 2.5933 - val_accuracy: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5521 - accuracy: 0.0000e+00 - val_loss: 2.5714 - val_accuracy: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5352 - accuracy: 0.0000e+00 - val_loss: 2.5342 - val_accuracy: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5196 - accuracy: 0.0000e+00 - val_loss: 2.5012 - val_accuracy: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4914 - accuracy: 0.0000e+00 - val_loss: 2.4668 - val_accuracy: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4663 - accuracy: 0.0000e+00 - val_loss: 2.4562 - val_accuracy: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.4561 - accuracy: 0.0000e+00 - val_loss: 2.4335 - val_accuracy: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4346 - accuracy: 0.0000e+00 - val_loss: 2.4202 - val_accuracy: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4165 - accuracy: 0.0000e+00 - val_loss: 2.3639 - val_accuracy: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3876 - accuracy: 0.0000e+00 - val_loss: 2.3731 - val_accuracy: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3453 - accuracy: 0.0000e+00 - val_loss: 2.2803 - val_accuracy: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.2344 - accuracy: 0.0000e+00 - val_loss: 2.2667 - val_accuracy: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.2123 - accuracy: 0.0000e+00 - val_loss: 2.2591 - val_accuracy: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1997 - accuracy: 0.0000e+00 - val_loss: 2.2545 - val_accuracy: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1916 - accuracy: 0.0000e+00 - val_loss: 2.2458 - val_accuracy: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1867 - accuracy: 0.0000e+00 - val_loss: 2.2429 - val_accuracy: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1763 - accuracy: 0.0000e+00 - val_loss: 2.2246 - val_accuracy: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1692 - accuracy: 0.0000e+00 - val_loss: 2.2203 - val_accuracy: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1651 - accuracy: 0.0000e+00 - val_loss: 2.2110 - val_accuracy: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1560 - accuracy: 0.0000e+00 - val_loss: 2.2076 - val_accuracy: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1425 - accuracy: 0.0000e+00 - val_loss: 2.1884 - val_accuracy: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1306 - accuracy: 0.0000e+00 - val_loss: 2.1780 - val_accuracy: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1216 - accuracy: 0.0000e+00 - val_loss: 2.1648 - val_accuracy: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1117 - accuracy: 0.0000e+00 - val_loss: 2.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1043 - accuracy: 0.0000e+00 - val_loss: 2.1492 - val_accuracy: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1004 - accuracy: 0.0000e+00 - val_loss: 2.1419 - val_accuracy: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0930 - accuracy: 0.0000e+00 - val_loss: 2.1243 - val_accuracy: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0738 - accuracy: 0.0000e+00 - val_loss: 2.0885 - val_accuracy: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0556 - accuracy: 0.0000e+00 - val_loss: 2.0833 - val_accuracy: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0472 - accuracy: 0.0000e+00 - val_loss: 2.0805 - val_accuracy: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0407 - accuracy: 0.0000e+00 - val_loss: 2.0587 - val_accuracy: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0311 - accuracy: 0.0000e+00 - val_loss: 2.0517 - val_accuracy: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0241 - accuracy: 0.0000e+00 - val_loss: 2.0403 - val_accuracy: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.0116 - accuracy: 0.0000e+00 - val_loss: 2.0329 - val_accuracy: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0062 - accuracy: 0.0000e+00 - val_loss: 2.0305 - val_accuracy: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0023 - accuracy: 0.0000e+00 - val_loss: 2.0241 - val_accuracy: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.9968 - accuracy: 0.0000e+00 - val_loss: 2.0110 - val_accuracy: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.9754 - accuracy: 0.0000e+00 - val_loss: 1.9864 - val_accuracy: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.9111 - accuracy: 0.0000e+00 - val_loss: 1.8967 - val_accuracy: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1558 - accuracy: 0.0000e+00 - val_loss: 2.5102 - val_accuracy: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.4074 - accuracy: 0.0000e+00 - val_loss: 2.4998 - val_accuracy: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.3972 - accuracy: 0.0000e+00 - val_loss: 2.4894 - val_accuracy: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.3924 - accuracy: 0.0000e+00 - val_loss: 2.4863 - val_accuracy: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3831 - accuracy: 0.0000e+00 - val_loss: 2.4827 - val_accuracy: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3713 - accuracy: 0.0000e+00 - val_loss: 2.4808 - val_accuracy: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3595 - accuracy: 0.0000e+00 - val_loss: 2.4718 - val_accuracy: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3516 - accuracy: 0.0000e+00 - val_loss: 2.4629 - val_accuracy: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.3468 - accuracy: 0.0000e+00 - val_loss: 2.4617 - val_accuracy: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3450 - accuracy: 0.0000e+00 - val_loss: 2.4604 - val_accuracy: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.3422 - accuracy: 0.0000e+00 - val_loss: 2.4457 - val_accuracy: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3393 - accuracy: 0.0000e+00 - val_loss: 2.4441 - val_accuracy: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3376 - accuracy: 0.0000e+00 - val_loss: 2.4376 - val_accuracy: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3301 - accuracy: 0.0000e+00 - val_loss: 2.4360 - val_accuracy: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3286 - accuracy: 0.0000e+00 - val_loss: 2.4350 - val_accuracy: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3277 - accuracy: 0.0000e+00 - val_loss: 2.4342 - val_accuracy: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3270 - accuracy: 0.0000e+00 - val_loss: 2.4292 - val_accuracy: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3263 - accuracy: 0.0000e+00 - val_loss: 2.4281 - val_accuracy: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3257 - accuracy: 0.0000e+00 - val_loss: 2.4273 - val_accuracy: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3113 - accuracy: 0.0000e+00 - val_loss: 2.4194 - val_accuracy: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2933 - accuracy: 0.0000e+00 - val_loss: 2.4150 - val_accuracy: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2823 - accuracy: 0.0000e+00 - val_loss: 2.3958 - val_accuracy: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1930 - accuracy: 0.0000e+00 - val_loss: 2.2893 - val_accuracy: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1610 - accuracy: 0.0000e+00 - val_loss: 2.2861 - val_accuracy: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1577 - accuracy: 0.0000e+00 - val_loss: 2.2836 - val_accuracy: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1540 - accuracy: 0.0000e+00 - val_loss: 2.2819 - val_accuracy: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1301 - accuracy: 0.0000e+00 - val_loss: 2.2602 - val_accuracy: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1035 - accuracy: 0.0000e+00 - val_loss: 2.2589 - val_accuracy: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0988 - accuracy: 0.0000e+00 - val_loss: 2.2567 - val_accuracy: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0964 - accuracy: 0.0000e+00 - val_loss: 2.2560 - val_accuracy: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0955 - accuracy: 0.0000e+00 - val_loss: 2.2553 - val_accuracy: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0947 - accuracy: 0.0000e+00 - val_loss: 2.2547 - val_accuracy: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0941 - accuracy: 0.0000e+00 - val_loss: 2.2541 - val_accuracy: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0934 - accuracy: 0.0000e+00 - val_loss: 2.2443 - val_accuracy: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0928 - accuracy: 0.0000e+00 - val_loss: 2.2427 - val_accuracy: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0923 - accuracy: 0.0000e+00 - val_loss: 2.2417 - val_accuracy: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0917 - accuracy: 0.0000e+00 - val_loss: 2.2409 - val_accuracy: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0912 - accuracy: 0.0000e+00 - val_loss: 2.2403 - val_accuracy: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0908 - accuracy: 0.0000e+00 - val_loss: 2.2397 - val_accuracy: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0903 - accuracy: 0.0000e+00 - val_loss: 2.2392 - val_accuracy: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0899 - accuracy: 0.0000e+00 - val_loss: 2.2387 - val_accuracy: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0895 - accuracy: 0.0000e+00 - val_loss: 2.2337 - val_accuracy: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0891 - accuracy: 0.0000e+00 - val_loss: 2.2328 - val_accuracy: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0887 - accuracy: 0.0000e+00 - val_loss: 2.2321 - val_accuracy: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0883 - accuracy: 0.0000e+00 - val_loss: 2.2316 - val_accuracy: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0880 - accuracy: 0.0000e+00 - val_loss: 2.2311 - val_accuracy: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0876 - accuracy: 0.0000e+00 - val_loss: 2.2307 - val_accuracy: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0873 - accuracy: 0.0000e+00 - val_loss: 2.2302 - val_accuracy: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0870 - accuracy: 0.0000e+00 - val_loss: 2.2299 - val_accuracy: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0867 - accuracy: 0.0000e+00 - val_loss: 2.2295 - val_accuracy: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0864 - accuracy: 0.0000e+00 - val_loss: 2.2291 - val_accuracy: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0861 - accuracy: 0.0000e+00 - val_loss: 2.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0858 - accuracy: 0.0000e+00 - val_loss: 2.2190 - val_accuracy: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0855 - accuracy: 0.0000e+00 - val_loss: 2.2148 - val_accuracy: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0853 - accuracy: 0.0000e+00 - val_loss: 2.2131 - val_accuracy: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0850 - accuracy: 0.0000e+00 - val_loss: 2.2121 - val_accuracy: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0847 - accuracy: 0.0000e+00 - val_loss: 2.2114 - val_accuracy: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0845 - accuracy: 0.0000e+00 - val_loss: 2.2108 - val_accuracy: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4627 - accuracy: 0.0000e+00 - val_loss: 2.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5214 - accuracy: 0.0000e+00 - val_loss: 2.6603 - val_accuracy: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.5076 - accuracy: 0.0000e+00 - val_loss: 2.6364 - val_accuracy: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.6707 - accuracy: 0.0000e+00 - val_loss: 2.9375 - val_accuracy: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.9164 - accuracy: 0.0000e+00 - val_loss: 2.9352 - val_accuracy: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.9041 - accuracy: 0.0000e+00 - val_loss: 2.9208 - val_accuracy: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8929 - accuracy: 0.0000e+00 - val_loss: 2.9190 - val_accuracy: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8812 - accuracy: 0.0000e+00 - val_loss: 2.9108 - val_accuracy: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8705 - accuracy: 0.0000e+00 - val_loss: 2.9071 - val_accuracy: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.8614 - accuracy: 0.0000e+00 - val_loss: 2.8923 - val_accuracy: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.8495 - accuracy: 0.0000e+00 - val_loss: 2.8697 - val_accuracy: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.7814 - accuracy: 0.0000e+00 - val_loss: 2.6871 - val_accuracy: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4699 - accuracy: 0.0000e+00 - val_loss: 2.5617 - val_accuracy: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4441 - accuracy: 0.0000e+00 - val_loss: 2.5551 - val_accuracy: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4356 - accuracy: 0.0000e+00 - val_loss: 2.5511 - val_accuracy: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4296 - accuracy: 0.0000e+00 - val_loss: 2.5422 - val_accuracy: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4257 - accuracy: 0.0000e+00 - val_loss: 2.5341 - val_accuracy: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.4228 - accuracy: 0.0000e+00 - val_loss: 2.5311 - val_accuracy: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4203 - accuracy: 0.0000e+00 - val_loss: 2.5289 - val_accuracy: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4145 - accuracy: 0.0000e+00 - val_loss: 2.5267 - val_accuracy: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4116 - accuracy: 0.0000e+00 - val_loss: 2.5245 - val_accuracy: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4091 - accuracy: 0.0000e+00 - val_loss: 2.5289 - val_accuracy: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4529 - accuracy: 0.0000e+00 - val_loss: 2.5843 - val_accuracy: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4453 - accuracy: 0.0000e+00 - val_loss: 2.5724 - val_accuracy: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4102 - accuracy: 0.0000e+00 - val_loss: 2.5665 - val_accuracy: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.4004 - accuracy: 0.0000e+00 - val_loss: 2.5643 - val_accuracy: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3918 - accuracy: 0.0000e+00 - val_loss: 2.5460 - val_accuracy: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3839 - accuracy: 0.0000e+00 - val_loss: 2.5434 - val_accuracy: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3754 - accuracy: 0.0000e+00 - val_loss: 2.5407 - val_accuracy: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3667 - accuracy: 0.0000e+00 - val_loss: 2.4922 - val_accuracy: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3330 - accuracy: 0.0000e+00 - val_loss: 2.4908 - val_accuracy: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3315 - accuracy: 0.0000e+00 - val_loss: 2.4845 - val_accuracy: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3303 - accuracy: 0.0000e+00 - val_loss: 2.4830 - val_accuracy: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3291 - accuracy: 0.0000e+00 - val_loss: 2.4817 - val_accuracy: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3262 - accuracy: 0.0000e+00 - val_loss: 2.4804 - val_accuracy: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3199 - accuracy: 0.0000e+00 - val_loss: 2.4784 - val_accuracy: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3174 - accuracy: 0.0000e+00 - val_loss: 2.4774 - val_accuracy: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3145 - accuracy: 0.0000e+00 - val_loss: 2.4763 - val_accuracy: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3110 - accuracy: 0.0000e+00 - val_loss: 2.4753 - val_accuracy: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3096 - accuracy: 0.0000e+00 - val_loss: 2.4695 - val_accuracy: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3086 - accuracy: 0.0000e+00 - val_loss: 2.4681 - val_accuracy: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3023 - accuracy: 0.0000e+00 - val_loss: 2.4560 - val_accuracy: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3005 - accuracy: 0.0000e+00 - val_loss: 2.4554 - val_accuracy: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2996 - accuracy: 0.0000e+00 - val_loss: 2.4508 - val_accuracy: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.3007 - accuracy: 0.0052 - val_loss: 2.4621 - val_accuracy: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2967 - accuracy: 0.0052 - val_loss: 2.4596 - val_accuracy: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2928 - accuracy: 0.0052 - val_loss: 2.4575 - val_accuracy: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2893 - accuracy: 0.0052 - val_loss: 2.4555 - val_accuracy: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2873 - accuracy: 0.0052 - val_loss: 2.4508 - val_accuracy: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2842 - accuracy: 0.0052 - val_loss: 2.4473 - val_accuracy: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2805 - accuracy: 0.0052 - val_loss: 2.4455 - val_accuracy: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2790 - accuracy: 0.0052 - val_loss: 2.4393 - val_accuracy: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.2777 - accuracy: 0.0052 - val_loss: 2.4377 - val_accuracy: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.2764 - accuracy: 0.0052 - val_loss: 2.4314 - val_accuracy: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.2743 - accuracy: 0.0052 - val_loss: 2.1707 - val_accuracy: 0.0104\n",
            "Epoch 430/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0758 - accuracy: 0.0069 - val_loss: 2.1578 - val_accuracy: 0.0104\n",
            "Epoch 431/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0651 - accuracy: 0.0069 - val_loss: 2.1433 - val_accuracy: 0.0104\n",
            "Epoch 432/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0418 - accuracy: 0.0069 - val_loss: 2.1322 - val_accuracy: 0.0104\n",
            "Epoch 433/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9764 - accuracy: 0.0104 - val_loss: 2.0988 - val_accuracy: 0.0104\n",
            "Epoch 434/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.9544 - accuracy: 0.0104 - val_loss: 2.0962 - val_accuracy: 0.0104\n",
            "Epoch 435/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9429 - accuracy: 0.0122 - val_loss: 2.1063 - val_accuracy: 0.0104\n",
            "Epoch 436/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9404 - accuracy: 0.0104 - val_loss: 2.0983 - val_accuracy: 0.0104\n",
            "Epoch 437/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9340 - accuracy: 0.0104 - val_loss: 2.0959 - val_accuracy: 0.0104\n",
            "Epoch 438/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9223 - accuracy: 0.0104 - val_loss: 2.0930 - val_accuracy: 0.0052\n",
            "Epoch 439/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.9058 - accuracy: 0.0104 - val_loss: 2.0711 - val_accuracy: 0.0052\n",
            "Epoch 440/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8708 - accuracy: 0.0139 - val_loss: 2.0532 - val_accuracy: 0.0521\n",
            "Epoch 441/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8518 - accuracy: 0.0417 - val_loss: 2.0523 - val_accuracy: 0.0521\n",
            "Epoch 442/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8504 - accuracy: 0.0399 - val_loss: 2.0515 - val_accuracy: 0.0521\n",
            "Epoch 443/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8493 - accuracy: 0.0399 - val_loss: 2.0507 - val_accuracy: 0.0469\n",
            "Epoch 444/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8483 - accuracy: 0.0382 - val_loss: 2.0500 - val_accuracy: 0.0365\n",
            "Epoch 445/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8474 - accuracy: 0.0347 - val_loss: 2.0447 - val_accuracy: 0.0312\n",
            "Epoch 446/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8465 - accuracy: 0.0330 - val_loss: 2.0437 - val_accuracy: 0.0312\n",
            "Epoch 447/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8457 - accuracy: 0.0312 - val_loss: 2.0386 - val_accuracy: 0.0260\n",
            "Epoch 448/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8448 - accuracy: 0.0312 - val_loss: 2.0375 - val_accuracy: 0.0260\n",
            "Epoch 449/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8441 - accuracy: 0.0295 - val_loss: 2.0368 - val_accuracy: 0.0156\n",
            "Epoch 450/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8417 - accuracy: 0.0295 - val_loss: 2.0293 - val_accuracy: 0.0104\n",
            "Epoch 451/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.8340 - accuracy: 0.0278 - val_loss: 2.0288 - val_accuracy: 0.0104\n",
            "Epoch 452/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8329 - accuracy: 0.0278 - val_loss: 2.0319 - val_accuracy: 0.0104\n",
            "Epoch 453/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8321 - accuracy: 0.0260 - val_loss: 2.0312 - val_accuracy: 0.0104\n",
            "Epoch 454/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8314 - accuracy: 0.0260 - val_loss: 2.0305 - val_accuracy: 0.0104\n",
            "Epoch 455/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8307 - accuracy: 0.0260 - val_loss: 2.0298 - val_accuracy: 0.0104\n",
            "Epoch 456/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8219 - accuracy: 0.0243 - val_loss: 2.0126 - val_accuracy: 0.0104\n",
            "Epoch 457/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8166 - accuracy: 0.0226 - val_loss: 2.0116 - val_accuracy: 0.0104\n",
            "Epoch 458/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8137 - accuracy: 0.0226 - val_loss: 2.0106 - val_accuracy: 0.0208\n",
            "Epoch 459/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8135 - accuracy: 0.0243 - val_loss: 2.0099 - val_accuracy: 0.0104\n",
            "Epoch 460/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8035 - accuracy: 0.0243 - val_loss: 2.0086 - val_accuracy: 0.0104\n",
            "Epoch 461/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7995 - accuracy: 0.0243 - val_loss: 2.0079 - val_accuracy: 0.0104\n",
            "Epoch 462/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.7806 - accuracy: 0.0243 - val_loss: 1.9847 - val_accuracy: 0.0104\n",
            "Epoch 463/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.7791 - accuracy: 0.0243 - val_loss: 1.9839 - val_accuracy: 0.0104\n",
            "Epoch 464/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7765 - accuracy: 0.0243 - val_loss: 1.9830 - val_accuracy: 0.0104\n",
            "Epoch 465/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.7753 - accuracy: 0.0243 - val_loss: 1.9824 - val_accuracy: 0.0104\n",
            "Epoch 466/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.7745 - accuracy: 0.0243 - val_loss: 1.9819 - val_accuracy: 0.0104\n",
            "Epoch 467/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7738 - accuracy: 0.0243 - val_loss: 1.9815 - val_accuracy: 0.0104\n",
            "Epoch 468/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7714 - accuracy: 0.0243 - val_loss: 1.9815 - val_accuracy: 0.0104\n",
            "Epoch 469/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7704 - accuracy: 0.0243 - val_loss: 1.9843 - val_accuracy: 0.0104\n",
            "Epoch 470/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7697 - accuracy: 0.0243 - val_loss: 1.9837 - val_accuracy: 0.0104\n",
            "Epoch 471/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7690 - accuracy: 0.0243 - val_loss: 1.9831 - val_accuracy: 0.0104\n",
            "Epoch 472/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7684 - accuracy: 0.0243 - val_loss: 1.9826 - val_accuracy: 0.0104\n",
            "Epoch 473/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7661 - accuracy: 0.0243 - val_loss: 1.9820 - val_accuracy: 0.0104\n",
            "Epoch 474/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7652 - accuracy: 0.0243 - val_loss: 1.9814 - val_accuracy: 0.0104\n",
            "Epoch 475/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7629 - accuracy: 0.0208 - val_loss: 1.9809 - val_accuracy: 0.0104\n",
            "Epoch 476/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7619 - accuracy: 0.0208 - val_loss: 1.9804 - val_accuracy: 0.0104\n",
            "Epoch 477/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7613 - accuracy: 0.0208 - val_loss: 1.9799 - val_accuracy: 0.0104\n",
            "Epoch 478/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7607 - accuracy: 0.0174 - val_loss: 1.9763 - val_accuracy: 0.0104\n",
            "Epoch 479/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7602 - accuracy: 0.0174 - val_loss: 1.9744 - val_accuracy: 0.0104\n",
            "Epoch 480/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7597 - accuracy: 0.0174 - val_loss: 1.9736 - val_accuracy: 0.0104\n",
            "Epoch 481/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7592 - accuracy: 0.0156 - val_loss: 1.9730 - val_accuracy: 0.0052\n",
            "Epoch 482/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7587 - accuracy: 0.0156 - val_loss: 1.9724 - val_accuracy: 0.0052\n",
            "Epoch 483/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7582 - accuracy: 0.0104 - val_loss: 1.9718 - val_accuracy: 0.0052\n",
            "Epoch 484/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7577 - accuracy: 0.0069 - val_loss: 1.9713 - val_accuracy: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7572 - accuracy: 0.0035 - val_loss: 1.9709 - val_accuracy: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7568 - accuracy: 0.0035 - val_loss: 1.9704 - val_accuracy: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7564 - accuracy: 0.0035 - val_loss: 1.9699 - val_accuracy: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7559 - accuracy: 0.0035 - val_loss: 1.9695 - val_accuracy: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7555 - accuracy: 0.0035 - val_loss: 1.9691 - val_accuracy: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7515 - accuracy: 0.0035 - val_loss: 1.9612 - val_accuracy: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7478 - accuracy: 0.0035 - val_loss: 1.9607 - val_accuracy: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7458 - accuracy: 0.0035 - val_loss: 1.9547 - val_accuracy: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7432 - accuracy: 0.0017 - val_loss: 1.9536 - val_accuracy: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7421 - accuracy: 0.0017 - val_loss: 1.9531 - val_accuracy: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7402 - accuracy: 0.0017 - val_loss: 1.9522 - val_accuracy: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7373 - accuracy: 0.0017 - val_loss: 1.9516 - val_accuracy: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7362 - accuracy: 0.0000e+00 - val_loss: 1.9512 - val_accuracy: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7358 - accuracy: 0.0000e+00 - val_loss: 1.9508 - val_accuracy: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7321 - accuracy: 0.0000e+00 - val_loss: 1.9501 - val_accuracy: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7309 - accuracy: 0.0000e+00 - val_loss: 1.9497 - val_accuracy: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7304 - accuracy: 0.0000e+00 - val_loss: 1.9493 - val_accuracy: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7299 - accuracy: 0.0000e+00 - val_loss: 1.9489 - val_accuracy: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7295 - accuracy: 0.0000e+00 - val_loss: 1.9485 - val_accuracy: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7291 - accuracy: 0.0000e+00 - val_loss: 1.9482 - val_accuracy: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7287 - accuracy: 0.0000e+00 - val_loss: 1.9479 - val_accuracy: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7283 - accuracy: 0.0000e+00 - val_loss: 1.9475 - val_accuracy: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7279 - accuracy: 0.0000e+00 - val_loss: 1.9472 - val_accuracy: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7275 - accuracy: 0.0000e+00 - val_loss: 1.9469 - val_accuracy: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7272 - accuracy: 0.0000e+00 - val_loss: 1.9466 - val_accuracy: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7268 - accuracy: 0.0000e+00 - val_loss: 1.9463 - val_accuracy: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7265 - accuracy: 0.0000e+00 - val_loss: 1.9460 - val_accuracy: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7261 - accuracy: 0.0000e+00 - val_loss: 1.9437 - val_accuracy: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7258 - accuracy: 0.0000e+00 - val_loss: 1.9411 - val_accuracy: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7255 - accuracy: 0.0000e+00 - val_loss: 1.9405 - val_accuracy: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7251 - accuracy: 0.0000e+00 - val_loss: 1.9400 - val_accuracy: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7248 - accuracy: 0.0000e+00 - val_loss: 1.9396 - val_accuracy: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7245 - accuracy: 0.0000e+00 - val_loss: 1.9392 - val_accuracy: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7242 - accuracy: 0.0000e+00 - val_loss: 1.9389 - val_accuracy: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7239 - accuracy: 0.0000e+00 - val_loss: 1.9386 - val_accuracy: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7236 - accuracy: 0.0000e+00 - val_loss: 1.9383 - val_accuracy: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7233 - accuracy: 0.0000e+00 - val_loss: 1.9380 - val_accuracy: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7178 - accuracy: 0.0000e+00 - val_loss: 1.9272 - val_accuracy: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7064 - accuracy: 0.0000e+00 - val_loss: 1.9268 - val_accuracy: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7058 - accuracy: 0.0000e+00 - val_loss: 1.9265 - val_accuracy: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7054 - accuracy: 0.0000e+00 - val_loss: 1.9218 - val_accuracy: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7051 - accuracy: 0.0000e+00 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7047 - accuracy: 0.0000e+00 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7044 - accuracy: 0.0000e+00 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7042 - accuracy: 0.0000e+00 - val_loss: 1.8958 - val_accuracy: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7001 - accuracy: 0.0000e+00 - val_loss: 1.8950 - val_accuracy: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6999 - accuracy: 0.0000e+00 - val_loss: 1.8944 - val_accuracy: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6981 - accuracy: 0.0000e+00 - val_loss: 1.8841 - val_accuracy: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6971 - accuracy: 0.0000e+00 - val_loss: 1.8833 - val_accuracy: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6968 - accuracy: 0.0000e+00 - val_loss: 1.8827 - val_accuracy: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6965 - accuracy: 0.0000e+00 - val_loss: 1.8821 - val_accuracy: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6963 - accuracy: 0.0000e+00 - val_loss: 1.8816 - val_accuracy: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6960 - accuracy: 0.0000e+00 - val_loss: 1.8811 - val_accuracy: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6943 - accuracy: 0.0000e+00 - val_loss: 1.8665 - val_accuracy: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6854 - accuracy: 0.0000e+00 - val_loss: 1.8660 - val_accuracy: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6850 - accuracy: 0.0000e+00 - val_loss: 1.8656 - val_accuracy: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6813 - accuracy: 0.0000e+00 - val_loss: 1.8640 - val_accuracy: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6755 - accuracy: 0.0000e+00 - val_loss: 1.8608 - val_accuracy: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.0000e+00 - val_loss: 1.8604 - val_accuracy: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6718 - accuracy: 0.0000e+00 - val_loss: 1.8601 - val_accuracy: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6714 - accuracy: 0.0000e+00 - val_loss: 1.8597 - val_accuracy: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6710 - accuracy: 0.0000e+00 - val_loss: 1.8594 - val_accuracy: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6707 - accuracy: 0.0000e+00 - val_loss: 1.8591 - val_accuracy: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6703 - accuracy: 0.0000e+00 - val_loss: 1.8588 - val_accuracy: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6700 - accuracy: 0.0000e+00 - val_loss: 1.8585 - val_accuracy: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6697 - accuracy: 0.0000e+00 - val_loss: 1.8583 - val_accuracy: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6694 - accuracy: 0.0000e+00 - val_loss: 1.8580 - val_accuracy: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6691 - accuracy: 0.0000e+00 - val_loss: 1.8577 - val_accuracy: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6688 - accuracy: 0.0000e+00 - val_loss: 1.8575 - val_accuracy: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6686 - accuracy: 0.0000e+00 - val_loss: 1.8572 - val_accuracy: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6683 - accuracy: 0.0000e+00 - val_loss: 1.8570 - val_accuracy: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6680 - accuracy: 0.0000e+00 - val_loss: 1.8568 - val_accuracy: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6678 - accuracy: 0.0000e+00 - val_loss: 1.8566 - val_accuracy: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6675 - accuracy: 0.0017 - val_loss: 1.8563 - val_accuracy: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6673 - accuracy: 0.0017 - val_loss: 1.8561 - val_accuracy: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6670 - accuracy: 0.0017 - val_loss: 1.8559 - val_accuracy: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6668 - accuracy: 0.0017 - val_loss: 1.8557 - val_accuracy: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6665 - accuracy: 0.0017 - val_loss: 1.8555 - val_accuracy: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6663 - accuracy: 0.0017 - val_loss: 1.8553 - val_accuracy: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6661 - accuracy: 0.0017 - val_loss: 1.8551 - val_accuracy: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6631 - accuracy: 0.0017 - val_loss: 1.8534 - val_accuracy: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6613 - accuracy: 0.0017 - val_loss: 1.8532 - val_accuracy: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6610 - accuracy: 0.0017 - val_loss: 1.8530 - val_accuracy: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6608 - accuracy: 0.0017 - val_loss: 1.8528 - val_accuracy: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6606 - accuracy: 0.0017 - val_loss: 1.8526 - val_accuracy: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6603 - accuracy: 0.0017 - val_loss: 1.8524 - val_accuracy: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6601 - accuracy: 0.0017 - val_loss: 1.8523 - val_accuracy: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6582 - accuracy: 0.0017 - val_loss: 1.8520 - val_accuracy: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6576 - accuracy: 0.0017 - val_loss: 1.8518 - val_accuracy: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6573 - accuracy: 0.0017 - val_loss: 1.8517 - val_accuracy: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6571 - accuracy: 0.0017 - val_loss: 1.8515 - val_accuracy: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6554 - accuracy: 0.0017 - val_loss: 1.8509 - val_accuracy: 0.0052\n",
            "Epoch 577/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6542 - accuracy: 0.0017 - val_loss: 1.8507 - val_accuracy: 0.0052\n",
            "Epoch 578/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6540 - accuracy: 0.0017 - val_loss: 1.8505 - val_accuracy: 0.0052\n",
            "Epoch 579/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6537 - accuracy: 0.0017 - val_loss: 1.8503 - val_accuracy: 0.0052\n",
            "Epoch 580/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6535 - accuracy: 0.0017 - val_loss: 1.8501 - val_accuracy: 0.0052\n",
            "Epoch 581/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6534 - accuracy: 0.0017 - val_loss: 1.8466 - val_accuracy: 0.0052\n",
            "Epoch 582/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6532 - accuracy: 0.0017 - val_loss: 1.8459 - val_accuracy: 0.0052\n",
            "Epoch 583/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6530 - accuracy: 0.0017 - val_loss: 1.8455 - val_accuracy: 0.0052\n",
            "Epoch 584/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6528 - accuracy: 0.0017 - val_loss: 1.8452 - val_accuracy: 0.0052\n",
            "Epoch 585/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6526 - accuracy: 0.0017 - val_loss: 1.8449 - val_accuracy: 0.0052\n",
            "Epoch 586/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6524 - accuracy: 0.0035 - val_loss: 1.8447 - val_accuracy: 0.0052\n",
            "Epoch 587/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6522 - accuracy: 0.0035 - val_loss: 1.8444 - val_accuracy: 0.0052\n",
            "Epoch 588/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6520 - accuracy: 0.0035 - val_loss: 1.8442 - val_accuracy: 0.0052\n",
            "Epoch 589/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6519 - accuracy: 0.0035 - val_loss: 1.8440 - val_accuracy: 0.0052\n",
            "Epoch 590/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6517 - accuracy: 0.0035 - val_loss: 1.8438 - val_accuracy: 0.0052\n",
            "Epoch 591/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.6515 - accuracy: 0.0035 - val_loss: 1.8436 - val_accuracy: 0.0052\n",
            "Epoch 592/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6514 - accuracy: 0.0035 - val_loss: 1.8434 - val_accuracy: 0.0052\n",
            "Epoch 593/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6512 - accuracy: 0.0035 - val_loss: 1.8433 - val_accuracy: 0.0052\n",
            "Epoch 594/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6451 - accuracy: 0.0035 - val_loss: 1.8345 - val_accuracy: 0.0052\n",
            "Epoch 595/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6394 - accuracy: 0.0035 - val_loss: 1.8339 - val_accuracy: 0.0052\n",
            "Epoch 596/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6363 - accuracy: 0.0035 - val_loss: 1.8338 - val_accuracy: 0.0052\n",
            "Epoch 597/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6322 - accuracy: 0.0035 - val_loss: 1.8334 - val_accuracy: 0.0052\n",
            "Epoch 598/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6169 - accuracy: 0.0035 - val_loss: 1.7774 - val_accuracy: 0.0052\n",
            "Epoch 599/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.6164 - accuracy: 0.0052 - val_loss: 1.7763 - val_accuracy: 0.0052\n",
            "Epoch 600/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6159 - accuracy: 0.0069 - val_loss: 1.7758 - val_accuracy: 0.0052\n",
            "Epoch 601/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.6156 - accuracy: 0.0069 - val_loss: 1.7755 - val_accuracy: 0.0052\n",
            "Epoch 602/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6153 - accuracy: 0.0069 - val_loss: 1.7752 - val_accuracy: 0.0052\n",
            "Epoch 603/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6113 - accuracy: 0.0069 - val_loss: 1.7794 - val_accuracy: 0.0052\n",
            "Epoch 604/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6101 - accuracy: 0.0069 - val_loss: 1.7792 - val_accuracy: 0.0052\n",
            "Epoch 605/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6098 - accuracy: 0.0069 - val_loss: 1.7791 - val_accuracy: 0.0052\n",
            "Epoch 606/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6079 - accuracy: 0.0069 - val_loss: 1.7785 - val_accuracy: 0.0052\n",
            "Epoch 607/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.6040 - accuracy: 0.0069 - val_loss: 1.7779 - val_accuracy: 0.0052\n",
            "Epoch 608/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5993 - accuracy: 0.0104 - val_loss: 1.7620 - val_accuracy: 0.0052\n",
            "Epoch 609/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.6014 - accuracy: 0.0104 - val_loss: 1.7619 - val_accuracy: 0.0052\n",
            "Epoch 610/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5986 - accuracy: 0.0104 - val_loss: 1.7675 - val_accuracy: 0.0052\n",
            "Epoch 611/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5944 - accuracy: 0.0104 - val_loss: 1.7673 - val_accuracy: 0.0052\n",
            "Epoch 612/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5941 - accuracy: 0.0104 - val_loss: 1.7672 - val_accuracy: 0.0052\n",
            "Epoch 613/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.5938 - accuracy: 0.0104 - val_loss: 1.7671 - val_accuracy: 0.0052\n",
            "Epoch 614/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5936 - accuracy: 0.0104 - val_loss: 1.7669 - val_accuracy: 0.0052\n",
            "Epoch 615/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5934 - accuracy: 0.0104 - val_loss: 1.7668 - val_accuracy: 0.0052\n",
            "Epoch 616/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5931 - accuracy: 0.0104 - val_loss: 1.7667 - val_accuracy: 0.0052\n",
            "Epoch 617/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5929 - accuracy: 0.0104 - val_loss: 1.7666 - val_accuracy: 0.0052\n",
            "Epoch 618/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5927 - accuracy: 0.0104 - val_loss: 1.7665 - val_accuracy: 0.0052\n",
            "Epoch 619/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5860 - accuracy: 0.0104 - val_loss: 1.7661 - val_accuracy: 0.0052\n",
            "Epoch 620/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5811 - accuracy: 0.0104 - val_loss: 1.7660 - val_accuracy: 0.0052\n",
            "Epoch 621/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5800 - accuracy: 0.0104 - val_loss: 1.7660 - val_accuracy: 0.0052\n",
            "Epoch 622/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5799 - accuracy: 0.0104 - val_loss: 1.7659 - val_accuracy: 0.0052\n",
            "Epoch 623/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5796 - accuracy: 0.0122 - val_loss: 1.7659 - val_accuracy: 0.0052\n",
            "Epoch 624/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5794 - accuracy: 0.0122 - val_loss: 1.7659 - val_accuracy: 0.0052\n",
            "Epoch 625/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5793 - accuracy: 0.0139 - val_loss: 1.7659 - val_accuracy: 0.0104\n",
            "Epoch 626/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5791 - accuracy: 0.0139 - val_loss: 1.7659 - val_accuracy: 0.0104\n",
            "Epoch 627/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5756 - accuracy: 0.0139 - val_loss: 1.7701 - val_accuracy: 0.0156\n",
            "Epoch 628/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5742 - accuracy: 0.0156 - val_loss: 1.7700 - val_accuracy: 0.0156\n",
            "Epoch 629/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5739 - accuracy: 0.0156 - val_loss: 1.7700 - val_accuracy: 0.0156\n",
            "Epoch 630/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5725 - accuracy: 0.0156 - val_loss: 1.7698 - val_accuracy: 0.0156\n",
            "Epoch 631/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5713 - accuracy: 0.0156 - val_loss: 1.7697 - val_accuracy: 0.0156\n",
            "Epoch 632/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5711 - accuracy: 0.0156 - val_loss: 1.7657 - val_accuracy: 0.0156\n",
            "Epoch 633/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5709 - accuracy: 0.0156 - val_loss: 1.7649 - val_accuracy: 0.0156\n",
            "Epoch 634/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5707 - accuracy: 0.0156 - val_loss: 1.7646 - val_accuracy: 0.0156\n",
            "Epoch 635/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5705 - accuracy: 0.0174 - val_loss: 1.7643 - val_accuracy: 0.0156\n",
            "Epoch 636/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5704 - accuracy: 0.0208 - val_loss: 1.7641 - val_accuracy: 0.0156\n",
            "Epoch 637/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5702 - accuracy: 0.0208 - val_loss: 1.7639 - val_accuracy: 0.0156\n",
            "Epoch 638/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5700 - accuracy: 0.0226 - val_loss: 1.7638 - val_accuracy: 0.0156\n",
            "Epoch 639/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5699 - accuracy: 0.0226 - val_loss: 1.7636 - val_accuracy: 0.0156\n",
            "Epoch 640/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5681 - accuracy: 0.0226 - val_loss: 1.7588 - val_accuracy: 0.0156\n",
            "Epoch 641/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5671 - accuracy: 0.0226 - val_loss: 1.7624 - val_accuracy: 0.0156\n",
            "Epoch 642/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5668 - accuracy: 0.0226 - val_loss: 1.7623 - val_accuracy: 0.0156\n",
            "Epoch 643/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5667 - accuracy: 0.0226 - val_loss: 1.7622 - val_accuracy: 0.0156\n",
            "Epoch 644/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5665 - accuracy: 0.0226 - val_loss: 1.7622 - val_accuracy: 0.0156\n",
            "Epoch 645/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5663 - accuracy: 0.0226 - val_loss: 1.7621 - val_accuracy: 0.0156\n",
            "Epoch 646/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5662 - accuracy: 0.0226 - val_loss: 1.7620 - val_accuracy: 0.0156\n",
            "Epoch 647/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5661 - accuracy: 0.0226 - val_loss: 1.7619 - val_accuracy: 0.0156\n",
            "Epoch 648/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5659 - accuracy: 0.0226 - val_loss: 1.7618 - val_accuracy: 0.0208\n",
            "Epoch 649/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5658 - accuracy: 0.0226 - val_loss: 1.7618 - val_accuracy: 0.0208\n",
            "Epoch 650/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5657 - accuracy: 0.0226 - val_loss: 1.7617 - val_accuracy: 0.0208\n",
            "Epoch 651/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5655 - accuracy: 0.0226 - val_loss: 1.7616 - val_accuracy: 0.0208\n",
            "Epoch 652/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5654 - accuracy: 0.0243 - val_loss: 1.7616 - val_accuracy: 0.0208\n",
            "Epoch 653/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5653 - accuracy: 0.0226 - val_loss: 1.7615 - val_accuracy: 0.0208\n",
            "Epoch 654/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5651 - accuracy: 0.0243 - val_loss: 1.7614 - val_accuracy: 0.0208\n",
            "Epoch 655/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5650 - accuracy: 0.0243 - val_loss: 1.7614 - val_accuracy: 0.0208\n",
            "Epoch 656/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5649 - accuracy: 0.0243 - val_loss: 1.7613 - val_accuracy: 0.0208\n",
            "Epoch 657/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5648 - accuracy: 0.0243 - val_loss: 1.7612 - val_accuracy: 0.0208\n",
            "Epoch 658/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5646 - accuracy: 0.0243 - val_loss: 1.7612 - val_accuracy: 0.0208\n",
            "Epoch 659/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5645 - accuracy: 0.0243 - val_loss: 1.7611 - val_accuracy: 0.0208\n",
            "Epoch 660/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5644 - accuracy: 0.0243 - val_loss: 1.7611 - val_accuracy: 0.0208\n",
            "Epoch 661/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5643 - accuracy: 0.0243 - val_loss: 1.7610 - val_accuracy: 0.0208\n",
            "Epoch 662/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5642 - accuracy: 0.0243 - val_loss: 1.7609 - val_accuracy: 0.0208\n",
            "Epoch 663/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5641 - accuracy: 0.0243 - val_loss: 1.7609 - val_accuracy: 0.0208\n",
            "Epoch 664/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5640 - accuracy: 0.0243 - val_loss: 1.7608 - val_accuracy: 0.0208\n",
            "Epoch 665/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5639 - accuracy: 0.0243 - val_loss: 1.7608 - val_accuracy: 0.0208\n",
            "Epoch 666/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5637 - accuracy: 0.0243 - val_loss: 1.7607 - val_accuracy: 0.0208\n",
            "Epoch 667/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5621 - accuracy: 0.0243 - val_loss: 1.7604 - val_accuracy: 0.0208\n",
            "Epoch 668/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5603 - accuracy: 0.0243 - val_loss: 1.7616 - val_accuracy: 0.0208\n",
            "Epoch 669/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5587 - accuracy: 0.0243 - val_loss: 1.7615 - val_accuracy: 0.0208\n",
            "Epoch 670/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5568 - accuracy: 0.0243 - val_loss: 1.7669 - val_accuracy: 0.0208\n",
            "Epoch 671/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5579 - accuracy: 0.0243 - val_loss: 1.7669 - val_accuracy: 0.0208\n",
            "Epoch 672/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5561 - accuracy: 0.0243 - val_loss: 1.7668 - val_accuracy: 0.0208\n",
            "Epoch 673/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5556 - accuracy: 0.0243 - val_loss: 1.7668 - val_accuracy: 0.0208\n",
            "Epoch 674/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5554 - accuracy: 0.0243 - val_loss: 1.7668 - val_accuracy: 0.0208\n",
            "Epoch 675/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5552 - accuracy: 0.0243 - val_loss: 1.7668 - val_accuracy: 0.0208\n",
            "Epoch 676/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5551 - accuracy: 0.0243 - val_loss: 1.7668 - val_accuracy: 0.0208\n",
            "Epoch 677/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5549 - accuracy: 0.0243 - val_loss: 1.7669 - val_accuracy: 0.0208\n",
            "Epoch 678/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5548 - accuracy: 0.0243 - val_loss: 1.7669 - val_accuracy: 0.0208\n",
            "Epoch 679/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5534 - accuracy: 0.0243 - val_loss: 1.7657 - val_accuracy: 0.0208\n",
            "Epoch 680/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5524 - accuracy: 0.0260 - val_loss: 1.7658 - val_accuracy: 0.0208\n",
            "Epoch 681/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5523 - accuracy: 0.0278 - val_loss: 1.7659 - val_accuracy: 0.0208\n",
            "Epoch 682/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5511 - accuracy: 0.0295 - val_loss: 1.7599 - val_accuracy: 0.0208\n",
            "Epoch 683/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5451 - accuracy: 0.0295 - val_loss: 1.7643 - val_accuracy: 0.0208\n",
            "Epoch 684/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5418 - accuracy: 0.0295 - val_loss: 1.7641 - val_accuracy: 0.0208\n",
            "Epoch 685/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5415 - accuracy: 0.0295 - val_loss: 1.7639 - val_accuracy: 0.0208\n",
            "Epoch 686/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5413 - accuracy: 0.0295 - val_loss: 1.7638 - val_accuracy: 0.0208\n",
            "Epoch 687/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5411 - accuracy: 0.0295 - val_loss: 1.7637 - val_accuracy: 0.0208\n",
            "Epoch 688/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5409 - accuracy: 0.0295 - val_loss: 1.7636 - val_accuracy: 0.0208\n",
            "Epoch 689/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5407 - accuracy: 0.0295 - val_loss: 1.7636 - val_accuracy: 0.0208\n",
            "Epoch 690/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5406 - accuracy: 0.0295 - val_loss: 1.7635 - val_accuracy: 0.0208\n",
            "Epoch 691/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5405 - accuracy: 0.0295 - val_loss: 1.7634 - val_accuracy: 0.0208\n",
            "Epoch 692/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5403 - accuracy: 0.0295 - val_loss: 1.7633 - val_accuracy: 0.0208\n",
            "Epoch 693/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5402 - accuracy: 0.0295 - val_loss: 1.7632 - val_accuracy: 0.0208\n",
            "Epoch 694/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5400 - accuracy: 0.0295 - val_loss: 1.7632 - val_accuracy: 0.0208\n",
            "Epoch 695/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5399 - accuracy: 0.0295 - val_loss: 1.7631 - val_accuracy: 0.0208\n",
            "Epoch 696/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5398 - accuracy: 0.0295 - val_loss: 1.7630 - val_accuracy: 0.0208\n",
            "Epoch 697/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5397 - accuracy: 0.0295 - val_loss: 1.7630 - val_accuracy: 0.0208\n",
            "Epoch 698/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5395 - accuracy: 0.0295 - val_loss: 1.7593 - val_accuracy: 0.0208\n",
            "Epoch 699/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5394 - accuracy: 0.0312 - val_loss: 1.7581 - val_accuracy: 0.0208\n",
            "Epoch 700/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5393 - accuracy: 0.0330 - val_loss: 1.7544 - val_accuracy: 0.0208\n",
            "Epoch 701/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5392 - accuracy: 0.0330 - val_loss: 1.7530 - val_accuracy: 0.0208\n",
            "Epoch 702/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5391 - accuracy: 0.0330 - val_loss: 1.7525 - val_accuracy: 0.0208\n",
            "Epoch 703/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5390 - accuracy: 0.0330 - val_loss: 1.7521 - val_accuracy: 0.0208\n",
            "Epoch 704/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5388 - accuracy: 0.0330 - val_loss: 1.7519 - val_accuracy: 0.0208\n",
            "Epoch 705/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5387 - accuracy: 0.0330 - val_loss: 1.7516 - val_accuracy: 0.0208\n",
            "Epoch 706/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5386 - accuracy: 0.0330 - val_loss: 1.7514 - val_accuracy: 0.0208\n",
            "Epoch 707/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5385 - accuracy: 0.0330 - val_loss: 1.7512 - val_accuracy: 0.0208\n",
            "Epoch 708/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5384 - accuracy: 0.0330 - val_loss: 1.7511 - val_accuracy: 0.0208\n",
            "Epoch 709/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5383 - accuracy: 0.0330 - val_loss: 1.7509 - val_accuracy: 0.0208\n",
            "Epoch 710/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.5382 - accuracy: 0.0347 - val_loss: 1.7508 - val_accuracy: 0.0208\n",
            "Epoch 711/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5381 - accuracy: 0.0347 - val_loss: 1.7506 - val_accuracy: 0.0208\n",
            "Epoch 712/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5380 - accuracy: 0.0365 - val_loss: 1.7505 - val_accuracy: 0.0208\n",
            "Epoch 713/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5379 - accuracy: 0.0365 - val_loss: 1.7504 - val_accuracy: 0.0208\n",
            "Epoch 714/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5378 - accuracy: 0.0365 - val_loss: 1.7503 - val_accuracy: 0.0208\n",
            "Epoch 715/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5377 - accuracy: 0.0365 - val_loss: 1.7502 - val_accuracy: 0.0208\n",
            "Epoch 716/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5325 - accuracy: 0.0365 - val_loss: 1.7494 - val_accuracy: 0.0208\n",
            "Epoch 717/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.5294 - accuracy: 0.0382 - val_loss: 1.7492 - val_accuracy: 0.0208\n",
            "Epoch 718/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.5283 - accuracy: 0.0382 - val_loss: 1.7491 - val_accuracy: 0.0208\n",
            "Epoch 719/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4884 - accuracy: 0.0399 - val_loss: 1.6831 - val_accuracy: 0.0260\n",
            "Epoch 720/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4703 - accuracy: 0.0417 - val_loss: 1.6823 - val_accuracy: 0.0312\n",
            "Epoch 721/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4681 - accuracy: 0.0417 - val_loss: 1.6813 - val_accuracy: 0.0312\n",
            "Epoch 722/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4675 - accuracy: 0.0417 - val_loss: 1.6810 - val_accuracy: 0.0312\n",
            "Epoch 723/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4672 - accuracy: 0.0417 - val_loss: 1.6807 - val_accuracy: 0.0365\n",
            "Epoch 724/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4670 - accuracy: 0.0451 - val_loss: 1.6805 - val_accuracy: 0.0417\n",
            "Epoch 725/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4667 - accuracy: 0.0469 - val_loss: 1.6803 - val_accuracy: 0.0417\n",
            "Epoch 726/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4648 - accuracy: 0.0451 - val_loss: 1.6751 - val_accuracy: 0.0417\n",
            "Epoch 727/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4608 - accuracy: 0.0469 - val_loss: 1.6736 - val_accuracy: 0.0417\n",
            "Epoch 728/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4587 - accuracy: 0.0486 - val_loss: 1.6745 - val_accuracy: 0.0417\n",
            "Epoch 729/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4556 - accuracy: 0.0469 - val_loss: 1.6742 - val_accuracy: 0.0417\n",
            "Epoch 730/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4536 - accuracy: 0.0469 - val_loss: 1.6739 - val_accuracy: 0.0417\n",
            "Epoch 731/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4530 - accuracy: 0.0469 - val_loss: 1.6737 - val_accuracy: 0.0469\n",
            "Epoch 732/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4527 - accuracy: 0.0486 - val_loss: 1.6736 - val_accuracy: 0.0521\n",
            "Epoch 733/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4524 - accuracy: 0.0486 - val_loss: 1.6735 - val_accuracy: 0.0521\n",
            "Epoch 734/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.4522 - accuracy: 0.0503 - val_loss: 1.6733 - val_accuracy: 0.0521\n",
            "Epoch 735/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4505 - accuracy: 0.0486 - val_loss: 1.6676 - val_accuracy: 0.0521\n",
            "Epoch 736/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4479 - accuracy: 0.0503 - val_loss: 1.6673 - val_accuracy: 0.0521\n",
            "Epoch 737/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4475 - accuracy: 0.0503 - val_loss: 1.6671 - val_accuracy: 0.0521\n",
            "Epoch 738/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4473 - accuracy: 0.0503 - val_loss: 1.6670 - val_accuracy: 0.0521\n",
            "Epoch 739/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4471 - accuracy: 0.0503 - val_loss: 1.6669 - val_accuracy: 0.0521\n",
            "Epoch 740/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4469 - accuracy: 0.0503 - val_loss: 1.6668 - val_accuracy: 0.0521\n",
            "Epoch 741/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4467 - accuracy: 0.0503 - val_loss: 1.6621 - val_accuracy: 0.0521\n",
            "Epoch 742/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4465 - accuracy: 0.0503 - val_loss: 1.6615 - val_accuracy: 0.0521\n",
            "Epoch 743/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4447 - accuracy: 0.0521 - val_loss: 1.6608 - val_accuracy: 0.0521\n",
            "Epoch 744/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4423 - accuracy: 0.0503 - val_loss: 1.6606 - val_accuracy: 0.0521\n",
            "Epoch 745/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4418 - accuracy: 0.0521 - val_loss: 1.6605 - val_accuracy: 0.0521\n",
            "Epoch 746/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4416 - accuracy: 0.0521 - val_loss: 1.6604 - val_accuracy: 0.0521\n",
            "Epoch 747/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.4414 - accuracy: 0.0538 - val_loss: 1.6604 - val_accuracy: 0.0521\n",
            "Epoch 748/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4395 - accuracy: 0.0538 - val_loss: 1.6656 - val_accuracy: 0.0521\n",
            "Epoch 749/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4388 - accuracy: 0.0538 - val_loss: 1.6656 - val_accuracy: 0.0521\n",
            "Epoch 750/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4386 - accuracy: 0.0538 - val_loss: 1.6655 - val_accuracy: 0.0521\n",
            "Epoch 751/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.4367 - accuracy: 0.0538 - val_loss: 1.6601 - val_accuracy: 0.0521\n",
            "Epoch 752/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4363 - accuracy: 0.0538 - val_loss: 1.6598 - val_accuracy: 0.0521\n",
            "Epoch 753/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.4344 - accuracy: 0.0538 - val_loss: 1.6596 - val_accuracy: 0.0521\n",
            "Epoch 754/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.4339 - accuracy: 0.0538 - val_loss: 1.6545 - val_accuracy: 0.0573\n",
            "Epoch 755/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4337 - accuracy: 0.0538 - val_loss: 1.6541 - val_accuracy: 0.0573\n",
            "Epoch 756/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.4335 - accuracy: 0.0538 - val_loss: 1.6539 - val_accuracy: 0.0573\n",
            "Epoch 757/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4333 - accuracy: 0.0538 - val_loss: 1.6538 - val_accuracy: 0.0573\n",
            "Epoch 758/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4296 - accuracy: 0.0538 - val_loss: 1.6537 - val_accuracy: 0.0573\n",
            "Epoch 759/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4285 - accuracy: 0.0556 - val_loss: 1.6536 - val_accuracy: 0.0573\n",
            "Epoch 760/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4266 - accuracy: 0.0556 - val_loss: 1.6639 - val_accuracy: 0.0625\n",
            "Epoch 761/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.4215 - accuracy: 0.0625 - val_loss: 1.6635 - val_accuracy: 0.0625\n",
            "Epoch 762/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6175 - accuracy: 0.0312 - val_loss: 1.9039 - val_accuracy: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8133 - accuracy: 0.0000e+00 - val_loss: 1.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8107 - accuracy: 0.0000e+00 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8100 - accuracy: 0.0000e+00 - val_loss: 1.9034 - val_accuracy: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8095 - accuracy: 0.0000e+00 - val_loss: 1.9033 - val_accuracy: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8074 - accuracy: 0.0000e+00 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8065 - accuracy: 0.0000e+00 - val_loss: 1.9037 - val_accuracy: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8061 - accuracy: 0.0000e+00 - val_loss: 1.9040 - val_accuracy: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8057 - accuracy: 0.0000e+00 - val_loss: 1.9087 - val_accuracy: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8054 - accuracy: 0.0000e+00 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.8051 - accuracy: 0.0000e+00 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.8012 - accuracy: 0.0000e+00 - val_loss: 1.9021 - val_accuracy: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7987 - accuracy: 0.0000e+00 - val_loss: 1.8352 - val_accuracy: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7695 - accuracy: 0.0035 - val_loss: 1.8282 - val_accuracy: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7666 - accuracy: 0.0035 - val_loss: 1.8290 - val_accuracy: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7658 - accuracy: 0.0035 - val_loss: 1.8281 - val_accuracy: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7652 - accuracy: 0.0035 - val_loss: 1.8275 - val_accuracy: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7631 - accuracy: 0.0035 - val_loss: 1.8309 - val_accuracy: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7622 - accuracy: 0.0035 - val_loss: 1.8303 - val_accuracy: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7618 - accuracy: 0.0035 - val_loss: 1.8297 - val_accuracy: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7614 - accuracy: 0.0035 - val_loss: 1.8292 - val_accuracy: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7610 - accuracy: 0.0035 - val_loss: 1.8288 - val_accuracy: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7607 - accuracy: 0.0035 - val_loss: 1.8284 - val_accuracy: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7604 - accuracy: 0.0035 - val_loss: 1.8280 - val_accuracy: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7601 - accuracy: 0.0035 - val_loss: 1.8229 - val_accuracy: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7585 - accuracy: 0.0035 - val_loss: 1.8218 - val_accuracy: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7533 - accuracy: 0.0035 - val_loss: 1.8213 - val_accuracy: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 1.7509 - accuracy: 0.0035 - val_loss: 1.8202 - val_accuracy: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.7502 - accuracy: 0.0035 - val_loss: 1.8198 - val_accuracy: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.9413 - accuracy: 0.0035 - val_loss: 2.1459 - val_accuracy: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1516 - accuracy: 0.0035 - val_loss: 2.1395 - val_accuracy: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1506 - accuracy: 0.0035 - val_loss: 2.1384 - val_accuracy: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1483 - accuracy: 0.0035 - val_loss: 2.1316 - val_accuracy: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1454 - accuracy: 0.0035 - val_loss: 2.1303 - val_accuracy: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1447 - accuracy: 0.0035 - val_loss: 2.1293 - val_accuracy: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1442 - accuracy: 0.0035 - val_loss: 2.1242 - val_accuracy: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1437 - accuracy: 0.0035 - val_loss: 2.1180 - val_accuracy: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1432 - accuracy: 0.0035 - val_loss: 2.1167 - val_accuracy: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1428 - accuracy: 0.0035 - val_loss: 2.1157 - val_accuracy: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1424 - accuracy: 0.0035 - val_loss: 2.1149 - val_accuracy: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1420 - accuracy: 0.0035 - val_loss: 2.1141 - val_accuracy: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1416 - accuracy: 0.0035 - val_loss: 2.1134 - val_accuracy: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1413 - accuracy: 0.0035 - val_loss: 2.1128 - val_accuracy: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1410 - accuracy: 0.0035 - val_loss: 2.1122 - val_accuracy: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1392 - accuracy: 0.0035 - val_loss: 2.1072 - val_accuracy: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1364 - accuracy: 0.0035 - val_loss: 2.1064 - val_accuracy: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1358 - accuracy: 0.0052 - val_loss: 2.1016 - val_accuracy: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1354 - accuracy: 0.0052 - val_loss: 2.1005 - val_accuracy: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1351 - accuracy: 0.0052 - val_loss: 2.0997 - val_accuracy: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1348 - accuracy: 0.0052 - val_loss: 2.0991 - val_accuracy: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1328 - accuracy: 0.0052 - val_loss: 2.1000 - val_accuracy: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1322 - accuracy: 0.0052 - val_loss: 2.1022 - val_accuracy: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1318 - accuracy: 0.0052 - val_loss: 2.1017 - val_accuracy: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1315 - accuracy: 0.0052 - val_loss: 2.1012 - val_accuracy: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1312 - accuracy: 0.0052 - val_loss: 2.1008 - val_accuracy: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1310 - accuracy: 0.0069 - val_loss: 2.1004 - val_accuracy: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1307 - accuracy: 0.0069 - val_loss: 2.1000 - val_accuracy: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1304 - accuracy: 0.0069 - val_loss: 2.0997 - val_accuracy: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1302 - accuracy: 0.0069 - val_loss: 2.0993 - val_accuracy: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1299 - accuracy: 0.0069 - val_loss: 2.0990 - val_accuracy: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1297 - accuracy: 0.0069 - val_loss: 2.0987 - val_accuracy: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1295 - accuracy: 0.0069 - val_loss: 2.0984 - val_accuracy: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1293 - accuracy: 0.0069 - val_loss: 2.0981 - val_accuracy: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1291 - accuracy: 0.0069 - val_loss: 2.0978 - val_accuracy: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1289 - accuracy: 0.0069 - val_loss: 2.0975 - val_accuracy: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1287 - accuracy: 0.0069 - val_loss: 2.0972 - val_accuracy: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1285 - accuracy: 0.0069 - val_loss: 2.0970 - val_accuracy: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1283 - accuracy: 0.0087 - val_loss: 2.0967 - val_accuracy: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1281 - accuracy: 0.0087 - val_loss: 2.0965 - val_accuracy: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1280 - accuracy: 0.0087 - val_loss: 2.0962 - val_accuracy: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1278 - accuracy: 0.0087 - val_loss: 2.0960 - val_accuracy: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1276 - accuracy: 0.0087 - val_loss: 2.0958 - val_accuracy: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1274 - accuracy: 0.0087 - val_loss: 2.0955 - val_accuracy: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1273 - accuracy: 0.0087 - val_loss: 2.0953 - val_accuracy: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1257 - accuracy: 0.0087 - val_loss: 2.0952 - val_accuracy: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1244 - accuracy: 0.0087 - val_loss: 2.0949 - val_accuracy: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1242 - accuracy: 0.0087 - val_loss: 2.0948 - val_accuracy: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1241 - accuracy: 0.0087 - val_loss: 2.0946 - val_accuracy: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1239 - accuracy: 0.0087 - val_loss: 2.0944 - val_accuracy: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1238 - accuracy: 0.0087 - val_loss: 2.0942 - val_accuracy: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1236 - accuracy: 0.0087 - val_loss: 2.0940 - val_accuracy: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1235 - accuracy: 0.0087 - val_loss: 2.0938 - val_accuracy: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1233 - accuracy: 0.0087 - val_loss: 2.0937 - val_accuracy: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1232 - accuracy: 0.0087 - val_loss: 2.0935 - val_accuracy: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1231 - accuracy: 0.0087 - val_loss: 2.0933 - val_accuracy: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1229 - accuracy: 0.0087 - val_loss: 2.0932 - val_accuracy: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1228 - accuracy: 0.0087 - val_loss: 2.0930 - val_accuracy: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1227 - accuracy: 0.0087 - val_loss: 2.0929 - val_accuracy: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1225 - accuracy: 0.0087 - val_loss: 2.0927 - val_accuracy: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1208 - accuracy: 0.0087 - val_loss: 2.0946 - val_accuracy: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1195 - accuracy: 0.0087 - val_loss: 2.0945 - val_accuracy: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1193 - accuracy: 0.0087 - val_loss: 2.0945 - val_accuracy: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1192 - accuracy: 0.0087 - val_loss: 2.0947 - val_accuracy: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1190 - accuracy: 0.0087 - val_loss: 2.0953 - val_accuracy: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1189 - accuracy: 0.0087 - val_loss: 2.0977 - val_accuracy: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1188 - accuracy: 0.0087 - val_loss: 2.0976 - val_accuracy: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1186 - accuracy: 0.0087 - val_loss: 2.0975 - val_accuracy: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1185 - accuracy: 0.0087 - val_loss: 2.0973 - val_accuracy: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1184 - accuracy: 0.0087 - val_loss: 2.0972 - val_accuracy: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1183 - accuracy: 0.0087 - val_loss: 2.0971 - val_accuracy: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1181 - accuracy: 0.0087 - val_loss: 2.0970 - val_accuracy: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1180 - accuracy: 0.0087 - val_loss: 2.0969 - val_accuracy: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1179 - accuracy: 0.0087 - val_loss: 2.0968 - val_accuracy: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1178 - accuracy: 0.0087 - val_loss: 2.0967 - val_accuracy: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1177 - accuracy: 0.0087 - val_loss: 2.0965 - val_accuracy: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1175 - accuracy: 0.0087 - val_loss: 2.0964 - val_accuracy: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1174 - accuracy: 0.0087 - val_loss: 2.0963 - val_accuracy: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1173 - accuracy: 0.0087 - val_loss: 2.0962 - val_accuracy: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1172 - accuracy: 0.0087 - val_loss: 2.0961 - val_accuracy: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.1171 - accuracy: 0.0087 - val_loss: 2.0961 - val_accuracy: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1170 - accuracy: 0.0087 - val_loss: 2.0913 - val_accuracy: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.1169 - accuracy: 0.0087 - val_loss: 2.0908 - val_accuracy: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1168 - accuracy: 0.0087 - val_loss: 2.0904 - val_accuracy: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1152 - accuracy: 0.0139 - val_loss: 2.0842 - val_accuracy: 0.0156\n",
            "Epoch 876/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1114 - accuracy: 0.0191 - val_loss: 2.0842 - val_accuracy: 0.0156\n",
            "Epoch 877/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1103 - accuracy: 0.0191 - val_loss: 2.0841 - val_accuracy: 0.0156\n",
            "Epoch 878/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1101 - accuracy: 0.0191 - val_loss: 2.0840 - val_accuracy: 0.0156\n",
            "Epoch 879/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1100 - accuracy: 0.0191 - val_loss: 2.0839 - val_accuracy: 0.0156\n",
            "Epoch 880/1000\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.1098 - accuracy: 0.0191 - val_loss: 2.0840 - val_accuracy: 0.0156\n",
            "Epoch 881/1000\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.1097 - accuracy: 0.0191 - val_loss: 2.0794 - val_accuracy: 0.0156\n",
            "Epoch 882/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1079 - accuracy: 0.0243 - val_loss: 2.0821 - val_accuracy: 0.0156\n",
            "Epoch 883/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1071 - accuracy: 0.0278 - val_loss: 2.0819 - val_accuracy: 0.0156\n",
            "Epoch 884/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1070 - accuracy: 0.0278 - val_loss: 2.0818 - val_accuracy: 0.0156\n",
            "Epoch 885/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1052 - accuracy: 0.0278 - val_loss: 2.0816 - val_accuracy: 0.0104\n",
            "Epoch 886/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1044 - accuracy: 0.0278 - val_loss: 2.0815 - val_accuracy: 0.0104\n",
            "Epoch 887/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1043 - accuracy: 0.0278 - val_loss: 2.0814 - val_accuracy: 0.0156\n",
            "Epoch 888/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1041 - accuracy: 0.0278 - val_loss: 2.0813 - val_accuracy: 0.0156\n",
            "Epoch 889/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1040 - accuracy: 0.0278 - val_loss: 2.0812 - val_accuracy: 0.0156\n",
            "Epoch 890/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1039 - accuracy: 0.0278 - val_loss: 2.0811 - val_accuracy: 0.0156\n",
            "Epoch 891/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1037 - accuracy: 0.0278 - val_loss: 2.0811 - val_accuracy: 0.0156\n",
            "Epoch 892/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1036 - accuracy: 0.0278 - val_loss: 2.0810 - val_accuracy: 0.0156\n",
            "Epoch 893/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1035 - accuracy: 0.0278 - val_loss: 2.0809 - val_accuracy: 0.0156\n",
            "Epoch 894/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1034 - accuracy: 0.0295 - val_loss: 2.0809 - val_accuracy: 0.0156\n",
            "Epoch 895/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1033 - accuracy: 0.0295 - val_loss: 2.0808 - val_accuracy: 0.0156\n",
            "Epoch 896/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1031 - accuracy: 0.0312 - val_loss: 2.0808 - val_accuracy: 0.0156\n",
            "Epoch 897/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.1030 - accuracy: 0.0312 - val_loss: 2.0807 - val_accuracy: 0.0208\n",
            "Epoch 898/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1029 - accuracy: 0.0312 - val_loss: 2.0768 - val_accuracy: 0.0208\n",
            "Epoch 899/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1028 - accuracy: 0.0312 - val_loss: 2.0759 - val_accuracy: 0.0208\n",
            "Epoch 900/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1027 - accuracy: 0.0312 - val_loss: 2.0756 - val_accuracy: 0.0208\n",
            "Epoch 901/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1026 - accuracy: 0.0312 - val_loss: 2.0754 - val_accuracy: 0.0208\n",
            "Epoch 902/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1025 - accuracy: 0.0312 - val_loss: 2.0752 - val_accuracy: 0.0208\n",
            "Epoch 903/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1024 - accuracy: 0.0312 - val_loss: 2.0751 - val_accuracy: 0.0208\n",
            "Epoch 904/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1023 - accuracy: 0.0312 - val_loss: 2.0750 - val_accuracy: 0.0208\n",
            "Epoch 905/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1022 - accuracy: 0.0312 - val_loss: 2.0750 - val_accuracy: 0.0208\n",
            "Epoch 906/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1021 - accuracy: 0.0312 - val_loss: 2.0750 - val_accuracy: 0.0208\n",
            "Epoch 907/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1020 - accuracy: 0.0330 - val_loss: 2.0750 - val_accuracy: 0.0208\n",
            "Epoch 908/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1019 - accuracy: 0.0330 - val_loss: 2.0751 - val_accuracy: 0.0208\n",
            "Epoch 909/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1018 - accuracy: 0.0347 - val_loss: 2.0755 - val_accuracy: 0.0208\n",
            "Epoch 910/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1017 - accuracy: 0.0347 - val_loss: 2.0787 - val_accuracy: 0.0208\n",
            "Epoch 911/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1016 - accuracy: 0.0347 - val_loss: 2.0786 - val_accuracy: 0.0208\n",
            "Epoch 912/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1015 - accuracy: 0.0347 - val_loss: 2.0785 - val_accuracy: 0.0208\n",
            "Epoch 913/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1014 - accuracy: 0.0347 - val_loss: 2.0784 - val_accuracy: 0.0208\n",
            "Epoch 914/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1013 - accuracy: 0.0347 - val_loss: 2.0783 - val_accuracy: 0.0208\n",
            "Epoch 915/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1013 - accuracy: 0.0347 - val_loss: 2.0782 - val_accuracy: 0.0208\n",
            "Epoch 916/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1012 - accuracy: 0.0347 - val_loss: 2.0781 - val_accuracy: 0.0208\n",
            "Epoch 917/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1011 - accuracy: 0.0347 - val_loss: 2.0780 - val_accuracy: 0.0208\n",
            "Epoch 918/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1010 - accuracy: 0.0347 - val_loss: 2.0780 - val_accuracy: 0.0208\n",
            "Epoch 919/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1009 - accuracy: 0.0347 - val_loss: 2.0779 - val_accuracy: 0.0208\n",
            "Epoch 920/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1008 - accuracy: 0.0347 - val_loss: 2.0778 - val_accuracy: 0.0208\n",
            "Epoch 921/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1007 - accuracy: 0.0347 - val_loss: 2.0778 - val_accuracy: 0.0208\n",
            "Epoch 922/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1006 - accuracy: 0.0347 - val_loss: 2.0737 - val_accuracy: 0.0208\n",
            "Epoch 923/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1005 - accuracy: 0.0347 - val_loss: 2.0732 - val_accuracy: 0.0208\n",
            "Epoch 924/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1005 - accuracy: 0.0347 - val_loss: 2.0729 - val_accuracy: 0.0208\n",
            "Epoch 925/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1004 - accuracy: 0.0347 - val_loss: 2.0727 - val_accuracy: 0.0208\n",
            "Epoch 926/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1003 - accuracy: 0.0347 - val_loss: 2.0725 - val_accuracy: 0.0208\n",
            "Epoch 927/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1002 - accuracy: 0.0347 - val_loss: 2.0724 - val_accuracy: 0.0208\n",
            "Epoch 928/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1001 - accuracy: 0.0347 - val_loss: 2.0723 - val_accuracy: 0.0208\n",
            "Epoch 929/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1000 - accuracy: 0.0365 - val_loss: 2.0722 - val_accuracy: 0.0208\n",
            "Epoch 930/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.1000 - accuracy: 0.0365 - val_loss: 2.0721 - val_accuracy: 0.0208\n",
            "Epoch 931/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0999 - accuracy: 0.0365 - val_loss: 2.0720 - val_accuracy: 0.0208\n",
            "Epoch 932/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0998 - accuracy: 0.0365 - val_loss: 2.0719 - val_accuracy: 0.0208\n",
            "Epoch 933/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0997 - accuracy: 0.0365 - val_loss: 2.0719 - val_accuracy: 0.0208\n",
            "Epoch 934/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0996 - accuracy: 0.0365 - val_loss: 2.0719 - val_accuracy: 0.0208\n",
            "Epoch 935/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.1004 - accuracy: 0.0365 - val_loss: 2.0647 - val_accuracy: 0.0208\n",
            "Epoch 936/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0992 - accuracy: 0.0347 - val_loss: 2.0647 - val_accuracy: 0.0208\n",
            "Epoch 937/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0991 - accuracy: 0.0347 - val_loss: 2.0647 - val_accuracy: 0.0208\n",
            "Epoch 938/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0990 - accuracy: 0.0365 - val_loss: 2.0647 - val_accuracy: 0.0208\n",
            "Epoch 939/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0990 - accuracy: 0.0365 - val_loss: 2.0647 - val_accuracy: 0.0208\n",
            "Epoch 940/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0989 - accuracy: 0.0365 - val_loss: 2.0648 - val_accuracy: 0.0208\n",
            "Epoch 941/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0988 - accuracy: 0.0365 - val_loss: 2.0648 - val_accuracy: 0.0208\n",
            "Epoch 942/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0987 - accuracy: 0.0365 - val_loss: 2.0649 - val_accuracy: 0.0208\n",
            "Epoch 943/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0986 - accuracy: 0.0365 - val_loss: 2.0651 - val_accuracy: 0.0208\n",
            "Epoch 944/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0986 - accuracy: 0.0365 - val_loss: 2.0654 - val_accuracy: 0.0208\n",
            "Epoch 945/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0985 - accuracy: 0.0365 - val_loss: 2.0695 - val_accuracy: 0.0208\n",
            "Epoch 946/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0984 - accuracy: 0.0365 - val_loss: 2.0694 - val_accuracy: 0.0208\n",
            "Epoch 947/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0984 - accuracy: 0.0365 - val_loss: 2.0694 - val_accuracy: 0.0208\n",
            "Epoch 948/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0983 - accuracy: 0.0365 - val_loss: 2.0693 - val_accuracy: 0.0208\n",
            "Epoch 949/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0982 - accuracy: 0.0365 - val_loss: 2.0693 - val_accuracy: 0.0208\n",
            "Epoch 950/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0981 - accuracy: 0.0365 - val_loss: 2.0692 - val_accuracy: 0.0260\n",
            "Epoch 951/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0981 - accuracy: 0.0365 - val_loss: 2.0692 - val_accuracy: 0.0260\n",
            "Epoch 952/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0980 - accuracy: 0.0365 - val_loss: 2.0691 - val_accuracy: 0.0260\n",
            "Epoch 953/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0979 - accuracy: 0.0365 - val_loss: 2.0691 - val_accuracy: 0.0260\n",
            "Epoch 954/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0978 - accuracy: 0.0365 - val_loss: 2.0691 - val_accuracy: 0.0260\n",
            "Epoch 955/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0978 - accuracy: 0.0365 - val_loss: 2.0690 - val_accuracy: 0.0260\n",
            "Epoch 956/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0977 - accuracy: 0.0365 - val_loss: 2.0690 - val_accuracy: 0.0260\n",
            "Epoch 957/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0976 - accuracy: 0.0365 - val_loss: 2.0690 - val_accuracy: 0.0260\n",
            "Epoch 958/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0976 - accuracy: 0.0365 - val_loss: 2.0689 - val_accuracy: 0.0260\n",
            "Epoch 959/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0975 - accuracy: 0.0365 - val_loss: 2.0689 - val_accuracy: 0.0260\n",
            "Epoch 960/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0974 - accuracy: 0.0365 - val_loss: 2.0689 - val_accuracy: 0.0260\n",
            "Epoch 961/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0973 - accuracy: 0.0382 - val_loss: 2.0689 - val_accuracy: 0.0260\n",
            "Epoch 962/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0935 - accuracy: 0.0399 - val_loss: 2.0671 - val_accuracy: 0.0417\n",
            "Epoch 963/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0905 - accuracy: 0.0417 - val_loss: 2.0670 - val_accuracy: 0.0417\n",
            "Epoch 964/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0904 - accuracy: 0.0417 - val_loss: 2.0669 - val_accuracy: 0.0417\n",
            "Epoch 965/1000\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.0903 - accuracy: 0.0417 - val_loss: 2.0668 - val_accuracy: 0.0417\n",
            "Epoch 966/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0902 - accuracy: 0.0417 - val_loss: 2.0668 - val_accuracy: 0.0417\n",
            "Epoch 967/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0894 - accuracy: 0.0382 - val_loss: 2.0682 - val_accuracy: 0.0312\n",
            "Epoch 968/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0878 - accuracy: 0.0382 - val_loss: 2.0681 - val_accuracy: 0.0312\n",
            "Epoch 969/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0862 - accuracy: 0.0382 - val_loss: 2.0678 - val_accuracy: 0.0312\n",
            "Epoch 970/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0836 - accuracy: 0.0382 - val_loss: 2.0677 - val_accuracy: 0.0312\n",
            "Epoch 971/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0834 - accuracy: 0.0382 - val_loss: 2.0676 - val_accuracy: 0.0312\n",
            "Epoch 972/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0832 - accuracy: 0.0382 - val_loss: 2.0675 - val_accuracy: 0.0365\n",
            "Epoch 973/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0831 - accuracy: 0.0382 - val_loss: 2.0673 - val_accuracy: 0.0365\n",
            "Epoch 974/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0829 - accuracy: 0.0382 - val_loss: 2.0672 - val_accuracy: 0.0365\n",
            "Epoch 975/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0828 - accuracy: 0.0382 - val_loss: 2.0671 - val_accuracy: 0.0417\n",
            "Epoch 976/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0827 - accuracy: 0.0382 - val_loss: 2.0670 - val_accuracy: 0.0417\n",
            "Epoch 977/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0826 - accuracy: 0.0382 - val_loss: 2.0629 - val_accuracy: 0.0417\n",
            "Epoch 978/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0825 - accuracy: 0.0382 - val_loss: 2.0621 - val_accuracy: 0.0417\n",
            "Epoch 979/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0824 - accuracy: 0.0382 - val_loss: 2.0618 - val_accuracy: 0.0417\n",
            "Epoch 980/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0823 - accuracy: 0.0382 - val_loss: 2.0615 - val_accuracy: 0.0417\n",
            "Epoch 981/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0822 - accuracy: 0.0382 - val_loss: 2.0613 - val_accuracy: 0.0417\n",
            "Epoch 982/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0722 - accuracy: 0.0382 - val_loss: 2.0604 - val_accuracy: 0.0417\n",
            "Epoch 983/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0709 - accuracy: 0.0382 - val_loss: 2.0602 - val_accuracy: 0.0417\n",
            "Epoch 984/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0706 - accuracy: 0.0382 - val_loss: 2.0600 - val_accuracy: 0.0417\n",
            "Epoch 985/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0705 - accuracy: 0.0382 - val_loss: 2.0599 - val_accuracy: 0.0417\n",
            "Epoch 986/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0704 - accuracy: 0.0382 - val_loss: 2.0598 - val_accuracy: 0.0417\n",
            "Epoch 987/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0702 - accuracy: 0.0399 - val_loss: 2.0597 - val_accuracy: 0.0417\n",
            "Epoch 988/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0650 - accuracy: 0.0469 - val_loss: 2.0641 - val_accuracy: 0.0417\n",
            "Epoch 989/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0635 - accuracy: 0.0486 - val_loss: 2.0640 - val_accuracy: 0.0417\n",
            "Epoch 990/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0633 - accuracy: 0.0486 - val_loss: 2.0638 - val_accuracy: 0.0417\n",
            "Epoch 991/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0631 - accuracy: 0.0486 - val_loss: 2.0637 - val_accuracy: 0.0417\n",
            "Epoch 992/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0630 - accuracy: 0.0486 - val_loss: 2.0635 - val_accuracy: 0.0417\n",
            "Epoch 993/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0628 - accuracy: 0.0486 - val_loss: 2.0634 - val_accuracy: 0.0417\n",
            "Epoch 994/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0612 - accuracy: 0.0486 - val_loss: 2.0633 - val_accuracy: 0.0417\n",
            "Epoch 995/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0605 - accuracy: 0.0451 - val_loss: 2.0632 - val_accuracy: 0.0417\n",
            "Epoch 996/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0604 - accuracy: 0.0451 - val_loss: 2.0631 - val_accuracy: 0.0417\n",
            "Epoch 997/1000\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.0602 - accuracy: 0.0451 - val_loss: 2.0630 - val_accuracy: 0.0417\n",
            "Epoch 998/1000\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0601 - accuracy: 0.0451 - val_loss: 2.0629 - val_accuracy: 0.0417\n",
            "Epoch 999/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0600 - accuracy: 0.0451 - val_loss: 2.0628 - val_accuracy: 0.0417\n",
            "Epoch 1000/1000\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 2.0599 - accuracy: 0.0451 - val_loss: 2.0627 - val_accuracy: 0.0417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot the results of training and validation loss using different learning rates, number of epocgs and network structures\n",
        "#Graph the trajectory of the loss functions, accuracy on both train and test set\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(run_hist_5.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
        "ax.plot(run_hist_5.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
        "ax.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "30SARsMZF9mb",
        "outputId": "ac256e17-b554-48b3-a0b3-2fd6d1032a25"
      },
      "id": "30SARsMZF9mb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7c3f4d2f2080>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data above is not a good graph because none of the train loss and validation loss was trained well. The training data shows an underfit performance due to its gap from the validation data."
      ],
      "metadata": {
        "id": "TtXjA9zoJ-Z5"
      },
      "id": "TtXjA9zoJ-Z5"
    },
    {
      "cell_type": "markdown",
      "id": "broad-appointment",
      "metadata": {
        "id": "broad-appointment"
      },
      "source": [
        "#CONCLUSION\n",
        "\n",
        "During this activity, I was able to understand the difference between the hidden layers, its nodes and the structures. I was also able to identify the effect of epoch and learning rate to the data. The higher the epoch, the higher the chance for the data to be overfitting or to learn more from the model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "efY0IiNZKa-y"
      },
      "id": "efY0IiNZKa-y"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cknXRu0mKa7a"
      },
      "id": "cknXRu0mKa7a"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2eDeSg90Kega"
      },
      "id": "2eDeSg90Kega"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QhkHMA2-KeWi"
      },
      "id": "QhkHMA2-KeWi"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s1jv7YUwKePr"
      },
      "id": "s1jv7YUwKePr"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2wsmXRSSKa5S"
      },
      "id": "2wsmXRSSKa5S"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QgaHvRY5Ka26"
      },
      "id": "QgaHvRY5Ka26"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OiFarce0KawC"
      },
      "id": "OiFarce0KawC"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}